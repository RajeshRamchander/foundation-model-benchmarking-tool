{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean your deployed model endpoint content\n",
    "-----\n",
    "\n",
    "#### In this notebook, we will parse through the existing endpoint.json to delete all of the existing endpoints once you are done with running your respective benchmarking tests.\n",
    "\n",
    "***If you are with running all of the tests, and want to delete the existing endpoints, run this notebook.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "## Import all necessary libraries\n",
    "import json\n",
    "import boto3\n",
    "import logging\n",
    "from globals import *\n",
    "from utils import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Set your logger to display all of the endpoints being cleaned\n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "## Load the config file to extract our endpoint.json file and its respective file path\n",
    "config = load_config(CONFIG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-19 01:13:24,774] p1658 {885729754.py:4} INFO - [\n",
      "  {\n",
      "    \"experiment_name\": \"llama2-13b-inf2.24xlarge-djl-0.24.0-neuronx-sdk-2.14.1-bs=4-tpd=12\",\n",
      "    \"endpoint\": {\n",
      "      \"EndpointName\": \"llama-2-13b-inf2-24xlarge-1705617198\",\n",
      "      \"EndpointArn\": \"arn:aws:sagemaker:us-east-1:015469603702:endpoint/llama-2-13b-inf2-24xlarge-1705617198\",\n",
      "      \"EndpointConfigName\": \"llama-2-13b-inf2-24xlarge-1705617198\",\n",
      "      \"ProductionVariants\": [\n",
      "        {\n",
      "          \"VariantName\": \"AllTraffic\",\n",
      "          \"DeployedImages\": [\n",
      "            {\n",
      "              \"SpecifiedImage\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.26.0-neuronx-sdk2.16.0\",\n",
      "              \"ResolvedImage\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference@sha256:5fb0cb418f37363633907270e3f28bf19f5bb3f44a30290d09edf66629bdf4d4\",\n",
      "              \"ResolutionTime\": \"2024-01-18 22:33:23.239000+00:00\"\n",
      "            }\n",
      "          ],\n",
      "          \"CurrentWeight\": 1.0,\n",
      "          \"DesiredWeight\": 1.0,\n",
      "          \"CurrentInstanceCount\": 1,\n",
      "          \"DesiredInstanceCount\": 1\n",
      "        }\n",
      "      ],\n",
      "      \"EndpointStatus\": \"InService\",\n",
      "      \"CreationTime\": \"2024-01-18 22:33:21.984000+00:00\",\n",
      "      \"LastModifiedTime\": \"2024-01-18 22:57:52.580000+00:00\",\n",
      "      \"ResponseMetadata\": {\n",
      "        \"RequestId\": \"c46a35e7-bc51-4a59-983c-c8649015a53f\",\n",
      "        \"HTTPStatusCode\": 200,\n",
      "        \"HTTPHeaders\": {\n",
      "          \"x-amzn-requestid\": \"c46a35e7-bc51-4a59-983c-c8649015a53f\",\n",
      "          \"content-type\": \"application/x-amz-json-1.1\",\n",
      "          \"content-length\": \"763\",\n",
      "          \"date\": \"Thu, 18 Jan 2024 23:03:30 GMT\"\n",
      "        },\n",
      "        \"RetryAttempts\": 0\n",
      "      }\n",
      "    },\n",
      "    \"endpoint_config\": {\n",
      "      \"EndpointConfigName\": \"llama-2-13b-inf2-24xlarge-1705617198\",\n",
      "      \"EndpointConfigArn\": \"arn:aws:sagemaker:us-east-1:015469603702:endpoint-config/llama-2-13b-inf2-24xlarge-1705617198\",\n",
      "      \"ProductionVariants\": [\n",
      "        {\n",
      "          \"VariantName\": \"AllTraffic\",\n",
      "          \"ModelName\": \"meta-textgenerationneuron-llama-2-13b-f-2024-01-18-22-33-18-012\",\n",
      "          \"InitialInstanceCount\": 1,\n",
      "          \"InstanceType\": \"ml.inf2.24xlarge\",\n",
      "          \"InitialVariantWeight\": 1.0,\n",
      "          \"VolumeSizeInGB\": 256,\n",
      "          \"ModelDataDownloadTimeoutInSeconds\": 3600,\n",
      "          \"ContainerStartupHealthCheckTimeoutInSeconds\": 3600\n",
      "        }\n",
      "      ],\n",
      "      \"CreationTime\": \"2024-01-18 22:33:19.253000+00:00\",\n",
      "      \"EnableNetworkIsolation\": false,\n",
      "      \"ResponseMetadata\": {\n",
      "        \"RequestId\": \"753bbf9b-e748-4caf-b7a1-8387a9c13019\",\n",
      "        \"HTTPStatusCode\": 200,\n",
      "        \"HTTPHeaders\": {\n",
      "          \"x-amzn-requestid\": \"753bbf9b-e748-4caf-b7a1-8387a9c13019\",\n",
      "          \"content-type\": \"application/x-amz-json-1.1\",\n",
      "          \"content-length\": \"569\",\n",
      "          \"date\": \"Thu, 18 Jan 2024 23:03:30 GMT\"\n",
      "        },\n",
      "        \"RetryAttempts\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_config\": {\n",
      "      \"ModelName\": \"meta-textgenerationneuron-llama-2-13b-f-2024-01-18-22-33-18-012\",\n",
      "      \"PrimaryContainer\": {\n",
      "        \"Image\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.26.0-neuronx-sdk2.16.0\",\n",
      "        \"Mode\": \"SingleModel\",\n",
      "        \"ModelDataSource\": {\n",
      "          \"S3DataSource\": {\n",
      "            \"S3Uri\": \"s3://jumpstart-private-cache-prod-us-east-1/meta-textgenerationneuron/meta-textgenerationneuron-llama-2-13b-f/artifacts/inference-prepack/v1.0.0/\",\n",
      "            \"S3DataType\": \"S3Prefix\",\n",
      "            \"CompressionType\": \"None\",\n",
      "            \"ModelAccessConfig\": {\n",
      "              \"AcceptEula\": true\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"Environment\": {\n",
      "          \"OPTION_DTYPE\": \"fp16\",\n",
      "          \"OPTION_MAX_ROLLING_BATCH_SIZE\": \"4\",\n",
      "          \"OPTION_NEURON_OPTIMIZE_LEVEL\": \"2\",\n",
      "          \"OPTION_N_POSITIONS\": \"4096\",\n",
      "          \"OPTION_ROLLING_BATCH\": \"auto\",\n",
      "          \"OPTION_TENSOR_PARALLEL_DEGREE\": \"12\",\n",
      "          \"SAGEMAKER_MODEL_SERVER_TIMEOUT\": \"120\",\n",
      "          \"SAGEMAKER_MODEL_SERVER_WORKERS\": \"1\",\n",
      "          \"SAGEMAKER_PROGRAM\": \"inference.py\",\n",
      "          \"SAGEMAKER_TS_RESPONSE_TIMEOUT\": \"120\"\n",
      "        }\n",
      "      },\n",
      "      \"ExecutionRoleArn\": \"arn:aws:iam::015469603702:role/SageMakerRepoRole\",\n",
      "      \"CreationTime\": \"2024-01-18 22:33:18.674000+00:00\",\n",
      "      \"ModelArn\": \"arn:aws:sagemaker:us-east-1:015469603702:model/meta-textgenerationneuron-llama-2-13b-f-2024-01-18-22-33-18-012\",\n",
      "      \"EnableNetworkIsolation\": true,\n",
      "      \"DeploymentRecommendation\": {\n",
      "        \"RecommendationStatus\": \"COMPLETED\",\n",
      "        \"RealTimeInferenceRecommendations\": []\n",
      "      },\n",
      "      \"ResponseMetadata\": {\n",
      "        \"RequestId\": \"3da16335-999b-46a5-9c57-23715c0f38de\",\n",
      "        \"HTTPStatusCode\": 200,\n",
      "        \"HTTPHeaders\": {\n",
      "          \"x-amzn-requestid\": \"3da16335-999b-46a5-9c57-23715c0f38de\",\n",
      "          \"content-type\": \"application/x-amz-json-1.1\",\n",
      "          \"content-length\": \"1208\",\n",
      "          \"date\": \"Thu, 18 Jan 2024 23:03:30 GMT\"\n",
      "        },\n",
      "        \"RetryAttempts\": 0\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"experiment_name\": \"llama2-13b-inf2.48xlarge-djl-0.24.0-neuronx-sdk-2.14.1-bs=4-tpd=24\",\n",
      "    \"endpoint\": {\n",
      "      \"EndpointName\": \"llama-2-13b-inf2-48xlarge-1705617197\",\n",
      "      \"EndpointArn\": \"arn:aws:sagemaker:us-east-1:015469603702:endpoint/llama-2-13b-inf2-48xlarge-1705617197\",\n",
      "      \"EndpointConfigName\": \"llama-2-13b-inf2-48xlarge-1705617197\",\n",
      "      \"ProductionVariants\": [\n",
      "        {\n",
      "          \"VariantName\": \"AllTraffic\",\n",
      "          \"DeployedImages\": [\n",
      "            {\n",
      "              \"SpecifiedImage\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.26.0-neuronx-sdk2.16.0\",\n",
      "              \"ResolvedImage\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference@sha256:5fb0cb418f37363633907270e3f28bf19f5bb3f44a30290d09edf66629bdf4d4\",\n",
      "              \"ResolutionTime\": \"2024-01-18 22:33:23.629000+00:00\"\n",
      "            }\n",
      "          ],\n",
      "          \"CurrentWeight\": 1.0,\n",
      "          \"DesiredWeight\": 1.0,\n",
      "          \"CurrentInstanceCount\": 1,\n",
      "          \"DesiredInstanceCount\": 1\n",
      "        }\n",
      "      ],\n",
      "      \"EndpointStatus\": \"InService\",\n",
      "      \"CreationTime\": \"2024-01-18 22:33:22.231000+00:00\",\n",
      "      \"LastModifiedTime\": \"2024-01-18 22:48:21.541000+00:00\",\n",
      "      \"ResponseMetadata\": {\n",
      "        \"RequestId\": \"9489220f-6208-488c-8022-8501e242902d\",\n",
      "        \"HTTPStatusCode\": 200,\n",
      "        \"HTTPHeaders\": {\n",
      "          \"x-amzn-requestid\": \"9489220f-6208-488c-8022-8501e242902d\",\n",
      "          \"content-type\": \"application/x-amz-json-1.1\",\n",
      "          \"content-length\": \"764\",\n",
      "          \"date\": \"Thu, 18 Jan 2024 23:03:30 GMT\"\n",
      "        },\n",
      "        \"RetryAttempts\": 0\n",
      "      }\n",
      "    },\n",
      "    \"endpoint_config\": {\n",
      "      \"EndpointConfigName\": \"llama-2-13b-inf2-48xlarge-1705617197\",\n",
      "      \"EndpointConfigArn\": \"arn:aws:sagemaker:us-east-1:015469603702:endpoint-config/llama-2-13b-inf2-48xlarge-1705617197\",\n",
      "      \"ProductionVariants\": [\n",
      "        {\n",
      "          \"VariantName\": \"AllTraffic\",\n",
      "          \"ModelName\": \"meta-textgenerationneuron-llama-2-13b-f-2024-01-18-22-33-17-751\",\n",
      "          \"InitialInstanceCount\": 1,\n",
      "          \"InstanceType\": \"ml.inf2.48xlarge\",\n",
      "          \"InitialVariantWeight\": 1.0,\n",
      "          \"VolumeSizeInGB\": 256,\n",
      "          \"ModelDataDownloadTimeoutInSeconds\": 3600,\n",
      "          \"ContainerStartupHealthCheckTimeoutInSeconds\": 3600\n",
      "        }\n",
      "      ],\n",
      "      \"CreationTime\": \"2024-01-18 22:33:21.620000+00:00\",\n",
      "      \"EnableNetworkIsolation\": false,\n",
      "      \"ResponseMetadata\": {\n",
      "        \"RequestId\": \"5b07faf5-4551-440d-8f52-bd901bb15002\",\n",
      "        \"HTTPStatusCode\": 200,\n",
      "        \"HTTPHeaders\": {\n",
      "          \"x-amzn-requestid\": \"5b07faf5-4551-440d-8f52-bd901bb15002\",\n",
      "          \"content-type\": \"application/x-amz-json-1.1\",\n",
      "          \"content-length\": \"568\",\n",
      "          \"date\": \"Thu, 18 Jan 2024 23:03:30 GMT\"\n",
      "        },\n",
      "        \"RetryAttempts\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_config\": {\n",
      "      \"ModelName\": \"meta-textgenerationneuron-llama-2-13b-f-2024-01-18-22-33-17-751\",\n",
      "      \"PrimaryContainer\": {\n",
      "        \"Image\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.26.0-neuronx-sdk2.16.0\",\n",
      "        \"Mode\": \"SingleModel\",\n",
      "        \"ModelDataSource\": {\n",
      "          \"S3DataSource\": {\n",
      "            \"S3Uri\": \"s3://jumpstart-private-cache-prod-us-east-1/meta-textgenerationneuron/meta-textgenerationneuron-llama-2-13b-f/artifacts/inference-prepack/v1.0.0/\",\n",
      "            \"S3DataType\": \"S3Prefix\",\n",
      "            \"CompressionType\": \"None\",\n",
      "            \"ModelAccessConfig\": {\n",
      "              \"AcceptEula\": true\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"Environment\": {\n",
      "          \"OPTION_DTYPE\": \"fp16\",\n",
      "          \"OPTION_MAX_ROLLING_BATCH_SIZE\": \"4\",\n",
      "          \"OPTION_NEURON_OPTIMIZE_LEVEL\": \"2\",\n",
      "          \"OPTION_N_POSITIONS\": \"4096\",\n",
      "          \"OPTION_ROLLING_BATCH\": \"auto\",\n",
      "          \"OPTION_TENSOR_PARALLEL_DEGREE\": \"24\",\n",
      "          \"SAGEMAKER_MODEL_SERVER_TIMEOUT\": \"120\",\n",
      "          \"SAGEMAKER_MODEL_SERVER_WORKERS\": \"1\",\n",
      "          \"SAGEMAKER_PROGRAM\": \"inference.py\",\n",
      "          \"SAGEMAKER_TS_RESPONSE_TIMEOUT\": \"120\"\n",
      "        }\n",
      "      },\n",
      "      \"ExecutionRoleArn\": \"arn:aws:iam::015469603702:role/SageMakerRepoRole\",\n",
      "      \"CreationTime\": \"2024-01-18 22:33:18.692000+00:00\",\n",
      "      \"ModelArn\": \"arn:aws:sagemaker:us-east-1:015469603702:model/meta-textgenerationneuron-llama-2-13b-f-2024-01-18-22-33-17-751\",\n",
      "      \"EnableNetworkIsolation\": true,\n",
      "      \"DeploymentRecommendation\": {\n",
      "        \"RecommendationStatus\": \"COMPLETED\",\n",
      "        \"RealTimeInferenceRecommendations\": []\n",
      "      },\n",
      "      \"ResponseMetadata\": {\n",
      "        \"RequestId\": \"8716cad0-c78f-4c1e-8376-0123e1f4bc3e\",\n",
      "        \"HTTPStatusCode\": 200,\n",
      "        \"HTTPHeaders\": {\n",
      "          \"x-amzn-requestid\": \"8716cad0-c78f-4c1e-8376-0123e1f4bc3e\",\n",
      "          \"content-type\": \"application/x-amz-json-1.1\",\n",
      "          \"content-length\": \"1208\",\n",
      "          \"date\": \"Thu, 18 Jan 2024 23:03:30 GMT\"\n",
      "        },\n",
      "        \"RetryAttempts\": 0\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"experiment_name\": \"llama2-13b-g5.12xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0\",\n",
      "    \"endpoint\": {\n",
      "      \"EndpointName\": \"llama-2-13b-g5-12xlarge-1705617198\",\n",
      "      \"EndpointArn\": \"arn:aws:sagemaker:us-east-1:015469603702:endpoint/llama-2-13b-g5-12xlarge-1705617198\",\n",
      "      \"EndpointConfigName\": \"llama-2-13b-g5-12xlarge-1705617198\",\n",
      "      \"ProductionVariants\": [\n",
      "        {\n",
      "          \"VariantName\": \"AllTraffic\",\n",
      "          \"DeployedImages\": [\n",
      "            {\n",
      "              \"SpecifiedImage\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04\",\n",
      "              \"ResolvedImage\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference@sha256:2739b630b95d8a95e6b4665e66d8243dd43b99c4fdb865feff13aab9c1da06eb\",\n",
      "              \"ResolutionTime\": \"2024-01-18 22:33:20.326000+00:00\"\n",
      "            }\n",
      "          ],\n",
      "          \"CurrentWeight\": 1.0,\n",
      "          \"DesiredWeight\": 1.0,\n",
      "          \"CurrentInstanceCount\": 1,\n",
      "          \"DesiredInstanceCount\": 1\n",
      "        }\n",
      "      ],\n",
      "      \"EndpointStatus\": \"InService\",\n",
      "      \"CreationTime\": \"2024-01-18 22:33:19.609000+00:00\",\n",
      "      \"LastModifiedTime\": \"2024-01-18 22:38:00.349000+00:00\",\n",
      "      \"ResponseMetadata\": {\n",
      "        \"RequestId\": \"609fce59-36ac-4733-aee2-7a4cf9b3b9e2\",\n",
      "        \"HTTPStatusCode\": 200,\n",
      "        \"HTTPHeaders\": {\n",
      "          \"x-amzn-requestid\": \"609fce59-36ac-4733-aee2-7a4cf9b3b9e2\",\n",
      "          \"content-type\": \"application/x-amz-json-1.1\",\n",
      "          \"content-length\": \"815\",\n",
      "          \"date\": \"Thu, 18 Jan 2024 23:03:30 GMT\"\n",
      "        },\n",
      "        \"RetryAttempts\": 0\n",
      "      }\n",
      "    },\n",
      "    \"endpoint_config\": {\n",
      "      \"EndpointConfigName\": \"llama-2-13b-g5-12xlarge-1705617198\",\n",
      "      \"EndpointConfigArn\": \"arn:aws:sagemaker:us-east-1:015469603702:endpoint-config/llama-2-13b-g5-12xlarge-1705617198\",\n",
      "      \"ProductionVariants\": [\n",
      "        {\n",
      "          \"VariantName\": \"AllTraffic\",\n",
      "          \"ModelName\": \"meta-textgeneration-llama-2-13b-2024-01-18-22-33-18-001\",\n",
      "          \"InitialInstanceCount\": 1,\n",
      "          \"InstanceType\": \"ml.g5.12xlarge\",\n",
      "          \"InitialVariantWeight\": 1.0,\n",
      "          \"ModelDataDownloadTimeoutInSeconds\": 1200,\n",
      "          \"ContainerStartupHealthCheckTimeoutInSeconds\": 1200\n",
      "        }\n",
      "      ],\n",
      "      \"CreationTime\": \"2024-01-18 22:33:19.200000+00:00\",\n",
      "      \"EnableNetworkIsolation\": false,\n",
      "      \"ResponseMetadata\": {\n",
      "        \"RequestId\": \"a7e168a5-8df1-445d-a059-e8313f244a9e\",\n",
      "        \"HTTPStatusCode\": 200,\n",
      "        \"HTTPHeaders\": {\n",
      "          \"x-amzn-requestid\": \"a7e168a5-8df1-445d-a059-e8313f244a9e\",\n",
      "          \"content-type\": \"application/x-amz-json-1.1\",\n",
      "          \"content-length\": \"532\",\n",
      "          \"date\": \"Thu, 18 Jan 2024 23:03:30 GMT\"\n",
      "        },\n",
      "        \"RetryAttempts\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_config\": {\n",
      "      \"ModelName\": \"meta-textgeneration-llama-2-13b-2024-01-18-22-33-18-001\",\n",
      "      \"PrimaryContainer\": {\n",
      "        \"Image\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04\",\n",
      "        \"Mode\": \"SingleModel\",\n",
      "        \"ModelDataSource\": {\n",
      "          \"S3DataSource\": {\n",
      "            \"S3Uri\": \"s3://jumpstart-private-cache-prod-us-east-1/meta-textgeneration/meta-textgeneration-llama-2-13b/artifacts/inference-prepack/v1.0.0/\",\n",
      "            \"S3DataType\": \"S3Prefix\",\n",
      "            \"CompressionType\": \"None\",\n",
      "            \"ModelAccessConfig\": {\n",
      "              \"AcceptEula\": true\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"Environment\": {\n",
      "          \"ENDPOINT_SERVER_TIMEOUT\": \"3600\",\n",
      "          \"HF_MODEL_ID\": \"/opt/ml/model\",\n",
      "          \"MAX_INPUT_LENGTH\": \"4095\",\n",
      "          \"MAX_TOTAL_TOKENS\": \"4096\",\n",
      "          \"MODEL_CACHE_ROOT\": \"/opt/ml/model\",\n",
      "          \"SAGEMAKER_ENV\": \"1\",\n",
      "          \"SAGEMAKER_MODEL_SERVER_WORKERS\": \"1\",\n",
      "          \"SAGEMAKER_PROGRAM\": \"inference.py\",\n",
      "          \"SM_NUM_GPUS\": \"4\"\n",
      "        }\n",
      "      },\n",
      "      \"ExecutionRoleArn\": \"arn:aws:iam::015469603702:role/SageMakerRepoRole\",\n",
      "      \"CreationTime\": \"2024-01-18 22:33:18.638000+00:00\",\n",
      "      \"ModelArn\": \"arn:aws:sagemaker:us-east-1:015469603702:model/meta-textgeneration-llama-2-13b-2024-01-18-22-33-18-001\",\n",
      "      \"EnableNetworkIsolation\": true,\n",
      "      \"DeploymentRecommendation\": {\n",
      "        \"RecommendationStatus\": \"COMPLETED\",\n",
      "        \"RealTimeInferenceRecommendations\": []\n",
      "      },\n",
      "      \"ResponseMetadata\": {\n",
      "        \"RequestId\": \"910070ea-853c-441d-a0a3-9471c8f1861b\",\n",
      "        \"HTTPStatusCode\": 200,\n",
      "        \"HTTPHeaders\": {\n",
      "          \"x-amzn-requestid\": \"910070ea-853c-441d-a0a3-9471c8f1861b\",\n",
      "          \"content-type\": \"application/x-amz-json-1.1\",\n",
      "          \"content-length\": \"1138\",\n",
      "          \"date\": \"Thu, 18 Jan 2024 23:03:30 GMT\"\n",
      "        },\n",
      "        \"RetryAttempts\": 0\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"experiment_name\": \"llama2-13b-g5.24xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0\",\n",
      "    \"endpoint\": {\n",
      "      \"EndpointName\": \"llama-2-13b-g5-24xlarge-1705617197\",\n",
      "      \"EndpointArn\": \"arn:aws:sagemaker:us-east-1:015469603702:endpoint/llama-2-13b-g5-24xlarge-1705617197\",\n",
      "      \"EndpointConfigName\": \"llama-2-13b-g5-24xlarge-1705617197\",\n",
      "      \"ProductionVariants\": [\n",
      "        {\n",
      "          \"VariantName\": \"AllTraffic\",\n",
      "          \"DeployedImages\": [\n",
      "            {\n",
      "              \"SpecifiedImage\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04\",\n",
      "              \"ResolvedImage\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference@sha256:2739b630b95d8a95e6b4665e66d8243dd43b99c4fdb865feff13aab9c1da06eb\",\n",
      "              \"ResolutionTime\": \"2024-01-18 22:33:29.207000+00:00\"\n",
      "            }\n",
      "          ],\n",
      "          \"CurrentWeight\": 1.0,\n",
      "          \"DesiredWeight\": 1.0,\n",
      "          \"CurrentInstanceCount\": 1,\n",
      "          \"DesiredInstanceCount\": 1\n",
      "        }\n",
      "      ],\n",
      "      \"EndpointStatus\": \"InService\",\n",
      "      \"CreationTime\": \"2024-01-18 22:33:28.240000+00:00\",\n",
      "      \"LastModifiedTime\": \"2024-01-18 22:37:48.299000+00:00\",\n",
      "      \"ResponseMetadata\": {\n",
      "        \"RequestId\": \"e48d6c52-5c13-4014-ab5e-62e84b78c101\",\n",
      "        \"HTTPStatusCode\": 200,\n",
      "        \"HTTPHeaders\": {\n",
      "          \"x-amzn-requestid\": \"e48d6c52-5c13-4014-ab5e-62e84b78c101\",\n",
      "          \"content-type\": \"application/x-amz-json-1.1\",\n",
      "          \"content-length\": \"814\",\n",
      "          \"date\": \"Thu, 18 Jan 2024 23:03:30 GMT\"\n",
      "        },\n",
      "        \"RetryAttempts\": 0\n",
      "      }\n",
      "    },\n",
      "    \"endpoint_config\": {\n",
      "      \"EndpointConfigName\": \"llama-2-13b-g5-24xlarge-1705617197\",\n",
      "      \"EndpointConfigArn\": \"arn:aws:sagemaker:us-east-1:015469603702:endpoint-config/llama-2-13b-g5-24xlarge-1705617197\",\n",
      "      \"ProductionVariants\": [\n",
      "        {\n",
      "          \"VariantName\": \"AllTraffic\",\n",
      "          \"ModelName\": \"meta-textgeneration-llama-2-13b-2024-01-18-22-33-17-998\",\n",
      "          \"InitialInstanceCount\": 1,\n",
      "          \"InstanceType\": \"ml.g5.24xlarge\",\n",
      "          \"InitialVariantWeight\": 1.0,\n",
      "          \"ModelDataDownloadTimeoutInSeconds\": 1200,\n",
      "          \"ContainerStartupHealthCheckTimeoutInSeconds\": 1200\n",
      "        }\n",
      "      ],\n",
      "      \"CreationTime\": \"2024-01-18 22:33:27.810000+00:00\",\n",
      "      \"EnableNetworkIsolation\": false,\n",
      "      \"ResponseMetadata\": {\n",
      "        \"RequestId\": \"7ad5b80d-e84d-4e92-82b3-989ecdd8efe1\",\n",
      "        \"HTTPStatusCode\": 200,\n",
      "        \"HTTPHeaders\": {\n",
      "          \"x-amzn-requestid\": \"7ad5b80d-e84d-4e92-82b3-989ecdd8efe1\",\n",
      "          \"content-type\": \"application/x-amz-json-1.1\",\n",
      "          \"content-length\": \"533\",\n",
      "          \"date\": \"Thu, 18 Jan 2024 23:03:30 GMT\"\n",
      "        },\n",
      "        \"RetryAttempts\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_config\": {\n",
      "      \"ModelName\": \"meta-textgeneration-llama-2-13b-2024-01-18-22-33-17-998\",\n",
      "      \"PrimaryContainer\": {\n",
      "        \"Image\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04\",\n",
      "        \"Mode\": \"SingleModel\",\n",
      "        \"ModelDataSource\": {\n",
      "          \"S3DataSource\": {\n",
      "            \"S3Uri\": \"s3://jumpstart-private-cache-prod-us-east-1/meta-textgeneration/meta-textgeneration-llama-2-13b/artifacts/inference-prepack/v1.0.0/\",\n",
      "            \"S3DataType\": \"S3Prefix\",\n",
      "            \"CompressionType\": \"None\",\n",
      "            \"ModelAccessConfig\": {\n",
      "              \"AcceptEula\": true\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"Environment\": {\n",
      "          \"ENDPOINT_SERVER_TIMEOUT\": \"3600\",\n",
      "          \"HF_MODEL_ID\": \"/opt/ml/model\",\n",
      "          \"MAX_INPUT_LENGTH\": \"4095\",\n",
      "          \"MAX_TOTAL_TOKENS\": \"4096\",\n",
      "          \"MODEL_CACHE_ROOT\": \"/opt/ml/model\",\n",
      "          \"SAGEMAKER_ENV\": \"1\",\n",
      "          \"SAGEMAKER_MODEL_SERVER_WORKERS\": \"1\",\n",
      "          \"SAGEMAKER_PROGRAM\": \"inference.py\",\n",
      "          \"SM_NUM_GPUS\": \"4\"\n",
      "        }\n",
      "      },\n",
      "      \"ExecutionRoleArn\": \"arn:aws:iam::015469603702:role/SageMakerRepoRole\",\n",
      "      \"CreationTime\": \"2024-01-18 22:33:27.299000+00:00\",\n",
      "      \"ModelArn\": \"arn:aws:sagemaker:us-east-1:015469603702:model/meta-textgeneration-llama-2-13b-2024-01-18-22-33-17-998\",\n",
      "      \"EnableNetworkIsolation\": true,\n",
      "      \"DeploymentRecommendation\": {\n",
      "        \"RecommendationStatus\": \"COMPLETED\",\n",
      "        \"RealTimeInferenceRecommendations\": []\n",
      "      },\n",
      "      \"ResponseMetadata\": {\n",
      "        \"RequestId\": \"58f24f8f-85a7-4be0-b447-82a84ea49171\",\n",
      "        \"HTTPStatusCode\": 200,\n",
      "        \"HTTPHeaders\": {\n",
      "          \"x-amzn-requestid\": \"58f24f8f-85a7-4be0-b447-82a84ea49171\",\n",
      "          \"content-type\": \"application/x-amz-json-1.1\",\n",
      "          \"content-length\": \"1138\",\n",
      "          \"date\": \"Thu, 18 Jan 2024 23:03:30 GMT\"\n",
      "        },\n",
      "        \"RetryAttempts\": 0\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"experiment_name\": \"llama2-13b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0\",\n",
      "    \"endpoint\": {\n",
      "      \"EndpointName\": \"llama-2-13b-g5-48xlarge-1705618677\",\n",
      "      \"EndpointArn\": \"arn:aws:sagemaker:us-east-1:015469603702:endpoint/llama-2-13b-g5-48xlarge-1705618677\",\n",
      "      \"EndpointConfigName\": \"llama-2-13b-g5-48xlarge-1705618677\",\n",
      "      \"ProductionVariants\": [\n",
      "        {\n",
      "          \"VariantName\": \"AllTraffic\",\n",
      "          \"DeployedImages\": [\n",
      "            {\n",
      "              \"SpecifiedImage\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04\",\n",
      "              \"ResolvedImage\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference@sha256:2739b630b95d8a95e6b4665e66d8243dd43b99c4fdb865feff13aab9c1da06eb\",\n",
      "              \"ResolutionTime\": \"2024-01-18 22:57:59.881000+00:00\"\n",
      "            }\n",
      "          ],\n",
      "          \"CurrentWeight\": 1.0,\n",
      "          \"DesiredWeight\": 1.0,\n",
      "          \"CurrentInstanceCount\": 1,\n",
      "          \"DesiredInstanceCount\": 1\n",
      "        }\n",
      "      ],\n",
      "      \"EndpointStatus\": \"InService\",\n",
      "      \"CreationTime\": \"2024-01-18 22:57:58.770000+00:00\",\n",
      "      \"LastModifiedTime\": \"2024-01-18 23:03:01.729000+00:00\",\n",
      "      \"ResponseMetadata\": {\n",
      "        \"RequestId\": \"fbc22774-9613-4cd4-ad5e-f6b13bbca396\",\n",
      "        \"HTTPStatusCode\": 200,\n",
      "        \"HTTPHeaders\": {\n",
      "          \"x-amzn-requestid\": \"fbc22774-9613-4cd4-ad5e-f6b13bbca396\",\n",
      "          \"content-type\": \"application/x-amz-json-1.1\",\n",
      "          \"content-length\": \"814\",\n",
      "          \"date\": \"Thu, 18 Jan 2024 23:03:30 GMT\"\n",
      "        },\n",
      "        \"RetryAttempts\": 0\n",
      "      }\n",
      "    },\n",
      "    \"endpoint_config\": {\n",
      "      \"EndpointConfigName\": \"llama-2-13b-g5-48xlarge-1705618677\",\n",
      "      \"EndpointConfigArn\": \"arn:aws:sagemaker:us-east-1:015469603702:endpoint-config/llama-2-13b-g5-48xlarge-1705618677\",\n",
      "      \"ProductionVariants\": [\n",
      "        {\n",
      "          \"VariantName\": \"AllTraffic\",\n",
      "          \"ModelName\": \"meta-textgeneration-llama-2-13b-2024-01-18-22-57-57-258\",\n",
      "          \"InitialInstanceCount\": 1,\n",
      "          \"InstanceType\": \"ml.g5.48xlarge\",\n",
      "          \"InitialVariantWeight\": 1.0,\n",
      "          \"ModelDataDownloadTimeoutInSeconds\": 1200,\n",
      "          \"ContainerStartupHealthCheckTimeoutInSeconds\": 1200\n",
      "        }\n",
      "      ],\n",
      "      \"CreationTime\": \"2024-01-18 22:57:58.358000+00:00\",\n",
      "      \"EnableNetworkIsolation\": false,\n",
      "      \"ResponseMetadata\": {\n",
      "        \"RequestId\": \"abaa5330-09d8-4822-ad17-a4976377ccf9\",\n",
      "        \"HTTPStatusCode\": 200,\n",
      "        \"HTTPHeaders\": {\n",
      "          \"x-amzn-requestid\": \"abaa5330-09d8-4822-ad17-a4976377ccf9\",\n",
      "          \"content-type\": \"application/x-amz-json-1.1\",\n",
      "          \"content-length\": \"534\",\n",
      "          \"date\": \"Thu, 18 Jan 2024 23:03:31 GMT\"\n",
      "        },\n",
      "        \"RetryAttempts\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_config\": {\n",
      "      \"ModelName\": \"meta-textgeneration-llama-2-13b-2024-01-18-22-57-57-258\",\n",
      "      \"PrimaryContainer\": {\n",
      "        \"Image\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04\",\n",
      "        \"Mode\": \"SingleModel\",\n",
      "        \"ModelDataSource\": {\n",
      "          \"S3DataSource\": {\n",
      "            \"S3Uri\": \"s3://jumpstart-private-cache-prod-us-east-1/meta-textgeneration/meta-textgeneration-llama-2-13b/artifacts/inference-prepack/v1.0.0/\",\n",
      "            \"S3DataType\": \"S3Prefix\",\n",
      "            \"CompressionType\": \"None\",\n",
      "            \"ModelAccessConfig\": {\n",
      "              \"AcceptEula\": true\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"Environment\": {\n",
      "          \"ENDPOINT_SERVER_TIMEOUT\": \"3600\",\n",
      "          \"HF_MODEL_ID\": \"/opt/ml/model\",\n",
      "          \"MAX_INPUT_LENGTH\": \"4095\",\n",
      "          \"MAX_TOTAL_TOKENS\": \"4096\",\n",
      "          \"MODEL_CACHE_ROOT\": \"/opt/ml/model\",\n",
      "          \"SAGEMAKER_ENV\": \"1\",\n",
      "          \"SAGEMAKER_MODEL_SERVER_WORKERS\": \"1\",\n",
      "          \"SAGEMAKER_PROGRAM\": \"inference.py\",\n",
      "          \"SM_NUM_GPUS\": \"8\"\n",
      "        }\n",
      "      },\n",
      "      \"ExecutionRoleArn\": \"arn:aws:iam::015469603702:role/SageMakerRepoRole\",\n",
      "      \"CreationTime\": \"2024-01-18 22:57:57.838000+00:00\",\n",
      "      \"ModelArn\": \"arn:aws:sagemaker:us-east-1:015469603702:model/meta-textgeneration-llama-2-13b-2024-01-18-22-57-57-258\",\n",
      "      \"EnableNetworkIsolation\": true,\n",
      "      \"DeploymentRecommendation\": {\n",
      "        \"RecommendationStatus\": \"COMPLETED\",\n",
      "        \"RealTimeInferenceRecommendations\": []\n",
      "      },\n",
      "      \"ResponseMetadata\": {\n",
      "        \"RequestId\": \"8a0f9305-77ee-4f1f-98a6-3141c7c1678c\",\n",
      "        \"HTTPStatusCode\": 200,\n",
      "        \"HTTPHeaders\": {\n",
      "          \"x-amzn-requestid\": \"8a0f9305-77ee-4f1f-98a6-3141c7c1678c\",\n",
      "          \"content-type\": \"application/x-amz-json-1.1\",\n",
      "          \"content-length\": \"1138\",\n",
      "          \"date\": \"Thu, 18 Jan 2024 23:03:31 GMT\"\n",
      "        },\n",
      "        \"RetryAttempts\": 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "## Parse through the existing endpoint.json file\n",
    "## read the list of deployed endpoints that are active\n",
    "endpoint_info_list = json.loads(Path(ENDPOINT_LIST_FPATH).read_text())\n",
    "logger.info(json.dumps(endpoint_info_list, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-19 01:13:25,146] p1658 {707195403.py:10} INFO - Going to describing the endpoint -> llama-2-13b-inf2-24xlarge-1705617198\n",
      "[2024-01-19 01:13:25,290] p1658 {707195403.py:15} INFO - going to delete llama-2-13b-inf2-24xlarge-1705617198\n",
      "[2024-01-19 01:13:25,373] p1658 {707195403.py:18} INFO - deleted llama-2-13b-inf2-24xlarge-1705617198\n",
      "[2024-01-19 01:13:25,374] p1658 {707195403.py:10} INFO - Going to describing the endpoint -> llama-2-13b-inf2-48xlarge-1705617197\n",
      "[2024-01-19 01:13:25,481] p1658 {707195403.py:15} INFO - going to delete llama-2-13b-inf2-48xlarge-1705617197\n",
      "[2024-01-19 01:13:27,993] p1658 {707195403.py:18} INFO - deleted llama-2-13b-inf2-48xlarge-1705617197\n",
      "[2024-01-19 01:13:27,994] p1658 {707195403.py:10} INFO - Going to describing the endpoint -> llama-2-13b-g5-12xlarge-1705617198\n",
      "[2024-01-19 01:13:28,109] p1658 {707195403.py:15} INFO - going to delete llama-2-13b-g5-12xlarge-1705617198\n",
      "[2024-01-19 01:13:29,152] p1658 {707195403.py:18} INFO - deleted llama-2-13b-g5-12xlarge-1705617198\n",
      "[2024-01-19 01:13:29,153] p1658 {707195403.py:10} INFO - Going to describing the endpoint -> llama-2-13b-g5-24xlarge-1705617197\n",
      "[2024-01-19 01:13:29,264] p1658 {707195403.py:15} INFO - going to delete llama-2-13b-g5-24xlarge-1705617197\n",
      "[2024-01-19 01:13:30,012] p1658 {707195403.py:18} INFO - deleted llama-2-13b-g5-24xlarge-1705617197\n",
      "[2024-01-19 01:13:30,013] p1658 {707195403.py:10} INFO - Going to describing the endpoint -> llama-2-13b-g5-48xlarge-1705618677\n",
      "[2024-01-19 01:13:30,104] p1658 {707195403.py:15} INFO - going to delete llama-2-13b-g5-48xlarge-1705618677\n",
      "[2024-01-19 01:13:30,437] p1658 {707195403.py:18} INFO - deleted llama-2-13b-g5-48xlarge-1705618677\n"
     ]
    }
   ],
   "source": [
    "## initialize a sagemaker client\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "# Iterate over the endpoint_info_list and mark the items for deletion\n",
    "for item in endpoint_info_list:   \n",
    "    \n",
    "    ## Extract the endpoint name from the deployed model configuration\n",
    "    ep_name = item['endpoint'][\"EndpointName\"]\n",
    "    try:\n",
    "        ## Describe the model endpoint \n",
    "        logger.info(f\"Going to describing the endpoint -> {ep_name}\")\n",
    "        resp = sm_client.describe_endpoint(EndpointName=ep_name)\n",
    "        \n",
    "        ## If the given model endpoint is in service, delete it \n",
    "        if resp['EndpointStatus'] == 'InService':\n",
    "            logger.info(f\"going to delete {ep_name}\")\n",
    "            ## deleting the model endpoint\n",
    "            sm_client.delete_endpoint(EndpointName=ep_name)\n",
    "            logger.info(f\"deleted {ep_name}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"error deleting endpoint={ep_name}, exception={e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
