{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean your deployed model endpoint content\n",
    "-----\n",
    "\n",
    "#### In this notebook, we will parse through the existing endpoint.json to delete all of the existing endpoints once you are done with running your respective benchmarking tests.\n",
    "\n",
    "***If you are with running all of the tests, and want to delete the existing endpoints, run this notebook.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "## Import all necessary libraries\n",
    "import json\n",
    "import boto3\n",
    "import logging\n",
    "from globals import *\n",
    "from utils import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Set your logger to display all of the endpoints being cleaned\n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "## Load the config file to extract our endpoint.json file and its respective file path\n",
    "config = load_config(CONFIG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-20 20:16:06,475] p371 {885729754.py:4} INFO - [\n",
      "  {\n",
      "    \"experiment_name\": \"llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0\",\n",
      "    \"endpoint\": {\n",
      "      \"EndpointName\": \"llama-2-70b-g5-48xlarge-1705773235\",\n",
      "      \"EndpointArn\": \"arn:aws:sagemaker:us-east-1:015469603702:endpoint/llama-2-70b-g5-48xlarge-1705773235\",\n",
      "      \"EndpointConfigName\": \"llama-2-70b-g5-48xlarge-1705773235\",\n",
      "      \"ProductionVariants\": [\n",
      "        {\n",
      "          \"VariantName\": \"AllTraffic\",\n",
      "          \"DeployedImages\": [\n",
      "            {\n",
      "              \"SpecifiedImage\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04\",\n",
      "              \"ResolvedImage\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference@sha256:2739b630b95d8a95e6b4665e66d8243dd43b99c4fdb865feff13aab9c1da06eb\",\n",
      "              \"ResolutionTime\": \"2024-01-20 17:53:58.429000+00:00\"\n",
      "            }\n",
      "          ],\n",
      "          \"CurrentWeight\": 1.0,\n",
      "          \"DesiredWeight\": 1.0,\n",
      "          \"CurrentInstanceCount\": 1,\n",
      "          \"DesiredInstanceCount\": 1\n",
      "        }\n",
      "      ],\n",
      "      \"EndpointStatus\": \"InService\",\n",
      "      \"CreationTime\": \"2024-01-20 17:53:57.406000+00:00\",\n",
      "      \"LastModifiedTime\": \"2024-01-20 18:00:13.628000+00:00\",\n",
      "      \"ResponseMetadata\": {\n",
      "        \"RequestId\": \"f3646c24-b670-4e64-8e6f-7569143b4a12\",\n",
      "        \"HTTPStatusCode\": 200,\n",
      "        \"HTTPHeaders\": {\n",
      "          \"x-amzn-requestid\": \"f3646c24-b670-4e64-8e6f-7569143b4a12\",\n",
      "          \"content-type\": \"application/x-amz-json-1.1\",\n",
      "          \"content-length\": \"815\",\n",
      "          \"date\": \"Sat, 20 Jan 2024 18:01:58 GMT\"\n",
      "        },\n",
      "        \"RetryAttempts\": 0\n",
      "      }\n",
      "    },\n",
      "    \"endpoint_config\": {\n",
      "      \"EndpointConfigName\": \"llama-2-70b-g5-48xlarge-1705773235\",\n",
      "      \"EndpointConfigArn\": \"arn:aws:sagemaker:us-east-1:015469603702:endpoint-config/llama-2-70b-g5-48xlarge-1705773235\",\n",
      "      \"ProductionVariants\": [\n",
      "        {\n",
      "          \"VariantName\": \"AllTraffic\",\n",
      "          \"ModelName\": \"meta-textgeneration-llama-2-70b-2024-01-20-17-53-55-754\",\n",
      "          \"InitialInstanceCount\": 1,\n",
      "          \"InstanceType\": \"ml.g5.48xlarge\",\n",
      "          \"InitialVariantWeight\": 1.0,\n",
      "          \"ModelDataDownloadTimeoutInSeconds\": 1200,\n",
      "          \"ContainerStartupHealthCheckTimeoutInSeconds\": 1200\n",
      "        }\n",
      "      ],\n",
      "      \"CreationTime\": \"2024-01-20 17:53:56.916000+00:00\",\n",
      "      \"EnableNetworkIsolation\": false,\n",
      "      \"ResponseMetadata\": {\n",
      "        \"RequestId\": \"0162e64f-8c75-47bd-90d4-861de5c568ad\",\n",
      "        \"HTTPStatusCode\": 200,\n",
      "        \"HTTPHeaders\": {\n",
      "          \"x-amzn-requestid\": \"0162e64f-8c75-47bd-90d4-861de5c568ad\",\n",
      "          \"content-type\": \"application/x-amz-json-1.1\",\n",
      "          \"content-length\": \"534\",\n",
      "          \"date\": \"Sat, 20 Jan 2024 18:01:58 GMT\"\n",
      "        },\n",
      "        \"RetryAttempts\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_config\": {\n",
      "      \"ModelName\": \"meta-textgeneration-llama-2-70b-2024-01-20-17-53-55-754\",\n",
      "      \"PrimaryContainer\": {\n",
      "        \"Image\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04\",\n",
      "        \"Mode\": \"SingleModel\",\n",
      "        \"ModelDataSource\": {\n",
      "          \"S3DataSource\": {\n",
      "            \"S3Uri\": \"s3://jumpstart-private-cache-prod-us-east-1/meta-textgeneration/meta-textgeneration-llama-2-70b/artifacts/inference-prepack/v1.0.0/\",\n",
      "            \"S3DataType\": \"S3Prefix\",\n",
      "            \"CompressionType\": \"None\",\n",
      "            \"ModelAccessConfig\": {\n",
      "              \"AcceptEula\": true\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"Environment\": {\n",
      "          \"ENDPOINT_SERVER_TIMEOUT\": \"3600\",\n",
      "          \"HF_MODEL_ID\": \"/opt/ml/model\",\n",
      "          \"MAX_INPUT_LENGTH\": \"4095\",\n",
      "          \"MAX_TOTAL_TOKENS\": \"4096\",\n",
      "          \"MODEL_CACHE_ROOT\": \"/opt/ml/model\",\n",
      "          \"SAGEMAKER_ENV\": \"1\",\n",
      "          \"SAGEMAKER_MODEL_SERVER_WORKERS\": \"1\",\n",
      "          \"SAGEMAKER_PROGRAM\": \"inference.py\",\n",
      "          \"SM_NUM_GPUS\": \"8\"\n",
      "        }\n",
      "      },\n",
      "      \"ExecutionRoleArn\": \"arn:aws:iam::015469603702:role/SageMakerRepoRole\",\n",
      "      \"CreationTime\": \"2024-01-20 17:53:56.387000+00:00\",\n",
      "      \"ModelArn\": \"arn:aws:sagemaker:us-east-1:015469603702:model/meta-textgeneration-llama-2-70b-2024-01-20-17-53-55-754\",\n",
      "      \"EnableNetworkIsolation\": true,\n",
      "      \"DeploymentRecommendation\": {\n",
      "        \"RecommendationStatus\": \"COMPLETED\",\n",
      "        \"RealTimeInferenceRecommendations\": []\n",
      "      },\n",
      "      \"ResponseMetadata\": {\n",
      "        \"RequestId\": \"7768399d-4166-446c-b4f2-87b844884a15\",\n",
      "        \"HTTPStatusCode\": 200,\n",
      "        \"HTTPHeaders\": {\n",
      "          \"x-amzn-requestid\": \"7768399d-4166-446c-b4f2-87b844884a15\",\n",
      "          \"content-type\": \"application/x-amz-json-1.1\",\n",
      "          \"content-length\": \"1138\",\n",
      "          \"date\": \"Sat, 20 Jan 2024 18:01:58 GMT\"\n",
      "        },\n",
      "        \"RetryAttempts\": 0\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"experiment_name\": \"llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118\",\n",
      "    \"endpoint\": {\n",
      "      \"EndpointName\": \"huggingface-pytorch-tgi-inference-2024-01-20-17-53-57-009\",\n",
      "      \"EndpointArn\": \"arn:aws:sagemaker:us-east-1:015469603702:endpoint/huggingface-pytorch-tgi-inference-2024-01-20-17-53-57-009\",\n",
      "      \"EndpointConfigName\": \"huggingface-pytorch-tgi-inference-2024-01-20-17-53-57-009\",\n",
      "      \"ProductionVariants\": [\n",
      "        {\n",
      "          \"VariantName\": \"AllTraffic\",\n",
      "          \"DeployedImages\": [\n",
      "            {\n",
      "              \"SpecifiedImage\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi0.9.3-gpu-py39-cu118-ubuntu20.04\",\n",
      "              \"ResolvedImage\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference@sha256:947399ae8b3fa131fc6d2da99f56c9c41195c7ce7cbd890e1e6c0dc328d238cd\",\n",
      "              \"ResolutionTime\": \"2024-01-20 17:53:58.504000+00:00\"\n",
      "            }\n",
      "          ],\n",
      "          \"CurrentWeight\": 1.0,\n",
      "          \"DesiredWeight\": 1.0,\n",
      "          \"CurrentInstanceCount\": 1,\n",
      "          \"DesiredInstanceCount\": 1\n",
      "        }\n",
      "      ],\n",
      "      \"EndpointStatus\": \"InService\",\n",
      "      \"CreationTime\": \"2024-01-20 17:53:57.729000+00:00\",\n",
      "      \"LastModifiedTime\": \"2024-01-20 18:01:58.813000+00:00\",\n",
      "      \"ResponseMetadata\": {\n",
      "        \"RequestId\": \"71eab07e-9355-47df-ae01-71d2b9f1124c\",\n",
      "        \"HTTPStatusCode\": 200,\n",
      "        \"HTTPHeaders\": {\n",
      "          \"x-amzn-requestid\": \"71eab07e-9355-47df-ae01-71d2b9f1124c\",\n",
      "          \"content-type\": \"application/x-amz-json-1.1\",\n",
      "          \"content-length\": \"884\",\n",
      "          \"date\": \"Sat, 20 Jan 2024 18:01:59 GMT\"\n",
      "        },\n",
      "        \"RetryAttempts\": 0\n",
      "      }\n",
      "    },\n",
      "    \"endpoint_config\": {\n",
      "      \"EndpointConfigName\": \"huggingface-pytorch-tgi-inference-2024-01-20-17-53-57-009\",\n",
      "      \"EndpointConfigArn\": \"arn:aws:sagemaker:us-east-1:015469603702:endpoint-config/huggingface-pytorch-tgi-inference-2024-01-20-17-53-57-009\",\n",
      "      \"ProductionVariants\": [\n",
      "        {\n",
      "          \"VariantName\": \"AllTraffic\",\n",
      "          \"ModelName\": \"huggingface-pytorch-tgi-inference-2024-01-20-17-53-56-406\",\n",
      "          \"InitialInstanceCount\": 1,\n",
      "          \"InstanceType\": \"ml.p4d.24xlarge\",\n",
      "          \"InitialVariantWeight\": 1.0,\n",
      "          \"ContainerStartupHealthCheckTimeoutInSeconds\": 300\n",
      "        }\n",
      "      ],\n",
      "      \"CreationTime\": \"2024-01-20 17:53:57.313000+00:00\",\n",
      "      \"EnableNetworkIsolation\": false,\n",
      "      \"ResponseMetadata\": {\n",
      "        \"RequestId\": \"79be082a-b24f-41dd-9c06-5b34e2bcf445\",\n",
      "        \"HTTPStatusCode\": 200,\n",
      "        \"HTTPHeaders\": {\n",
      "          \"x-amzn-requestid\": \"79be082a-b24f-41dd-9c06-5b34e2bcf445\",\n",
      "          \"content-type\": \"application/x-amz-json-1.1\",\n",
      "          \"content-length\": \"541\",\n",
      "          \"date\": \"Sat, 20 Jan 2024 18:01:59 GMT\"\n",
      "        },\n",
      "        \"RetryAttempts\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_config\": {\n",
      "      \"ModelName\": \"huggingface-pytorch-tgi-inference-2024-01-20-17-53-56-406\",\n",
      "      \"PrimaryContainer\": {\n",
      "        \"Image\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi0.9.3-gpu-py39-cu118-ubuntu20.04\",\n",
      "        \"Mode\": \"SingleModel\",\n",
      "        \"Environment\": {\n",
      "          \"HF_MODEL_ID\": \"meta-llama/Llama-2-70b-chat-hf\",\n",
      "          \"HUGGING_FACE_HUB_TOKEN\": \"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\",\n",
      "          \"MAX_BATCH_TOTAL_TOKENS\": \"8192\",\n",
      "          \"MAX_INPUT_LENGTH\": \"4090\",\n",
      "          \"MAX_TOTAL_TOKENS\": \"4096\",\n",
      "          \"SAGEMAKER_CONTAINER_LOG_LEVEL\": \"20\",\n",
      "          \"SAGEMAKER_REGION\": \"us-east-1\",\n",
      "          \"SM_NUM_GPUS\": \"8\"\n",
      "        }\n",
      "      },\n",
      "      \"ExecutionRoleArn\": \"arn:aws:iam::015469603702:role/SageMakerRepoRole\",\n",
      "      \"CreationTime\": \"2024-01-20 17:53:56.883000+00:00\",\n",
      "      \"ModelArn\": \"arn:aws:sagemaker:us-east-1:015469603702:model/huggingface-pytorch-tgi-inference-2024-01-20-17-53-56-406\",\n",
      "      \"EnableNetworkIsolation\": false,\n",
      "      \"DeploymentRecommendation\": {\n",
      "        \"RecommendationStatus\": \"COMPLETED\",\n",
      "        \"RealTimeInferenceRecommendations\": []\n",
      "      },\n",
      "      \"ResponseMetadata\": {\n",
      "        \"RequestId\": \"0c4aabdf-977a-4a05-a819-53ab906fbbb6\",\n",
      "        \"HTTPStatusCode\": 200,\n",
      "        \"HTTPHeaders\": {\n",
      "          \"x-amzn-requestid\": \"0c4aabdf-977a-4a05-a819-53ab906fbbb6\",\n",
      "          \"content-type\": \"application/x-amz-json-1.1\",\n",
      "          \"content-length\": \"897\",\n",
      "          \"date\": \"Sat, 20 Jan 2024 18:01:59 GMT\"\n",
      "        },\n",
      "        \"RetryAttempts\": 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "## Parse through the existing endpoint.json file\n",
    "## read the list of deployed endpoints that are active\n",
    "endpoint_info_list = json.loads(Path(ENDPOINT_LIST_FPATH).read_text())\n",
    "logger.info(json.dumps(endpoint_info_list, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-20 20:16:07,996] p371 {707195403.py:10} INFO - Going to describing the endpoint -> llama-2-70b-g5-48xlarge-1705773235\n",
      "[2024-01-20 20:16:08,174] p371 {707195403.py:15} INFO - going to delete llama-2-70b-g5-48xlarge-1705773235\n",
      "[2024-01-20 20:16:08,267] p371 {707195403.py:18} INFO - deleted llama-2-70b-g5-48xlarge-1705773235\n",
      "[2024-01-20 20:16:08,268] p371 {707195403.py:10} INFO - Going to describing the endpoint -> huggingface-pytorch-tgi-inference-2024-01-20-17-53-57-009\n",
      "[2024-01-20 20:16:08,372] p371 {707195403.py:15} INFO - going to delete huggingface-pytorch-tgi-inference-2024-01-20-17-53-57-009\n",
      "[2024-01-20 20:16:10,448] p371 {707195403.py:18} INFO - deleted huggingface-pytorch-tgi-inference-2024-01-20-17-53-57-009\n"
     ]
    }
   ],
   "source": [
    "## initialize a sagemaker client\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "# Iterate over the endpoint_info_list and mark the items for deletion\n",
    "for item in endpoint_info_list:   \n",
    "    \n",
    "    ## Extract the endpoint name from the deployed model configuration\n",
    "    ep_name = item['endpoint'][\"EndpointName\"]\n",
    "    try:\n",
    "        ## Describe the model endpoint \n",
    "        logger.info(f\"Going to describing the endpoint -> {ep_name}\")\n",
    "        resp = sm_client.describe_endpoint(EndpointName=ep_name)\n",
    "        \n",
    "        ## If the given model endpoint is in service, delete it \n",
    "        if resp['EndpointStatus'] == 'InService':\n",
    "            logger.info(f\"going to delete {ep_name}\")\n",
    "            ## deleting the model endpoint\n",
    "            sm_client.delete_endpoint(EndpointName=ep_name)\n",
    "            logger.info(f\"deleted {ep_name}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"error deleting endpoint={ep_name}, exception={e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
