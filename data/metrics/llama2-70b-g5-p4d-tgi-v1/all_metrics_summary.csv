experiment_name,payload_file,instance_type,concurrency,error_rate,prompt_token_count_mean,prompt_token_throughput,completion_token_count_mean,completion_token_throughput,latency_mean,transactions_per_minute
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1-500.jsonl,ml.g5.48xlarge,1,0.0,304,47,102,15,6.23,9
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1-500.jsonl,ml.g5.48xlarge,2,0.0,304,79,102,26,7.45,15
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1-500.jsonl,ml.g5.48xlarge,4,0.0,304,125,102,42,9.67,24
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1-500.jsonl,ml.g5.48xlarge,6,0.0,304,158,70,36,9.54,31
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1-500.jsonl,ml.g5.48xlarge,8,0.0,304,140,81,37,11.5,27
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1000-2000.jsonl,ml.g5.48xlarge,1,0.0,1623,185,76,7,9.56,6
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1000-2000.jsonl,ml.g5.48xlarge,2,0.0,1643,198,84,10,15.43,6
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1000-2000.jsonl,ml.g5.48xlarge,4,0.0,1641,237,78,11,24.48,8
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1000-2000.jsonl,ml.g5.48xlarge,6,0.0,1672,259,80,12,35.89,9
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1000-2000.jsonl,ml.g5.48xlarge,8,0.0,1630,253,78,12,34.37,9
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_2000-3000.jsonl,ml.g5.48xlarge,1,0.0,2503,222,70,5,12.21,4
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_2000-3000.jsonl,ml.g5.48xlarge,2,0.0,2503,227,75,6,20.2,5
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_2000-3000.jsonl,ml.g5.48xlarge,4,0.0,2503,254,83,8,34.19,5
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_2000-3000.jsonl,ml.g5.48xlarge,6,0.0,2515,262,83,8,49.79,6
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_2000-3000.jsonl,ml.g5.48xlarge,8,0.38,4090,270,57,3,39.57,3
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_3000-4000.jsonl,ml.g5.48xlarge,1,0.0,3478,239,67,3,15.44,3
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_3000-4000.jsonl,ml.g5.48xlarge,2,0.0,3474,245,75,5,26.82,3
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_3000-4000.jsonl,ml.g5.48xlarge,4,0.0,3468,268,70,5,43.95,4
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_3000-4000.jsonl,ml.g5.48xlarge,6,0.78,16106,344,10,0,44.26,0
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_3000-4000.jsonl,ml.g5.48xlarge,8,0.67,11223,301,48,1,34.89,1
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_500-1000.jsonl,ml.g5.48xlarge,1,0.0,980,116,102,12,8.43,7
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_500-1000.jsonl,ml.g5.48xlarge,2,0.0,980,165,102,17,11.82,10
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_500-1000.jsonl,ml.g5.48xlarge,4,0.0,980,211,101,21,18.49,13
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_500-1000.jsonl,ml.g5.48xlarge,6,0.0,980,235,72,17,21.61,14
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_500-1000.jsonl,ml.g5.48xlarge,8,0.0,980,246,69,17,22.0,15
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_1-500.jsonl,ml.p4d.24xlarge,1,0.0,304,226,328,244,1.33,44
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_1-500.jsonl,ml.p4d.24xlarge,2,0.0,304,394,328,425,1.53,78
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_1-500.jsonl,ml.p4d.24xlarge,4,0.0,304,708,328,764,1.69,139
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_1-500.jsonl,ml.p4d.24xlarge,6,0.0,304,930,328,1003,1.93,183
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_1-500.jsonl,ml.p4d.24xlarge,8,0.0,304,666,328,718,1.93,131
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_1000-2000.jsonl,ml.p4d.24xlarge,1,0.0,1623,1002,1654,1016,2.01,36
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_1000-2000.jsonl,ml.p4d.24xlarge,2,0.0,1643,1213,1670,1229,2.64,43
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_1000-2000.jsonl,ml.p4d.24xlarge,4,0.0,1641,1322,1671,1342,3.72,46
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_1000-2000.jsonl,ml.p4d.24xlarge,6,0.0,1672,1694,1693,1711,4.31,59
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_1000-2000.jsonl,ml.p4d.24xlarge,8,0.0,1630,1380,1660,1405,5.28,50
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_2000-3000.jsonl,ml.p4d.24xlarge,1,0.0,2503,1241,2535,1252,2.51,29
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_2000-3000.jsonl,ml.p4d.24xlarge,2,0.0,2503,1376,2536,1391,3.36,33
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_2000-3000.jsonl,ml.p4d.24xlarge,4,0.0,2503,1476,2534,1493,4.99,35
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_2000-3000.jsonl,ml.p4d.24xlarge,6,0.0,2515,1402,2550,1422,7.51,33
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_2000-3000.jsonl,ml.p4d.24xlarge,8,0.0,2503,1455,2533,1473,7.66,34
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_3000-4000.jsonl,ml.p4d.24xlarge,1,0.0,3478,1471,3504,1479,2.68,25
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_3000-4000.jsonl,ml.p4d.24xlarge,2,0.0,3474,1688,3502,1699,3.92,28
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_3000-4000.jsonl,ml.p4d.24xlarge,4,0.0,3468,1697,3496,1709,6.15,28
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_3000-4000.jsonl,ml.p4d.24xlarge,6,0.0,3454,1770,3480,1782,8.04,30
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_3000-4000.jsonl,ml.p4d.24xlarge,8,0.0,3455,1659,3484,1672,9.53,28
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_500-1000.jsonl,ml.p4d.24xlarge,1,0.0,980,670,1004,687,1.45,40
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_500-1000.jsonl,ml.p4d.24xlarge,2,0.0,980,991,999,1011,1.73,60
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_500-1000.jsonl,ml.p4d.24xlarge,4,0.0,980,1567,1004,1605,2.47,96
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_500-1000.jsonl,ml.p4d.24xlarge,6,0.0,980,1390,1001,1420,3.15,85
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_500-1000.jsonl,ml.p4d.24xlarge,8,0.0,980,1527,1004,1564,3.06,93
