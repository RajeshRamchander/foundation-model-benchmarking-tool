experiment_name,payload_file,instance_type,concurrency,error_rate,prompt_token_count_mean,prompt_token_throughput,completion_token_count_mean,completion_token_throughput,latency_mean,transactions_per_minute,price_per_hour,price_per_txn,score
llama2-13b-g5.12xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_3000-4000.jsonl,ml.g5.12xlarge,4,0.0,3468,1301,84,31,9.0,22,7.09,0.005371212121212121,93.14441310139476
llama2-13b-g5.24xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_3000-4000.jsonl,ml.g5.24xlarge,4,0.0,3468,1296,86,32,9.14,21,10.18,0.008079365079365079,61.9407556757361
llama2-13b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_3000-4000.jsonl,ml.g5.48xlarge,4,0.0,3468,965,86,24,12.82,16,20.36,0.021208333333333333,23.61464006693863
llama2-13b-inf2.48xlarge-djl-0.24.0-neuronx-sdk-2.14.1-bs=4-tpd=24,payload_en_3000-4000.jsonl,ml.inf2.48xlarge,2,0.0,3474,3420,29,26,1.9,58,15.58,0.004477011494252873,111.94480102695763
llama2-13b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_3000-4000.jsonl,ml.p4d.24xlarge,2,0.0,3474,3377,3507,3404,1.89,58,37.688,0.010829885057471265,46.43309197543967
