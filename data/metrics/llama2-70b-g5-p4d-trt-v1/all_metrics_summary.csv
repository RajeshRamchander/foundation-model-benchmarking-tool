experiment_name,payload_file,instance_type,concurrency,error_rate,prompt_token_count_mean,prompt_token_throughput,completion_token_count_mean,completion_token_throughput,latency_mean,transactions_per_minute
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_1-500.jsonl,ml.p4d.24xlarge,1,0.0,304,27,192,17,10.85,5
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_1-500.jsonl,ml.p4d.24xlarge,2,0.0,304,52,111,19,7.36,10
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_1-500.jsonl,ml.p4d.24xlarge,4,0.0,304,84,137,38,11.18,16
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_1-500.jsonl,ml.p4d.24xlarge,6,0.0,304,111,127,46,12.35,22
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_1-500.jsonl,ml.p4d.24xlarge,8,0.0,304,130,79,34,9.01,25
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_1000-2000.jsonl,ml.p4d.24xlarge,1,0.0,1623,171,117,8,11.81,5
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_1000-2000.jsonl,ml.p4d.24xlarge,2,0.0,1643,149,135,12,18.2,5
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_1000-2000.jsonl,ml.p4d.24xlarge,4,0.0,1641,248,87,11,22.39,9
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_1000-2000.jsonl,ml.p4d.24xlarge,6,0.0,1672,240,106,15,31.42,8
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_1000-2000.jsonl,ml.p4d.24xlarge,8,0.0,1630,251,90,14,31.46,9
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_2000-3000.jsonl,ml.p4d.24xlarge,1,0.0,2503,254,77,4,11.88,5
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_2000-3000.jsonl,ml.p4d.24xlarge,2,0.0,2503,232,87,7,19.27,5
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_2000-3000.jsonl,ml.p4d.24xlarge,4,0.0,2503,236,111,10,33.18,5
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_2000-3000.jsonl,ml.p4d.24xlarge,6,0.03,2600,256,109,10,44.82,5
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_2000-3000.jsonl,ml.p4d.24xlarge,8,0.03,2593,225,67,5,51.22,5
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_3000-4000.jsonl,ml.p4d.24xlarge,1,0.09,3431,4305,94,4,16.35,3
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_3000-4000.jsonl,ml.p4d.24xlarge,2,0.09,4105,300,89,5,23.59,3
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_3000-4000.jsonl,ml.p4d.24xlarge,4,0.08,3950,281,113,8,40.93,3
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_3000-4000.jsonl,ml.p4d.24xlarge,6,0.12,4013,252,64,3,63.1,3
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_3000-4000.jsonl,ml.p4d.24xlarge,8,0.12,4055,193,52,2,93.73,2
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_500-1000.jsonl,ml.p4d.24xlarge,1,0.0,980,72,192,14,13.59,4
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_500-1000.jsonl,ml.p4d.24xlarge,2,0.0,980,116,192,22,16.85,7
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_500-1000.jsonl,ml.p4d.24xlarge,4,0.0,980,171,90,15,16.71,10
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_500-1000.jsonl,ml.p4d.24xlarge,6,0.0,980,199,133,27,23.81,12
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_500-1000.jsonl,ml.p4d.24xlarge,8,0.0,980,172,168,29,26.34,10
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1-500.jsonl,ml.g5.48xlarge,1,0.0,304,28,192,17,10.8,5
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1-500.jsonl,ml.g5.48xlarge,2,0.0,304,52,107,18,7.13,10
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1-500.jsonl,ml.g5.48xlarge,4,0.0,304,83,151,41,12.13,16
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1-500.jsonl,ml.g5.48xlarge,6,0.0,304,113,107,40,10.91,22
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1-500.jsonl,ml.g5.48xlarge,8,0.0,304,125,123,51,12.3,24
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1000-2000.jsonl,ml.g5.48xlarge,1,0.0,1623,151,145,9,13.52,5
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1000-2000.jsonl,ml.g5.48xlarge,2,0.0,1643,177,119,11,16.97,6
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1000-2000.jsonl,ml.g5.48xlarge,4,0.0,1641,208,122,15,24.6,7
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1000-2000.jsonl,ml.g5.48xlarge,6,0.0,1672,237,127,18,34.77,8
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1000-2000.jsonl,ml.g5.48xlarge,8,0.0,1630,235,129,18,34.85,8
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_2000-3000.jsonl,ml.g5.48xlarge,1,0.0,2503,240,91,5,12.96,5
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_2000-3000.jsonl,ml.g5.48xlarge,2,0.0,2503,237,91,7,19.47,5
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_2000-3000.jsonl,ml.g5.48xlarge,4,0.0,2503,259,80,7,29.42,6
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_2000-3000.jsonl,ml.g5.48xlarge,6,0.0,2515,257,104,10,44.7,5
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_2000-3000.jsonl,ml.g5.48xlarge,8,0.03,2593,199,59,4,59.39,4
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_3000-4000.jsonl,ml.g5.48xlarge,1,0.09,3431,3366,105,4,17.24,3
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_3000-4000.jsonl,ml.g5.48xlarge,2,0.09,4105,280,108,6,25.36,3
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_3000-4000.jsonl,ml.g5.48xlarge,4,0.08,3950,295,102,7,40.31,4
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_3000-4000.jsonl,ml.g5.48xlarge,6,0.08,3873,244,67,4,63.05,3
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_3000-4000.jsonl,ml.g5.48xlarge,8,0.17,4261,229,42,2,77.17,3
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_500-1000.jsonl,ml.g5.48xlarge,1,0.0,980,73,190,14,13.31,4
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_500-1000.jsonl,ml.g5.48xlarge,2,0.0,980,123,108,13,11.04,7
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_500-1000.jsonl,ml.g5.48xlarge,4,0.0,980,178,90,16,15.68,10
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_500-1000.jsonl,ml.g5.48xlarge,6,0.0,980,200,131,26,23.44,12
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_500-1000.jsonl,ml.g5.48xlarge,8,0.0,980,228,110,25,22.99,13
