experiment_name,payload_file,instance_type,concurrency,error_rate,prompt_token_count_mean,prompt_token_throughput,completion_token_count_mean,completion_token_throughput,latency_mean,transactions_per_minute
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_1-500.jsonl,ml.p4d.24xlarge,1,0.0,304,120,102,40,2.51,24
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_1-500.jsonl,ml.p4d.24xlarge,2,0.0,304,230,101,76,2.62,45
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_1-500.jsonl,ml.p4d.24xlarge,4,0.0,304,398,101,132,3.03,78
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_1-500.jsonl,ml.p4d.24xlarge,6,0.0,304,577,88,167,2.75,114
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_1-500.jsonl,ml.p4d.24xlarge,8,0.0,304,418,90,124,2.81,82
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_1000-2000.jsonl,ml.p4d.24xlarge,1,0.0,1623,2109,70,31,1.97,74
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_1000-2000.jsonl,ml.p4d.24xlarge,2,0.0,1643,1062,87,56,2.71,38
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_1000-2000.jsonl,ml.p4d.24xlarge,4,0.0,1641,1814,67,73,2.66,66
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_1000-2000.jsonl,ml.p4d.24xlarge,6,0.0,1672,2328,86,120,3.79,83
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_1000-2000.jsonl,ml.p4d.24xlarge,8,0.0,1630,2234,89,118,3.78,81
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_2000-3000.jsonl,ml.p4d.24xlarge,1,0.0,2503,2124,76,29,2.3,49
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_2000-3000.jsonl,ml.p4d.24xlarge,2,0.0,2503,1749,81,48,2.82,41
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_2000-3000.jsonl,ml.p4d.24xlarge,4,0.0,2503,2399,73,70,3.32,57
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_2000-3000.jsonl,ml.p4d.24xlarge,6,0.0,2515,3085,88,108,4.43,73
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_2000-3000.jsonl,ml.p4d.24xlarge,8,0.0,2503,3473,67,92,3.77,82
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_500-1000.jsonl,ml.p4d.24xlarge,1,0.0,980,370,102,38,2.64,22
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_500-1000.jsonl,ml.p4d.24xlarge,2,0.0,980,710,56,40,1.64,43
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_500-1000.jsonl,ml.p4d.24xlarge,4,0.0,980,1160,77,91,2.65,70
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_500-1000.jsonl,ml.p4d.24xlarge,6,0.0,980,1615,71,117,2.73,99
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_500-1000.jsonl,ml.p4d.24xlarge,8,0.0,980,1395,83,119,3.2,85
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1-500.jsonl,ml.g5.48xlarge,1,0.0,304,216,9,6,1.24,42
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1-500.jsonl,ml.g5.48xlarge,2,0.0,304,82,102,27,7.35,16
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1-500.jsonl,ml.g5.48xlarge,4,0.0,304,125,102,42,9.69,24
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1-500.jsonl,ml.g5.48xlarge,6,0.0,304,158,86,45,10.48,31
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1-500.jsonl,ml.g5.48xlarge,8,0.0,304,126,102,42,10.73,25
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1000-2000.jsonl,ml.g5.48xlarge,1,0.0,1623,175,83,7,10.06,5
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1000-2000.jsonl,ml.g5.48xlarge,2,0.0,1643,196,97,11,16.34,6
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1000-2000.jsonl,ml.g5.48xlarge,4,0.0,1641,244,84,12,24.88,8
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1000-2000.jsonl,ml.g5.48xlarge,6,0.0,1672,266,71,11,31.47,9
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1000-2000.jsonl,ml.g5.48xlarge,8,0.0,1630,259,84,13,33.48,9
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_2000-3000.jsonl,ml.g5.48xlarge,1,0.0,2503,215,78,5,12.54,4
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_2000-3000.jsonl,ml.g5.48xlarge,2,0.0,2503,235,87,7,20.94,5
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_2000-3000.jsonl,ml.g5.48xlarge,4,0.0,2503,254,82,8,34.29,6
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_2000-3000.jsonl,ml.g5.48xlarge,6,0.0,2515,266,76,8,46.62,6
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_2000-3000.jsonl,ml.g5.48xlarge,8,0.41,4342,277,68,4,38.34,3
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_500-1000.jsonl,ml.g5.48xlarge,1,0.0,980,116,102,12,8.38,7
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_500-1000.jsonl,ml.g5.48xlarge,2,0.0,980,168,102,17,11.65,10
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_500-1000.jsonl,ml.g5.48xlarge,4,0.0,980,216,102,22,18.11,13
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_500-1000.jsonl,ml.g5.48xlarge,6,0.0,980,238,88,21,22.33,14
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_500-1000.jsonl,ml.g5.48xlarge,8,0.0,980,218,99,22,21.64,13
