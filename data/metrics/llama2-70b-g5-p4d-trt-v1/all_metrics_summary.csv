experiment_name,payload_file,instance_type,concurrency,error_rate,prompt_token_count_mean,prompt_token_throughput,completion_token_count_mean,completion_token_throughput,latency_mean,transactions_per_minute
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_1-500.jsonl,ml.p4d.24xlarge,1,0.0,304,571,8,15,0.53,112
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_1-500.jsonl,ml.p4d.24xlarge,2,0.0,304,230,101,77,2.62,45
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_1-500.jsonl,ml.p4d.24xlarge,4,0.0,304,404,83,110,2.49,79
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_1-500.jsonl,ml.p4d.24xlarge,6,0.0,304,561,101,187,3.21,111
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_1-500.jsonl,ml.p4d.24xlarge,8,0.0,304,419,101,140,3.02,82
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_1000-2000.jsonl,ml.p4d.24xlarge,1,0.0,1623,1261,83,33,2.33,47
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_1000-2000.jsonl,ml.p4d.24xlarge,2,0.0,1643,1069,79,51,2.5,38
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_1000-2000.jsonl,ml.p4d.24xlarge,4,0.0,1641,1741,90,96,3.4,63
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_1000-2000.jsonl,ml.p4d.24xlarge,6,0.0,1672,2340,90,127,3.91,84
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_1000-2000.jsonl,ml.p4d.24xlarge,8,0.0,1630,2258,78,103,3.46,81
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_2000-3000.jsonl,ml.p4d.24xlarge,1,0.0,2503,1597,89,31,2.68,37
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_2000-3000.jsonl,ml.p4d.24xlarge,2,0.0,2503,1489,70,41,2.5,35
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_2000-3000.jsonl,ml.p4d.24xlarge,4,0.0,2503,2388,77,73,3.44,57
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_2000-3000.jsonl,ml.p4d.24xlarge,6,0.0,2515,3123,74,92,3.96,74
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_2000-3000.jsonl,ml.p4d.24xlarge,8,0.0,2503,3168,73,89,3.9,75
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_3000-4000.jsonl,ml.p4d.24xlarge,1,0.0,3478,2156,80,27,2.65,36
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_3000-4000.jsonl,ml.p4d.24xlarge,2,0.0,3474,1987,77,41,3.03,33
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_3000-4000.jsonl,ml.p4d.24xlarge,4,0.0,3468,2944,70,59,3.73,50
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_3000-4000.jsonl,ml.p4d.24xlarge,6,0.0,3454,3739,64,68,4.33,64
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_3000-4000.jsonl,ml.p4d.24xlarge,8,0.0,3455,4089,70,83,4.59,70
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_500-1000.jsonl,ml.p4d.24xlarge,1,0.0,980,369,102,38,2.65,22
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_500-1000.jsonl,ml.p4d.24xlarge,2,0.0,980,677,101,70,2.88,41
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_500-1000.jsonl,ml.p4d.24xlarge,4,0.0,980,1157,101,119,3.36,70
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_500-1000.jsonl,ml.p4d.24xlarge,6,0.0,980,1631,70,116,2.67,99
llama2-70b-chat-p4d.24xlarge-djl-inference-0.26.0-tensorrtllm0.7.1-cu122,payload_en_500-1000.jsonl,ml.p4d.24xlarge,8,0.0,980,1190,90,110,3.3,73
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1-500.jsonl,ml.g5.48xlarge,1,0.0,304,49,102,16,6.16,9
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1-500.jsonl,ml.g5.48xlarge,2,0.0,304,82,102,27,7.38,16
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1-500.jsonl,ml.g5.48xlarge,4,0.0,304,128,102,43,9.42,25
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1-500.jsonl,ml.g5.48xlarge,6,0.0,304,158,77,40,9.97,31
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1-500.jsonl,ml.g5.48xlarge,8,0.0,304,97,90,28,15.14,19
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1000-2000.jsonl,ml.g5.48xlarge,1,0.0,1623,164,89,8,10.48,5
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1000-2000.jsonl,ml.g5.48xlarge,2,0.0,1643,194,83,9,15.7,6
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1000-2000.jsonl,ml.g5.48xlarge,4,0.0,1641,239,96,14,26.41,8
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1000-2000.jsonl,ml.g5.48xlarge,6,0.0,1672,255,83,12,36.05,9
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1000-2000.jsonl,ml.g5.48xlarge,8,0.0,1630,253,78,12,34.74,9
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_2000-3000.jsonl,ml.g5.48xlarge,1,0.0,2503,217,73,5,12.3,4
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_2000-3000.jsonl,ml.g5.48xlarge,2,0.0,2503,234,78,7,20.33,5
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_2000-3000.jsonl,ml.g5.48xlarge,4,0.0,2503,258,78,8,33.32,5
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_2000-3000.jsonl,ml.g5.48xlarge,6,0.0,2515,270,69,7,45.79,6
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_2000-3000.jsonl,ml.g5.48xlarge,8,0.41,4347,281,43,2,36.14,3
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_3000-4000.jsonl,ml.g5.48xlarge,1,0.0,3478,222,80,4,16.38,3
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_3000-4000.jsonl,ml.g5.48xlarge,2,0.0,3474,249,76,5,26.5,4
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_3000-4000.jsonl,ml.g5.48xlarge,4,0.0,3468,272,73,5,44.09,4
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_3000-4000.jsonl,ml.g5.48xlarge,6,0.82,15714,344,9,0,34.59,0
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_3000-4000.jsonl,ml.g5.48xlarge,8,0.64,10394,290,63,1,40.68,1
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_500-1000.jsonl,ml.g5.48xlarge,1,0.0,980,116,102,12,8.42,7
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_500-1000.jsonl,ml.g5.48xlarge,2,0.0,980,169,102,17,11.55,10
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_500-1000.jsonl,ml.g5.48xlarge,4,0.0,980,215,102,22,18.14,13
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_500-1000.jsonl,ml.g5.48xlarge,6,0.0,980,237,69,16,20.84,14
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_500-1000.jsonl,ml.g5.48xlarge,8,0.0,980,216,92,20,20.79,13
