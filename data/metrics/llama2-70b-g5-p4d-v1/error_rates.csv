experiment_name,payload_file,instance_type,concurrency,error_rate
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1-500.jsonl,ml.g5.48xlarge,1,0.0
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1-500.jsonl,ml.g5.48xlarge,2,0.0
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1-500.jsonl,ml.g5.48xlarge,4,0.0
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1-500.jsonl,ml.g5.48xlarge,6,0.0
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1-500.jsonl,ml.g5.48xlarge,8,0.0
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1000-2000.jsonl,ml.g5.48xlarge,1,0.0
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1000-2000.jsonl,ml.g5.48xlarge,2,0.0
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1000-2000.jsonl,ml.g5.48xlarge,4,0.0
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1000-2000.jsonl,ml.g5.48xlarge,6,0.0
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_1000-2000.jsonl,ml.g5.48xlarge,8,0.0
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_2000-3000.jsonl,ml.g5.48xlarge,1,0.0
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_2000-3000.jsonl,ml.g5.48xlarge,2,0.0
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_2000-3000.jsonl,ml.g5.48xlarge,4,0.0
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_2000-3000.jsonl,ml.g5.48xlarge,6,0.0
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_2000-3000.jsonl,ml.g5.48xlarge,8,0.34
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_3000-4000.jsonl,ml.g5.48xlarge,1,0.0
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_3000-4000.jsonl,ml.g5.48xlarge,2,0.0
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_3000-4000.jsonl,ml.g5.48xlarge,4,0.0
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_3000-4000.jsonl,ml.g5.48xlarge,6,0.72
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_3000-4000.jsonl,ml.g5.48xlarge,8,0.66
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_500-1000.jsonl,ml.g5.48xlarge,1,0.0
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_500-1000.jsonl,ml.g5.48xlarge,2,0.0
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_500-1000.jsonl,ml.g5.48xlarge,4,0.0
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_500-1000.jsonl,ml.g5.48xlarge,6,0.0
llama2-70b-g5.48xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,payload_en_500-1000.jsonl,ml.g5.48xlarge,8,0.0
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_1-500.jsonl,ml.p4d.24xlarge,1,0.0
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_1-500.jsonl,ml.p4d.24xlarge,2,0.0
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_1-500.jsonl,ml.p4d.24xlarge,4,0.0
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_1-500.jsonl,ml.p4d.24xlarge,6,0.0
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_1-500.jsonl,ml.p4d.24xlarge,8,0.0
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_1000-2000.jsonl,ml.p4d.24xlarge,1,0.0
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_1000-2000.jsonl,ml.p4d.24xlarge,2,0.0
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_1000-2000.jsonl,ml.p4d.24xlarge,4,0.0
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_1000-2000.jsonl,ml.p4d.24xlarge,6,0.0
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_1000-2000.jsonl,ml.p4d.24xlarge,8,0.0
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_2000-3000.jsonl,ml.p4d.24xlarge,1,0.0
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_2000-3000.jsonl,ml.p4d.24xlarge,2,0.0
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_2000-3000.jsonl,ml.p4d.24xlarge,4,0.0
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_2000-3000.jsonl,ml.p4d.24xlarge,6,0.0
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_2000-3000.jsonl,ml.p4d.24xlarge,8,0.0
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_3000-4000.jsonl,ml.p4d.24xlarge,1,0.0
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_3000-4000.jsonl,ml.p4d.24xlarge,2,0.0
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_3000-4000.jsonl,ml.p4d.24xlarge,4,0.0
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_3000-4000.jsonl,ml.p4d.24xlarge,6,0.0
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_3000-4000.jsonl,ml.p4d.24xlarge,8,0.0
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_500-1000.jsonl,ml.p4d.24xlarge,1,0.0
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_500-1000.jsonl,ml.p4d.24xlarge,2,0.0
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_500-1000.jsonl,ml.p4d.24xlarge,4,0.0
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_500-1000.jsonl,ml.p4d.24xlarge,6,0.0
llama2-70b-p4d.24xlarge-tgi-inference-2.0.1-tgi0.9.3-gpu-py39-cu118,payload_en_500-1000.jsonl,ml.p4d.24xlarge,8,0.0
