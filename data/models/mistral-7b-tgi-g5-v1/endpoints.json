[
  {
    "experiment_name": "mistral-7b-g5-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0",
    "endpoint": {
      "EndpointName": "lmistral7b-g5-2xlarge-1706037700",
      "EndpointArn": "arn:aws:sagemaker:us-east-1:015469603702:endpoint/lmistral7b-g5-2xlarge-1706037700",
      "EndpointConfigName": "lmistral7b-g5-2xlarge-1706037700",
      "ProductionVariants": [
        {
          "VariantName": "AllTraffic",
          "DeployedImages": [
            {
              "SpecifiedImage": "763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04",
              "ResolvedImage": "763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference@sha256:2739b630b95d8a95e6b4665e66d8243dd43b99c4fdb865feff13aab9c1da06eb",
              "ResolutionTime": "2024-01-23 19:21:42.916000+00:00"
            }
          ],
          "CurrentWeight": 1.0,
          "DesiredWeight": 1.0,
          "CurrentInstanceCount": 1,
          "DesiredInstanceCount": 1
        }
      ],
      "EndpointStatus": "InService",
      "CreationTime": "2024-01-23 19:21:41.849000+00:00",
      "LastModifiedTime": "2024-01-23 19:26:38.869000+00:00",
      "ResponseMetadata": {
        "RequestId": "a6262624-3153-4067-bd2a-27ab95081989",
        "HTTPStatusCode": 200,
        "HTTPHeaders": {
          "x-amzn-requestid": "a6262624-3153-4067-bd2a-27ab95081989",
          "content-type": "application/x-amz-json-1.1",
          "content-length": "809",
          "date": "Tue, 23 Jan 2024 19:26:42 GMT"
        },
        "RetryAttempts": 0
      }
    },
    "endpoint_config": {
      "EndpointConfigName": "lmistral7b-g5-2xlarge-1706037700",
      "EndpointConfigArn": "arn:aws:sagemaker:us-east-1:015469603702:endpoint-config/lmistral7b-g5-2xlarge-1706037700",
      "ProductionVariants": [
        {
          "VariantName": "AllTraffic",
          "ModelName": "hf-llm-mistral-7b-2024-01-23-19-21-40-301",
          "InitialInstanceCount": 1,
          "InstanceType": "ml.g5.2xlarge",
          "InitialVariantWeight": 1.0,
          "ModelDataDownloadTimeoutInSeconds": 1200,
          "ContainerStartupHealthCheckTimeoutInSeconds": 1200
        }
      ],
      "CreationTime": "2024-01-23 19:21:41.466000+00:00",
      "EnableNetworkIsolation": false,
      "ResponseMetadata": {
        "RequestId": "f92e0c54-1f72-4682-8716-38c6eae1ed21",
        "HTTPStatusCode": 200,
        "HTTPHeaders": {
          "x-amzn-requestid": "f92e0c54-1f72-4682-8716-38c6eae1ed21",
          "content-type": "application/x-amz-json-1.1",
          "content-length": "515",
          "date": "Tue, 23 Jan 2024 19:26:42 GMT"
        },
        "RetryAttempts": 0
      }
    },
    "model_config": {
      "ModelName": "hf-llm-mistral-7b-2024-01-23-19-21-40-301",
      "PrimaryContainer": {
        "Image": "763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04",
        "Mode": "SingleModel",
        "ModelDataSource": {
          "S3DataSource": {
            "S3Uri": "s3://jumpstart-cache-prod-us-east-1/huggingface-llm/huggingface-llm-mistral-7b/artifacts/inference-prepack/v1.0.0/",
            "S3DataType": "S3Prefix",
            "CompressionType": "None",
            "ModelAccessConfig": {
              "AcceptEula": true
            }
          }
        },
        "Environment": {
          "ENDPOINT_SERVER_TIMEOUT": "3600",
          "HF_MODEL_ID": "/opt/ml/model",
          "MAX_BATCH_PREFILL_TOKENS": "8191",
          "MAX_INPUT_LENGTH": "8191",
          "MAX_TOTAL_TOKENS": "8192",
          "MODEL_CACHE_ROOT": "/opt/ml/model",
          "SAGEMAKER_ENV": "1",
          "SAGEMAKER_MODEL_SERVER_WORKERS": "1",
          "SAGEMAKER_PROGRAM": "inference.py",
          "SM_NUM_GPUS": "1"
        }
      },
      "ExecutionRoleArn": "arn:aws:iam::015469603702:role/service-role/AmazonSageMaker-ExecutionRole-20231116T132325",
      "CreationTime": "2024-01-23 19:21:40.932000+00:00",
      "ModelArn": "arn:aws:sagemaker:us-east-1:015469603702:model/hf-llm-mistral-7b-2024-01-23-19-21-40-301",
      "EnableNetworkIsolation": true,
      "DeploymentRecommendation": {
        "RecommendationStatus": "COMPLETED",
        "RealTimeInferenceRecommendations": []
      },
      "ResponseMetadata": {
        "RequestId": "fc7ea6d7-0fa9-41fb-911f-44ce941c89ff",
        "HTTPStatusCode": 200,
        "HTTPHeaders": {
          "x-amzn-requestid": "fc7ea6d7-0fa9-41fb-911f-44ce941c89ff",
          "content-type": "application/x-amz-json-1.1",
          "content-length": "1168",
          "date": "Tue, 23 Jan 2024 19:26:43 GMT"
        },
        "RetryAttempts": 0
      }
    }
  }
]