{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference on all deployed endpoints: Various combinations of payloads, concurrency levels, model configurations\n",
    "---------------------\n",
    "*This notebook works best with the conda_python3 kernel on a ml.t3.medium machine*.\n",
    "\n",
    "#### This step of our solution design includes running inferences on all deployed model endpoints (with different configurations, concurrency levels and payload sizes). This notebook runs inferences in a manner that is calls endpoints concurrently and asychronously to generate responses and record metrics. Here are some of the key components:\n",
    "\n",
    "- **Accessing the deployed endpoints**, creating a predictor object for these endpoints to call them during inference time.\n",
    "\n",
    "- **Functions to define metrics**: This notebook sets stage for metrics to be recorded during the time of invocation of all these models for benchmarking purposes.\n",
    "\n",
    "- **Running Actual Inferences**: Once the metrics are defined, we set a blocker function that is responsible for creating inference on a single payload called get_inference. We then run a series of asynchronous functions that can be viewed in the code (link above), to create asychronous inferefences on the deployed models. The way we send requests are by creating combinations: this means creating combinations of payloads of different sizes that can be viewed in the config.yml file, with different concurrency levels (in this case we first go through all patches of payloads with a concurrency level of 1, then 2, and then 4). You can set this to your desired value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all of the necessary libraries below to run this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if interactive mode is set to no -> pickup fmbench from Python installation path\n",
    "# if interactive mode is set to yes -> pickup fmbench from the current path (one level above this notebook)\n",
    "# if interactive mode is not defined -> pickup fmbench from the current path (one level above this notebook)\n",
    "# the premise is that if run non-interactively then it can only be run through main.py which will set interactive mode to no\n",
    "import os\n",
    "import sys\n",
    "if os.environ.get(\"INTERACTIVE_MODE_SET\", \"yes\") == \"yes\":\n",
    "    sys.path.append(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "config file current -> configs/config-distilbert-base-uncased.yml, None\n",
      "Loaded config: {'general': {'name': 'distilbert-base-uncased-v1', 'model_name': 'distilbert-base-uncased'}, 'aws': {'region': 'us-east-1', 'sagemaker_execution_role': 'arn:aws:sts::015469603702:assumed-role/fmbench-role/SageMaker', 'bucket': 'sagemaker-fmbench-write-015469603702'}, 'dir_paths': {'data_prefix': 'data', 'prompts_prefix': 'prompts', 'all_prompts_file': 'all_prompts.csv', 'metrics_dir': 'metrics', 'models_dir': 'models', 'metadata_dir': 'metadata'}, 's3_read_data': {'read_bucket': 'sagemaker-fmbench-read-015469603702', 'scripts_prefix': 'scripts', 'script_files': ['hf_token.txt'], 'source_data_prefix': 'source_data1', 'tokenizer_prefix': 'tokenizer', 'prompt_template_dir': 'prompt_template1', 'prompt_template_file': 'prompt_template.txt'}, 'run_steps': {'1_generate_data.ipynb': True, '2_deploy_model.ipynb': True, '3_run_inference.ipynb': True, '4_model_metric_analysis.ipynb': True, '5_cleanup.ipynb': True}, 'datasets': [{'language': 'en', 'min_length_in_tokens': 1, 'max_length_in_tokens': 500, 'payload_file': 'payload_en_1-500.jsonl'}, {'language': 'en', 'min_length_in_tokens': 500, 'max_length_in_tokens': 1000, 'payload_file': 'payload_en_500-1000.jsonl'}, {'language': 'en', 'min_length_in_tokens': 1000, 'max_length_in_tokens': 2000, 'payload_file': 'payload_en_1000-2000.jsonl'}, {'language': 'en', 'min_length_in_tokens': 2000, 'max_length_in_tokens': 3000, 'payload_file': 'payload_en_2000-3000.jsonl'}, {'language': 'en', 'min_length_in_tokens': 3000, 'max_length_in_tokens': 4000, 'payload_file': 'payload_en_3000-4000.jsonl'}, {'language': 'en', 'min_length_in_tokens': 305, 'max_length_in_tokens': 3997, 'payload_file': 'payload_en_305-3997.jsonl'}, {'language': 'en', 'min_length_in_tokens': 100, 'max_length_in_tokens': 250, 'payload_file': 'payload_en_100-250.jsonl'}, {'language': 'en', 'min_length_in_tokens': 10, 'max_length_in_tokens': 20, 'payload_file': 'payload_en_10-20.jsonl'}, {'language': 'en', 'min_length_in_tokens': 50, 'max_length_in_tokens': 150, 'payload_file': 'payload_en_50-150.jsonl'}], 'dataset': {'prompt_template_keys': ['text']}, 'metrics': {'dataset_of_interest': 'en_50-150', 'weights': {'price_per_tx_wt': 0.65, 'latenct_wt': 0.35}}, 'pricing': {'ml.m5.xlarge': 0.23, 'ml.g5.xlarge': 1.006, 'ml.g5.2xlarge': 1.212, 'ml.g5.12xlarge': 7.09, 'ml.g5.24xlarge': 10.18, 'ml.g5.48xlarge': 20.36, 'ml.inf2.24xlarge': 7.79, 'ml.inf2.48xlarge': 15.58, 'ml.p4d.24xlarge': 37.688, 'ml.p3.2xlarge': 3.825}, 'inference_parameters': {'ContentType': 'application/x-text', 'Accept': 'application/json;verbose'}, 'experiments': [{'name': 'distilbert-base-uncased-ml-p3-2xlarge', 'model_id': 'huggingface-tc-distilbert-base-uncased', 'model_version': '*', 'model_name': 'distilbert-base-uncased', 'ep_name': 'distilbert-base-uncased', 'instance_type': 'ml.p3.2xlarge', 'image_uri': '763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-inference:1.10.2-transformers4.17.0-gpu-py38-cu113-ubuntu20.04', 'deploy': True, 'instance_count': 1, 'deployment_script': 'jumpstart.py', 'inference_script': 'sagemaker_predictor.py', 'payload_files': ['payload_en_50-150.jsonl'], 'concurrency_levels': [1, 2, 4, 6, 8], 'env': {'SAGEMAKER_PROGRAM': 'inference.py', 'ENDPOINT_SERVER_TIMEOUT': '3600', 'MODEL_CACHE_ROOT': '/opt/ml/model', 'SAGEMAKER_ENV': '1', 'SAGEMAKER_MODEL_SERVER_WORKERS': '1'}}], 'results': {'per_inference_request_file': 'per_inference_request_results.csv', 'all_metrics_file': 'all_metrics.csv'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomTokenizer, based on HF transformers\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import time\n",
    "import json\n",
    "import io\n",
    "import copy\n",
    "import boto3\n",
    "import asyncio\n",
    "import logging\n",
    "import itertools\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import importlib.util\n",
    "from fmbench.utils import *\n",
    "from fmbench.globals import * ## add only the vars needed import globals as g.\n",
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "from transformers import AutoTokenizer\n",
    "from sagemaker.predictor import Predictor\n",
    "import importlib.resources as pkg_resources\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from typing import Dict, List, Optional, Tuple, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pygmentize globals.py to view and use any of the globally initialized variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Config.yml file that contains information that is used across this benchmarking environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-18 13:30:10,272] p32749 {635462509.py:2} INFO - {\n",
      "  \"general\": {\n",
      "    \"name\": \"distilbert-base-uncased-v1\",\n",
      "    \"model_name\": \"distilbert-base-uncased\"\n",
      "  },\n",
      "  \"aws\": {\n",
      "    \"region\": \"us-east-1\",\n",
      "    \"sagemaker_execution_role\": \"arn:aws:sts::015469603702:assumed-role/fmbench-role/SageMaker\",\n",
      "    \"bucket\": \"sagemaker-fmbench-write-015469603702\"\n",
      "  },\n",
      "  \"dir_paths\": {\n",
      "    \"data_prefix\": \"data\",\n",
      "    \"prompts_prefix\": \"prompts\",\n",
      "    \"all_prompts_file\": \"all_prompts.csv\",\n",
      "    \"metrics_dir\": \"metrics\",\n",
      "    \"models_dir\": \"models\",\n",
      "    \"metadata_dir\": \"metadata\"\n",
      "  },\n",
      "  \"s3_read_data\": {\n",
      "    \"read_bucket\": \"sagemaker-fmbench-read-015469603702\",\n",
      "    \"scripts_prefix\": \"scripts\",\n",
      "    \"script_files\": [\n",
      "      \"hf_token.txt\"\n",
      "    ],\n",
      "    \"source_data_prefix\": \"source_data1\",\n",
      "    \"tokenizer_prefix\": \"tokenizer\",\n",
      "    \"prompt_template_dir\": \"prompt_template1\",\n",
      "    \"prompt_template_file\": \"prompt_template.txt\"\n",
      "  },\n",
      "  \"run_steps\": {\n",
      "    \"1_generate_data.ipynb\": true,\n",
      "    \"2_deploy_model.ipynb\": true,\n",
      "    \"3_run_inference.ipynb\": true,\n",
      "    \"4_model_metric_analysis.ipynb\": true,\n",
      "    \"5_cleanup.ipynb\": true\n",
      "  },\n",
      "  \"datasets\": [\n",
      "    {\n",
      "      \"language\": \"en\",\n",
      "      \"min_length_in_tokens\": 1,\n",
      "      \"max_length_in_tokens\": 500,\n",
      "      \"payload_file\": \"payload_en_1-500.jsonl\"\n",
      "    },\n",
      "    {\n",
      "      \"language\": \"en\",\n",
      "      \"min_length_in_tokens\": 500,\n",
      "      \"max_length_in_tokens\": 1000,\n",
      "      \"payload_file\": \"payload_en_500-1000.jsonl\"\n",
      "    },\n",
      "    {\n",
      "      \"language\": \"en\",\n",
      "      \"min_length_in_tokens\": 1000,\n",
      "      \"max_length_in_tokens\": 2000,\n",
      "      \"payload_file\": \"payload_en_1000-2000.jsonl\"\n",
      "    },\n",
      "    {\n",
      "      \"language\": \"en\",\n",
      "      \"min_length_in_tokens\": 2000,\n",
      "      \"max_length_in_tokens\": 3000,\n",
      "      \"payload_file\": \"payload_en_2000-3000.jsonl\"\n",
      "    },\n",
      "    {\n",
      "      \"language\": \"en\",\n",
      "      \"min_length_in_tokens\": 3000,\n",
      "      \"max_length_in_tokens\": 4000,\n",
      "      \"payload_file\": \"payload_en_3000-4000.jsonl\"\n",
      "    },\n",
      "    {\n",
      "      \"language\": \"en\",\n",
      "      \"min_length_in_tokens\": 305,\n",
      "      \"max_length_in_tokens\": 3997,\n",
      "      \"payload_file\": \"payload_en_305-3997.jsonl\"\n",
      "    },\n",
      "    {\n",
      "      \"language\": \"en\",\n",
      "      \"min_length_in_tokens\": 100,\n",
      "      \"max_length_in_tokens\": 250,\n",
      "      \"payload_file\": \"payload_en_100-250.jsonl\"\n",
      "    },\n",
      "    {\n",
      "      \"language\": \"en\",\n",
      "      \"min_length_in_tokens\": 10,\n",
      "      \"max_length_in_tokens\": 20,\n",
      "      \"payload_file\": \"payload_en_10-20.jsonl\"\n",
      "    },\n",
      "    {\n",
      "      \"language\": \"en\",\n",
      "      \"min_length_in_tokens\": 50,\n",
      "      \"max_length_in_tokens\": 150,\n",
      "      \"payload_file\": \"payload_en_50-150.jsonl\"\n",
      "    }\n",
      "  ],\n",
      "  \"dataset\": {\n",
      "    \"prompt_template_keys\": [\n",
      "      \"text\"\n",
      "    ]\n",
      "  },\n",
      "  \"metrics\": {\n",
      "    \"dataset_of_interest\": \"en_50-150\",\n",
      "    \"weights\": {\n",
      "      \"price_per_tx_wt\": 0.65,\n",
      "      \"latenct_wt\": 0.35\n",
      "    }\n",
      "  },\n",
      "  \"pricing\": {\n",
      "    \"ml.m5.xlarge\": 0.23,\n",
      "    \"ml.g5.xlarge\": 1.006,\n",
      "    \"ml.g5.2xlarge\": 1.212,\n",
      "    \"ml.g5.12xlarge\": 7.09,\n",
      "    \"ml.g5.24xlarge\": 10.18,\n",
      "    \"ml.g5.48xlarge\": 20.36,\n",
      "    \"ml.inf2.24xlarge\": 7.79,\n",
      "    \"ml.inf2.48xlarge\": 15.58,\n",
      "    \"ml.p4d.24xlarge\": 37.688,\n",
      "    \"ml.p3.2xlarge\": 3.825\n",
      "  },\n",
      "  \"inference_parameters\": {\n",
      "    \"ContentType\": \"application/x-text\",\n",
      "    \"Accept\": \"application/json;verbose\"\n",
      "  },\n",
      "  \"experiments\": [\n",
      "    {\n",
      "      \"name\": \"distilbert-base-uncased-ml-p3-2xlarge\",\n",
      "      \"model_id\": \"huggingface-tc-distilbert-base-uncased\",\n",
      "      \"model_version\": \"*\",\n",
      "      \"model_name\": \"distilbert-base-uncased\",\n",
      "      \"ep_name\": \"distilbert-base-uncased\",\n",
      "      \"instance_type\": \"ml.p3.2xlarge\",\n",
      "      \"image_uri\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-inference:1.10.2-transformers4.17.0-gpu-py38-cu113-ubuntu20.04\",\n",
      "      \"deploy\": true,\n",
      "      \"instance_count\": 1,\n",
      "      \"deployment_script\": \"jumpstart.py\",\n",
      "      \"inference_script\": \"sagemaker_predictor.py\",\n",
      "      \"payload_files\": [\n",
      "        \"payload_en_50-150.jsonl\"\n",
      "      ],\n",
      "      \"concurrency_levels\": [\n",
      "        1,\n",
      "        2,\n",
      "        4,\n",
      "        6,\n",
      "        8\n",
      "      ],\n",
      "      \"env\": {\n",
      "        \"SAGEMAKER_PROGRAM\": \"inference.py\",\n",
      "        \"ENDPOINT_SERVER_TIMEOUT\": \"3600\",\n",
      "        \"MODEL_CACHE_ROOT\": \"/opt/ml/model\",\n",
      "        \"SAGEMAKER_ENV\": \"1\",\n",
      "        \"SAGEMAKER_MODEL_SERVER_WORKERS\": \"1\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"results\": {\n",
      "    \"per_inference_request_file\": \"per_inference_request_results.csv\",\n",
      "    \"all_metrics_file\": \"all_metrics.csv\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "config = load_config(CONFIG_FILE)\n",
    "logger.info(json.dumps(config, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "date_time = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## getting access to the s3 bucket where endpoints.json for different models resides\n",
    "s3_client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access the deployed model endpoints from the endpoints.json file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-18 13:30:10,358] p32749 {3784763608.py:4} INFO - found information for 1 endpoints in bucket=sagemaker-fmbench-write-015469603702, key=distilbert-base-uncased-v1-SageMaker/data/models/endpoints.json\n",
      "[2024-03-18 13:30:10,359] p32749 {3784763608.py:5} INFO - [\n",
      "  {\n",
      "    \"experiment_name\": \"distilbert-base-uncased-ml-p3-2xlarge\",\n",
      "    \"endpoint\": {\n",
      "      \"EndpointName\": \"distilbert-base-uncased-1710719092\",\n",
      "      \"EndpointArn\": \"arn:aws:sagemaker:us-east-1:015469603702:endpoint/distilbert-base-uncased-1710719092\",\n",
      "      \"EndpointConfigName\": \"distilbert-base-uncased-1710719092\",\n",
      "      \"ProductionVariants\": [\n",
      "        {\n",
      "          \"VariantName\": \"AllTraffic\",\n",
      "          \"DeployedImages\": [\n",
      "            {\n",
      "              \"SpecifiedImage\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-inference:1.10.2-transformers4.17.0-gpu-py38-cu113-ubuntu20.04\",\n",
      "              \"ResolvedImage\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-inference@sha256:17e776fd3295cc6dfee4e122618f5bab7ef04e87ed0490ce6b64722a60f03333\",\n",
      "              \"ResolutionTime\": \"2024-03-17 23:44:54.981000+00:00\"\n",
      "            }\n",
      "          ],\n",
      "          \"CurrentWeight\": 1.0,\n",
      "          \"DesiredWeight\": 1.0,\n",
      "          \"CurrentInstanceCount\": 1,\n",
      "          \"DesiredInstanceCount\": 1\n",
      "        }\n",
      "      ],\n",
      "      \"EndpointStatus\": \"InService\",\n",
      "      \"CreationTime\": \"2024-03-17 23:44:54.208000+00:00\",\n",
      "      \"LastModifiedTime\": \"2024-03-17 23:49:02.927000+00:00\",\n",
      "      \"ResponseMetadata\": {\n",
      "        \"RequestId\": \"6ab02b4b-b1ca-4451-8e44-ff52332c358e\",\n",
      "        \"HTTPStatusCode\": 200,\n",
      "        \"HTTPHeaders\": {\n",
      "          \"x-amzn-requestid\": \"6ab02b4b-b1ca-4451-8e44-ff52332c358e\",\n",
      "          \"content-type\": \"application/x-amz-json-1.1\",\n",
      "          \"content-length\": \"818\",\n",
      "          \"date\": \"Sun, 17 Mar 2024 23:49:25 GMT\"\n",
      "        },\n",
      "        \"RetryAttempts\": 0\n",
      "      }\n",
      "    },\n",
      "    \"endpoint_config\": {\n",
      "      \"EndpointConfigName\": \"distilbert-base-uncased-1710719092\",\n",
      "      \"EndpointConfigArn\": \"arn:aws:sagemaker:us-east-1:015469603702:endpoint-config/distilbert-base-uncased-1710719092\",\n",
      "      \"ProductionVariants\": [\n",
      "        {\n",
      "          \"VariantName\": \"AllTraffic\",\n",
      "          \"ModelName\": \"hf-tc-distilbert-base-uncased-2024-03-17-23-44-52-620\",\n",
      "          \"InitialInstanceCount\": 1,\n",
      "          \"InstanceType\": \"ml.p3.2xlarge\",\n",
      "          \"InitialVariantWeight\": 1.0\n",
      "        }\n",
      "      ],\n",
      "      \"CreationTime\": \"2024-03-17 23:44:53.747000+00:00\",\n",
      "      \"EnableNetworkIsolation\": false,\n",
      "      \"ResponseMetadata\": {\n",
      "        \"RequestId\": \"1c124dbf-4165-47e3-9aaf-411add27eb2e\",\n",
      "        \"HTTPStatusCode\": 200,\n",
      "        \"HTTPHeaders\": {\n",
      "          \"x-amzn-requestid\": \"1c124dbf-4165-47e3-9aaf-411add27eb2e\",\n",
      "          \"content-type\": \"application/x-amz-json-1.1\",\n",
      "          \"content-length\": \"439\",\n",
      "          \"date\": \"Sun, 17 Mar 2024 23:49:25 GMT\"\n",
      "        },\n",
      "        \"RetryAttempts\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_config\": {\n",
      "      \"ModelName\": \"hf-tc-distilbert-base-uncased-2024-03-17-23-44-52-620\",\n",
      "      \"PrimaryContainer\": {\n",
      "        \"Image\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-inference:1.10.2-transformers4.17.0-gpu-py38-cu113-ubuntu20.04\",\n",
      "        \"Mode\": \"SingleModel\",\n",
      "        \"ModelDataSource\": {\n",
      "          \"S3DataSource\": {\n",
      "            \"S3Uri\": \"s3://jumpstart-cache-prod-us-east-1/huggingface-tc/huggingface-tc-distilbert-base-uncased/artifacts/inference-prepack/v1.0.0/\",\n",
      "            \"S3DataType\": \"S3Prefix\",\n",
      "            \"CompressionType\": \"None\"\n",
      "          }\n",
      "        },\n",
      "        \"Environment\": {\n",
      "          \"ENDPOINT_SERVER_TIMEOUT\": \"3600\",\n",
      "          \"MODEL_CACHE_ROOT\": \"/opt/ml/model\",\n",
      "          \"SAGEMAKER_ENV\": \"1\",\n",
      "          \"SAGEMAKER_MODEL_SERVER_WORKERS\": \"1\",\n",
      "          \"SAGEMAKER_PROGRAM\": \"inference.py\"\n",
      "        }\n",
      "      },\n",
      "      \"ExecutionRoleArn\": \"arn:aws:iam::015469603702:role/fmbench-role\",\n",
      "      \"CreationTime\": \"2024-03-17 23:44:53.262000+00:00\",\n",
      "      \"ModelArn\": \"arn:aws:sagemaker:us-east-1:015469603702:model/hf-tc-distilbert-base-uncased-2024-03-17-23-44-52-620\",\n",
      "      \"EnableNetworkIsolation\": true,\n",
      "      \"DeploymentRecommendation\": {\n",
      "        \"RecommendationStatus\": \"COMPLETED\",\n",
      "        \"RealTimeInferenceRecommendations\": [\n",
      "          {\n",
      "            \"RecommendationId\": \"hf-tc-distilbert-base-uncased-2024-03-17-23-44-52-620/8DvMpqyj\",\n",
      "            \"InstanceType\": \"ml.g4dn.2xlarge\",\n",
      "            \"Environment\": {}\n",
      "          },\n",
      "          {\n",
      "            \"RecommendationId\": \"hf-tc-distilbert-base-uncased-2024-03-17-23-44-52-620/Ffw0gLZ0\",\n",
      "            \"InstanceType\": \"ml.c5.large\",\n",
      "            \"Environment\": {}\n",
      "          },\n",
      "          {\n",
      "            \"RecommendationId\": \"hf-tc-distilbert-base-uncased-2024-03-17-23-44-52-620/1YqudRgh\",\n",
      "            \"InstanceType\": \"ml.c5.2xlarge\",\n",
      "            \"Environment\": {}\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"ResponseMetadata\": {\n",
      "        \"RequestId\": \"afbfa15c-ad82-4bae-a810-df550db1e56c\",\n",
      "        \"HTTPStatusCode\": 200,\n",
      "        \"HTTPHeaders\": {\n",
      "          \"x-amzn-requestid\": \"afbfa15c-ad82-4bae-a810-df550db1e56c\",\n",
      "          \"content-type\": \"application/x-amz-json-1.1\",\n",
      "          \"content-length\": \"1391\",\n",
      "          \"date\": \"Sun, 17 Mar 2024 23:49:25 GMT\"\n",
      "        },\n",
      "        \"RetryAttempts\": 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "## Refer to the file path for the endpoint\n",
    "## getting the endpoint as an s3 object from the deployed path\n",
    "endpoint_info_list = json.loads(get_s3_object(config['aws']['bucket'], ENDPOINT_LIST_PATH))\n",
    "logger.info(f\"found information for {len(endpoint_info_list)} endpoints in bucket={config['aws']['bucket']}, key={ENDPOINT_LIST_PATH}\")\n",
    "logger.info(json.dumps(endpoint_info_list, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-18 13:30:10,367] p32749 {1455142584.py:3} INFO - there are 1 deployed endpoint(s), endpoint_name_list->['distilbert-base-uncased-1710719092']\n"
     ]
    }
   ],
   "source": [
    "# List down the endpoint names that have been deployed\n",
    "endpoint_name_list = [e['endpoint']['EndpointName'] for e in endpoint_info_list]\n",
    "logger.info(f\"there are {len(endpoint_name_list)} deployed endpoint(s), endpoint_name_list->{endpoint_name_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating functions to define and calculate metrics during the time of invocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def safe_sum(l: List) -> Union[int, float]:\n",
    "    return sum(filter(None, l))\n",
    "\n",
    "def safe_div(n: Union[int, float], d: Union[int, float]) -> Optional[Union[int, float]]:\n",
    "    return n/d if d else None\n",
    "\n",
    "## Represents the function to calculate all of the metrics at the time of inference\n",
    "def calculate_metrics(responses, chunk, elapsed_async, experiment_name, concurrency, payload_file) -> Dict:\n",
    "    \n",
    "    ## calculate errors based on the completion status of the inference prompt\n",
    "    errors = [r for r in responses if r['completion'] is None]\n",
    "    \n",
    "    ## Calculate the difference as the successes \n",
    "    successes = len(chunk) - len(errors)\n",
    "    \n",
    "    ## Count all of the prompts token count during inference\n",
    "    all_prompts_token_count = safe_sum([r['prompt_tokens'] for r in responses])\n",
    "    prompt_token_throughput = round(all_prompts_token_count / elapsed_async, 2)\n",
    "    prompt_token_count_mean = safe_div(all_prompts_token_count, successes)\n",
    "    all_completions_token_count = safe_sum([r['completion_tokens'] for r in responses])\n",
    "    completion_token_throughput = round(all_completions_token_count / elapsed_async, 2)\n",
    "    completion_token_count_mean = safe_div(all_completions_token_count, successes)\n",
    "    transactions_per_second = round(successes / elapsed_async, 2)\n",
    "    transactions_per_minute = int(transactions_per_second * 60)\n",
    "    \n",
    "    ## calculate the latency mean utilizing the safe_sum function defined above\n",
    "    latency_mean = safe_div(safe_sum([r['latency'] for r in responses]), successes)\n",
    "    \n",
    "    ## Function returns all these values at the time of the invocations\n",
    "    return {\n",
    "        'experiment_name': experiment_name,\n",
    "        'concurrency': concurrency,\n",
    "        'payload_file': payload_file,\n",
    "        'errors': errors,\n",
    "        'successes': successes,\n",
    "        'error_rate': len(errors)/len(chunk),\n",
    "        'all_prompts_token_count': all_prompts_token_count,\n",
    "        'prompt_token_count_mean': prompt_token_count_mean,\n",
    "        'prompt_token_throughput': prompt_token_throughput,\n",
    "        'all_completions_token_count': all_completions_token_count,\n",
    "        'completion_token_count_mean': completion_token_count_mean,\n",
    "        'completion_token_throughput': completion_token_throughput,\n",
    "        'transactions': len(chunk),\n",
    "        'transactions_per_second': transactions_per_second,\n",
    "        'transactions_per_minute': transactions_per_minute,\n",
    "        'latency_mean': latency_mean\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set a blocker function and a series of asynchronous concurrent model prompt invocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_metrics(endpoint_name=None,\n",
    "                    prompt=None,\n",
    "                    inference_params=None,\n",
    "                    completion=None,\n",
    "                    prompt_tokens=None,\n",
    "                    completion_tokens=None,\n",
    "                    latency=None) -> Dict:\n",
    "    return dict(endpoint_name=endpoint_name,                \n",
    "                prompt=prompt,\n",
    "                **inference_params,\n",
    "                completion=completion,\n",
    "                prompt_tokens=prompt_tokens,\n",
    "                completion_tokens=completion_tokens,\n",
    "                latency=latency)\n",
    "\n",
    "def get_inference(predictor, payload) -> Dict:\n",
    "    \n",
    "    latency = 0\n",
    "\n",
    "    try:\n",
    "        prompt_tokens = count_tokens(payload['inputs'])\n",
    "        logger.info(f\"get_inference, endpoint={predictor.endpoint_name}, prompt_tokens={prompt_tokens}\")\n",
    "\n",
    "        # get inference      \n",
    "        resp = predictor.get_prediction(payload) \n",
    "        response_json = resp['response_json']\n",
    "        latency = resp['latency']\n",
    "\n",
    "        completion = response_json.get(\"generated_text\", \"\")\n",
    "        completion_tokens = count_tokens(completion)\n",
    "\n",
    "        # Set metrics and logging for both cases\n",
    "        response = set_metrics(predictor.endpoint_name,\n",
    "                               payload['inputs'],\n",
    "                               payload['parameters'],\n",
    "                               completion,\n",
    "                               prompt_tokens,\n",
    "                               completion_tokens,\n",
    "                               latency)\n",
    "        # logger.info(f\"get_inference, done, endpoint={predictor.endpoint_name}, response={json.dumps(response, indent=2)}, latency={latency:.2f}\")\n",
    "        logger.info(f\"get_inference, done, endpoint={predictor.endpoint_name}, completion_tokens={completion_tokens}, latency={latency:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"error occurred with {predictor.endpoint_name}, exception={str(e)}\")\n",
    "        response = set_metrics(predictor.endpoint_name,\n",
    "                               payload['inputs'],\n",
    "                               payload['parameters'],\n",
    "                               None,\n",
    "                               prompt_tokens,\n",
    "                               None,\n",
    "                               None)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting a series of asynchronous functions to invoke and run inferences concurrently and asynchronously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Represents a function to start invoking models in separate thread asynchronously for the blocker function\n",
    "async def async_get_inference(predictor, payload: Dict) -> Dict:\n",
    "    return await asyncio.to_thread(get_inference, predictor, payload)\n",
    "\n",
    "## Gathers all of the tasks and sets of the concurrent calling of the asychronous invocations\n",
    "async def async_get_all_inferences(predictor, payload_list: List) -> List:\n",
    "    return await asyncio.gather(*[async_get_inference(predictor, payload) for payload in payload_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## This function runs the asynchronous function series above together for different experiments and concurrency levels.\n",
    "async def run_inferences(predictor: sagemaker.base_predictor.Predictor, chunk: List, experiment: Dict, concurrency: int, payload_file: str) -> Tuple[List, Dict]:\n",
    "    logger.info(f\"processing chunk with concurrency={concurrency}\")\n",
    "    s = time.perf_counter()\n",
    "    responses = await async_get_all_inferences(predictor, chunk)\n",
    "    elapsed_async = time.perf_counter() - s\n",
    "\n",
    "    # Add more metadata about this experiment\n",
    "    for r in responses:\n",
    "        r['experiment_name'] = experiment['name']\n",
    "        r['concurrency'] = concurrency\n",
    "\n",
    "    metrics = calculate_metrics(responses, chunk, elapsed_async, experiment['name'], concurrency, payload_file)\n",
    "    return responses, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Function to create the predictors from the experiment we are iterating over\n",
    "def create_predictor_for_experiment(experiment: Dict, config: Dict, endpoint_info_list: List) -> Optional[sagemaker.base_predictor.Predictor]:\n",
    "\n",
    "    ## Iterate through the endpoint information to fetch the endpoint name\n",
    "    ep_info = [e for e in endpoint_info_list if e['experiment_name'] == experiment['name']]\n",
    "    if not ep_info:\n",
    "        logger.error(f\"endpoint for experiment={experiment['name']} not found, skipping\")\n",
    "        return None\n",
    "    ep_name = ep_info[0]['endpoint']['EndpointName']\n",
    "    logger.info(f\"experiment name={experiment['name']}, ep_name={ep_name}\")\n",
    "\n",
    "    # create predictor objects\n",
    "    # Proceed with deployment as before\n",
    "    # Assuming fmbench is a valid Python package and scripts is a subdirectory within it\n",
    "    scripts_dir = Path(pkg_resources.files('fmbench'), 'scripts')\n",
    "    logger.info(f\"Using fmbench.scripts directory: {scripts_dir}\")\n",
    "\n",
    "    # Ensure the scripts directory exists\n",
    "    scripts_dir.mkdir(parents=True, exist_ok=True)\n",
    "    module_name = Path(experiment['inference_script']).stem\n",
    "    logger.info(f\"script provided for inference from this model is --> {module_name}\")\n",
    "    script_path = scripts_dir / f\"{module_name}.py\"\n",
    "    logger.info(f\"script path is --> {script_path}\")\n",
    "\n",
    "    # Check and proceed with local script\n",
    "    if not script_path.exists():\n",
    "        logger.error(f\"script {script_path} not found.\")\n",
    "        return None\n",
    "\n",
    "    logger.info(f\"Deploying using local code: {script_path}\")\n",
    "\n",
    "    spec = importlib.util.spec_from_file_location(module_name, str(script_path))\n",
    "    inference_module = importlib.util.module_from_spec(spec)\n",
    "    sys.modules[module_name] = inference_module\n",
    "    spec.loader.exec_module(inference_module)\n",
    "    # create a predictor from each endpoint in experiments\n",
    "    return inference_module.create_predictor(ep_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Here, we will process combinations of concurrency levels, the payload files and then loop through the \n",
    "## different combinations to make payloads splitted in terms of the concurrency metric and how we can run \n",
    "## it and make inference\n",
    "\n",
    "def create_payload_dict(jline: str, experiment: Dict) -> Dict:\n",
    "    payload: Dict = json.loads(jline)\n",
    "    if experiment.get('remove_truncate', False) is True:\n",
    "        if payload['parameters'].get('truncate'):\n",
    "            del payload['parameters']['truncate']\n",
    "    return payload\n",
    "    \n",
    "    \n",
    "def create_combinations(experiment: Dict) -> List[Tuple]:\n",
    "    combinations_data = []\n",
    "\n",
    "    # Repeat for each concurrency level\n",
    "    combinations = list(itertools.product(experiment['concurrency_levels'], experiment['payload_files']))\n",
    "    logger.info(f\"there are {len(combinations)} combinations of {combinations} to run\")\n",
    "\n",
    "    for concurrency, payload_file in combinations:\n",
    "        # Construct the full S3 file path\n",
    "        s3_file_path = os.path.join(PROMPTS_DIR, payload_file)\n",
    "        logger.info(f\"s3 path where the payload files are being read from -> {s3_file_path}\")\n",
    "\n",
    "        # Read the payload file from S3\n",
    "        try:\n",
    "            response = s3_client.get_object(Bucket=config['aws']['bucket'], Key=s3_file_path)\n",
    "            payload_file_content = response['Body'].read().decode('utf-8')\n",
    "\n",
    "            # Create a payload list by processing each line\n",
    "            payload_list = [create_payload_dict(jline, experiment) for jline in payload_file_content.splitlines()]\n",
    "            logger.info(f\"read from s3://{config['aws']['bucket']}/{s3_file_path}, contains {len(payload_list)} lines\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading file from S3: {e}\")\n",
    "            continue\n",
    "\n",
    "        logger.info(f\"creating combinations for concurrency={concurrency}, payload_file={payload_file}, payload_list length={len(payload_list)}\")\n",
    "        \n",
    "        n = concurrency\n",
    "        \n",
    "        if len(payload_list) < n:\n",
    "            elements_to_add = n - len(payload_list)\n",
    "            element_to_replicate = payload_list[0]\n",
    "            # payload_list = payload_list.extend([element_to_replicate]*elements_to_add)\n",
    "            payload_list.extend([element_to_replicate]*elements_to_add)\n",
    "            \n",
    "        # Split the original list into sublists which contain the number of requests we want to send concurrently        \n",
    "        payload_list_splitted = [payload_list[i * n:(i + 1) * n] for i in range((len(payload_list) + n - 1) // n )]  \n",
    "        \n",
    "        for p in payload_list_splitted:\n",
    "            if len(p) < n:\n",
    "                elements_to_add = n - len(p)\n",
    "                element_to_replicate = p[0]\n",
    "                # p = p.extend([element_to_replicate]*elements_to_add)\n",
    "                p.extend([element_to_replicate]*elements_to_add)\n",
    "            \n",
    "\n",
    "        # Only keep lists that have at least concurrency number of elements\n",
    "        len_before = len(payload_list_splitted)\n",
    "        payload_list_splitted = [p for p in payload_list_splitted if len(p) == concurrency]\n",
    "        logger.info(f\"after only retaining chunks of length {concurrency}, we have {len(payload_list_splitted)} chunks, previously we had {len_before} chunks\")\n",
    "        combinations_data.append((concurrency, payload_file, payload_list_splitted))\n",
    "    logger.info(f\"there are {len(combinations)} for {experiment}\")\n",
    "    return combinations_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-18 13:30:10,445] p32749 {295706451.py:23} INFO - Current time recorded while running this experiment is 2024-03-18 13:30:10.445761+00:00..... deployed models are going to start inferences...\n",
      "[2024-03-18 13:30:10,447] p32749 {2734306530.py:10} INFO - experiment name=distilbert-base-uncased-ml-p3-2xlarge, ep_name=distilbert-base-uncased-1710719092\n",
      "[2024-03-18 13:30:10,452] p32749 {2734306530.py:16} INFO - Using fmbench.scripts directory: /home/ec2-user/SageMaker/repos2/foundation-model-benchmarking-tool/src/fmbench/scripts\n",
      "[2024-03-18 13:30:10,453] p32749 {2734306530.py:21} INFO - script provided for inference from this model is --> sagemaker_predictor\n",
      "[2024-03-18 13:30:10,455] p32749 {2734306530.py:23} INFO - script path is --> /home/ec2-user/SageMaker/repos2/foundation-model-benchmarking-tool/src/fmbench/scripts/sagemaker_predictor.py\n",
      "[2024-03-18 13:30:10,457] p32749 {2734306530.py:30} INFO - Deploying using local code: /home/ec2-user/SageMaker/repos2/foundation-model-benchmarking-tool/src/fmbench/scripts/sagemaker_predictor.py\n",
      "[2024-03-18 13:30:10,673] p32749 {sagemaker_predictor.py:46} INFO - __init__ self._predictor=Predictor: {'endpoint_name': 'distilbert-base-uncased-1710719092', 'sagemaker_session': <sagemaker.session.Session object at 0x7f8c42baf8d0>, 'serializer': <sagemaker.base_serializers.JSONSerializer object at 0x7f8c42ba4950>, 'deserializer': <sagemaker.base_deserializers.BytesDeserializer object at 0x7f8c46d99310>}\n",
      "[2024-03-18 13:30:10,673] p32749 {2049168958.py:18} INFO - there are 5 combinations of [(1, 'payload_en_50-150.jsonl'), (2, 'payload_en_50-150.jsonl'), (4, 'payload_en_50-150.jsonl'), (6, 'payload_en_50-150.jsonl'), (8, 'payload_en_50-150.jsonl')] to run\n",
      "[2024-03-18 13:30:10,674] p32749 {2049168958.py:23} INFO - s3 path where the payload files are being read from -> distilbert-base-uncased-v1-SageMaker/data/prompts/payload_en_50-150.jsonl\n",
      "[2024-03-18 13:30:10,712] p32749 {2049168958.py:32} INFO - read from s3://sagemaker-fmbench-write-015469603702/distilbert-base-uncased-v1-SageMaker/data/prompts/payload_en_50-150.jsonl, contains 154 lines\n",
      "[2024-03-18 13:30:10,713] p32749 {2049168958.py:38} INFO - creating combinations for concurrency=1, payload_file=payload_en_50-150.jsonl, payload_list length=154\n",
      "[2024-03-18 13:30:10,714] p32749 {2049168958.py:62} INFO - after only retaining chunks of length 1, we have 154 chunks, previously we had 154 chunks\n",
      "[2024-03-18 13:30:10,715] p32749 {2049168958.py:23} INFO - s3 path where the payload files are being read from -> distilbert-base-uncased-v1-SageMaker/data/prompts/payload_en_50-150.jsonl\n",
      "[2024-03-18 13:30:10,746] p32749 {2049168958.py:32} INFO - read from s3://sagemaker-fmbench-write-015469603702/distilbert-base-uncased-v1-SageMaker/data/prompts/payload_en_50-150.jsonl, contains 154 lines\n",
      "[2024-03-18 13:30:10,746] p32749 {2049168958.py:38} INFO - creating combinations for concurrency=2, payload_file=payload_en_50-150.jsonl, payload_list length=154\n",
      "[2024-03-18 13:30:10,747] p32749 {2049168958.py:62} INFO - after only retaining chunks of length 2, we have 77 chunks, previously we had 77 chunks\n",
      "[2024-03-18 13:30:10,748] p32749 {2049168958.py:23} INFO - s3 path where the payload files are being read from -> distilbert-base-uncased-v1-SageMaker/data/prompts/payload_en_50-150.jsonl\n",
      "[2024-03-18 13:30:10,761] p32749 {2049168958.py:32} INFO - read from s3://sagemaker-fmbench-write-015469603702/distilbert-base-uncased-v1-SageMaker/data/prompts/payload_en_50-150.jsonl, contains 154 lines\n",
      "[2024-03-18 13:30:10,762] p32749 {2049168958.py:38} INFO - creating combinations for concurrency=4, payload_file=payload_en_50-150.jsonl, payload_list length=154\n",
      "[2024-03-18 13:30:10,763] p32749 {2049168958.py:62} INFO - after only retaining chunks of length 4, we have 39 chunks, previously we had 39 chunks\n",
      "[2024-03-18 13:30:10,763] p32749 {2049168958.py:23} INFO - s3 path where the payload files are being read from -> distilbert-base-uncased-v1-SageMaker/data/prompts/payload_en_50-150.jsonl\n",
      "[2024-03-18 13:30:10,780] p32749 {2049168958.py:32} INFO - read from s3://sagemaker-fmbench-write-015469603702/distilbert-base-uncased-v1-SageMaker/data/prompts/payload_en_50-150.jsonl, contains 154 lines\n",
      "[2024-03-18 13:30:10,781] p32749 {2049168958.py:38} INFO - creating combinations for concurrency=6, payload_file=payload_en_50-150.jsonl, payload_list length=154\n",
      "[2024-03-18 13:30:10,781] p32749 {2049168958.py:62} INFO - after only retaining chunks of length 6, we have 26 chunks, previously we had 26 chunks\n",
      "[2024-03-18 13:30:10,782] p32749 {2049168958.py:23} INFO - s3 path where the payload files are being read from -> distilbert-base-uncased-v1-SageMaker/data/prompts/payload_en_50-150.jsonl\n",
      "[2024-03-18 13:30:10,796] p32749 {2049168958.py:32} INFO - read from s3://sagemaker-fmbench-write-015469603702/distilbert-base-uncased-v1-SageMaker/data/prompts/payload_en_50-150.jsonl, contains 154 lines\n",
      "[2024-03-18 13:30:10,797] p32749 {2049168958.py:38} INFO - creating combinations for concurrency=8, payload_file=payload_en_50-150.jsonl, payload_list length=154\n",
      "[2024-03-18 13:30:10,798] p32749 {2049168958.py:62} INFO - after only retaining chunks of length 8, we have 20 chunks, previously we had 20 chunks\n",
      "[2024-03-18 13:30:10,798] p32749 {2049168958.py:64} INFO - there are 5 for {'name': 'distilbert-base-uncased-ml-p3-2xlarge', 'model_id': 'huggingface-tc-distilbert-base-uncased', 'model_version': '*', 'model_name': 'distilbert-base-uncased', 'ep_name': 'distilbert-base-uncased', 'instance_type': 'ml.p3.2xlarge', 'image_uri': '763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-inference:1.10.2-transformers4.17.0-gpu-py38-cu113-ubuntu20.04', 'deploy': True, 'instance_count': 1, 'deployment_script': 'jumpstart.py', 'inference_script': 'sagemaker_predictor.py', 'payload_files': ['payload_en_50-150.jsonl'], 'concurrency_levels': [1, 2, 4, 6, 8], 'env': {'SAGEMAKER_PROGRAM': 'inference.py', 'ENDPOINT_SERVER_TIMEOUT': '3600', 'MODEL_CACHE_ROOT': '/opt/ml/model', 'SAGEMAKER_ENV': '1', 'SAGEMAKER_MODEL_SERVER_WORKERS': '1'}}\n",
      "[2024-03-18 13:30:10,799] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=1/154\n",
      "[2024-03-18 13:30:10,800] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:10,803] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:30:10,871] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0667\n",
      "[2024-03-18 13:30:11,023] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=2/154\n",
      "[2024-03-18 13:30:11,025] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:11,026] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=77\n",
      "[2024-03-18 13:30:11,042] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0147\n",
      "[2024-03-18 13:30:11,177] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=3/154\n",
      "[2024-03-18 13:30:11,178] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:11,181] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=62\n",
      "[2024-03-18 13:30:11,196] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0141\n",
      "[2024-03-18 13:30:11,349] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=4/154\n",
      "[2024-03-18 13:30:11,350] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:11,351] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:30:11,366] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0142\n",
      "[2024-03-18 13:30:11,575] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=5/154\n",
      "[2024-03-18 13:30:11,576] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:11,578] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:30:11,592] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0139\n",
      "[2024-03-18 13:30:11,715] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=6/154\n",
      "[2024-03-18 13:30:11,716] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:11,717] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=82\n",
      "[2024-03-18 13:30:11,732] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0133\n",
      "[2024-03-18 13:30:11,907] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=7/154\n",
      "[2024-03-18 13:30:11,908] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:11,909] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:30:11,924] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0144\n",
      "[2024-03-18 13:30:12,156] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=8/154\n",
      "[2024-03-18 13:30:12,157] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:12,159] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:30:12,174] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0140\n",
      "[2024-03-18 13:30:12,384] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=9/154\n",
      "[2024-03-18 13:30:12,385] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:12,387] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=69\n",
      "[2024-03-18 13:30:12,402] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0147\n",
      "[2024-03-18 13:30:12,572] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=10/154\n",
      "[2024-03-18 13:30:12,574] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:12,575] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=60\n",
      "[2024-03-18 13:30:12,590] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0139\n",
      "[2024-03-18 13:30:12,748] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=11/154\n",
      "[2024-03-18 13:30:12,750] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:12,751] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:30:12,765] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0137\n",
      "[2024-03-18 13:30:12,957] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=12/154\n",
      "[2024-03-18 13:30:12,958] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:12,959] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:30:12,975] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0147\n",
      "[2024-03-18 13:30:13,126] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=13/154\n",
      "[2024-03-18 13:30:13,127] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:13,129] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=65\n",
      "[2024-03-18 13:30:13,144] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0140\n",
      "[2024-03-18 13:30:13,294] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=14/154\n",
      "[2024-03-18 13:30:13,295] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:13,297] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=75\n",
      "[2024-03-18 13:30:13,313] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0146\n",
      "[2024-03-18 13:30:13,489] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=15/154\n",
      "[2024-03-18 13:30:13,490] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:13,492] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=57\n",
      "[2024-03-18 13:30:13,508] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0138\n",
      "[2024-03-18 13:30:13,678] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=16/154\n",
      "[2024-03-18 13:30:13,680] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:13,681] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:30:13,695] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0140\n",
      "[2024-03-18 13:30:13,883] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=17/154\n",
      "[2024-03-18 13:30:13,884] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:13,886] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:30:13,900] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0137\n",
      "[2024-03-18 13:30:14,141] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=18/154\n",
      "[2024-03-18 13:30:14,143] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:14,144] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:30:14,159] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0140\n",
      "[2024-03-18 13:30:14,340] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=19/154\n",
      "[2024-03-18 13:30:14,341] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:14,343] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:30:14,359] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0145\n",
      "[2024-03-18 13:30:14,566] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=20/154\n",
      "[2024-03-18 13:30:14,567] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:14,569] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:30:14,583] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0140\n",
      "[2024-03-18 13:30:14,761] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=21/154\n",
      "[2024-03-18 13:30:14,762] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:14,764] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:30:14,779] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0146\n",
      "[2024-03-18 13:30:14,944] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=22/154\n",
      "[2024-03-18 13:30:14,945] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:14,947] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:30:14,961] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0136\n",
      "[2024-03-18 13:30:15,119] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=23/154\n",
      "[2024-03-18 13:30:15,125] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:15,130] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=60\n",
      "[2024-03-18 13:30:15,147] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0146\n",
      "[2024-03-18 13:30:15,353] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=24/154\n",
      "[2024-03-18 13:30:15,354] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:15,356] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:30:15,370] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0136\n",
      "[2024-03-18 13:30:15,584] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=25/154\n",
      "[2024-03-18 13:30:15,585] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:15,587] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=65\n",
      "[2024-03-18 13:30:15,603] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0147\n",
      "[2024-03-18 13:30:15,768] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=26/154\n",
      "[2024-03-18 13:30:15,769] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:15,770] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:30:15,786] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0145\n",
      "[2024-03-18 13:30:15,962] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=27/154\n",
      "[2024-03-18 13:30:15,963] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:15,964] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:30:15,980] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0149\n",
      "[2024-03-18 13:30:16,244] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=28/154\n",
      "[2024-03-18 13:30:16,246] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:16,247] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=63\n",
      "[2024-03-18 13:30:16,264] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0155\n",
      "[2024-03-18 13:30:16,438] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=29/154\n",
      "[2024-03-18 13:30:16,439] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:16,440] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=55\n",
      "[2024-03-18 13:30:16,459] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0158\n",
      "[2024-03-18 13:30:16,674] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=30/154\n",
      "[2024-03-18 13:30:16,675] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:16,677] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=62\n",
      "[2024-03-18 13:30:16,692] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0147\n",
      "[2024-03-18 13:30:16,900] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=31/154\n",
      "[2024-03-18 13:30:16,901] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:16,902] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:30:16,918] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0145\n",
      "[2024-03-18 13:30:17,101] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=32/154\n",
      "[2024-03-18 13:30:17,103] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:17,104] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:30:17,121] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0158\n",
      "[2024-03-18 13:30:17,290] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=33/154\n",
      "[2024-03-18 13:30:17,292] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:17,295] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:30:17,311] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0150\n",
      "[2024-03-18 13:30:17,492] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=34/154\n",
      "[2024-03-18 13:30:17,494] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:17,496] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:30:17,512] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0155\n",
      "[2024-03-18 13:30:17,647] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=35/154\n",
      "[2024-03-18 13:30:17,648] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:17,649] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:30:17,664] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0144\n",
      "[2024-03-18 13:30:17,886] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=36/154\n",
      "[2024-03-18 13:30:17,888] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:17,890] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=57\n",
      "[2024-03-18 13:30:17,905] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0148\n",
      "[2024-03-18 13:30:18,152] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=37/154\n",
      "[2024-03-18 13:30:18,154] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:18,155] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:30:18,172] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0156\n",
      "[2024-03-18 13:30:18,388] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=38/154\n",
      "[2024-03-18 13:30:18,389] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:18,391] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:30:18,406] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0137\n",
      "[2024-03-18 13:30:18,607] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=39/154\n",
      "[2024-03-18 13:30:18,608] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:18,610] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=65\n",
      "[2024-03-18 13:30:18,627] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0153\n",
      "[2024-03-18 13:30:18,853] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=40/154\n",
      "[2024-03-18 13:30:18,854] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:18,856] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:30:18,871] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0144\n",
      "[2024-03-18 13:30:19,037] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=41/154\n",
      "[2024-03-18 13:30:19,038] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:19,040] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=60\n",
      "[2024-03-18 13:30:19,056] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0154\n",
      "[2024-03-18 13:30:19,226] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=42/154\n",
      "[2024-03-18 13:30:19,227] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:19,229] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:30:19,244] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0140\n",
      "[2024-03-18 13:30:19,440] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=43/154\n",
      "[2024-03-18 13:30:19,442] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:19,443] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=57\n",
      "[2024-03-18 13:30:19,458] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0140\n",
      "[2024-03-18 13:30:19,675] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=44/154\n",
      "[2024-03-18 13:30:19,676] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:19,677] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:30:19,693] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0146\n",
      "[2024-03-18 13:30:19,873] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=45/154\n",
      "[2024-03-18 13:30:19,874] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:19,875] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=73\n",
      "[2024-03-18 13:30:19,890] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0141\n",
      "[2024-03-18 13:30:20,100] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=46/154\n",
      "[2024-03-18 13:30:20,102] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:20,103] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=71\n",
      "[2024-03-18 13:30:20,122] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0178\n",
      "[2024-03-18 13:30:20,320] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=47/154\n",
      "[2024-03-18 13:30:20,321] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:20,323] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:30:20,338] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0144\n",
      "[2024-03-18 13:30:20,589] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=48/154\n",
      "[2024-03-18 13:30:20,592] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:20,594] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:30:20,609] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0136\n",
      "[2024-03-18 13:30:20,826] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=49/154\n",
      "[2024-03-18 13:30:20,827] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:20,828] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:30:20,843] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0147\n",
      "[2024-03-18 13:30:21,055] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=50/154\n",
      "[2024-03-18 13:30:21,056] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:21,058] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:30:21,073] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0139\n",
      "[2024-03-18 13:30:21,242] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=51/154\n",
      "[2024-03-18 13:30:21,243] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:21,245] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:30:21,260] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0145\n",
      "[2024-03-18 13:30:21,432] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=52/154\n",
      "[2024-03-18 13:30:21,433] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:21,434] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:30:21,449] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0145\n",
      "[2024-03-18 13:30:21,605] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=53/154\n",
      "[2024-03-18 13:30:21,607] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:21,610] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:30:21,626] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0138\n",
      "[2024-03-18 13:30:21,817] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=54/154\n",
      "[2024-03-18 13:30:21,819] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:21,820] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=75\n",
      "[2024-03-18 13:30:21,835] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0140\n",
      "[2024-03-18 13:30:21,991] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=55/154\n",
      "[2024-03-18 13:30:21,992] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:21,994] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=90\n",
      "[2024-03-18 13:30:22,009] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0138\n",
      "[2024-03-18 13:30:22,226] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=56/154\n",
      "[2024-03-18 13:30:22,228] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:22,229] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=86\n",
      "[2024-03-18 13:30:22,244] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0137\n",
      "[2024-03-18 13:30:22,431] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=57/154\n",
      "[2024-03-18 13:30:22,432] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:22,434] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=105\n",
      "[2024-03-18 13:30:22,449] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0140\n",
      "[2024-03-18 13:30:22,657] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=58/154\n",
      "[2024-03-18 13:30:22,658] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:22,660] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=81\n",
      "[2024-03-18 13:30:22,675] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0143\n",
      "[2024-03-18 13:30:22,823] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=59/154\n",
      "[2024-03-18 13:30:22,825] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:22,827] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=99\n",
      "[2024-03-18 13:30:22,842] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0144\n",
      "[2024-03-18 13:30:23,067] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=60/154\n",
      "[2024-03-18 13:30:23,068] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:23,070] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=72\n",
      "[2024-03-18 13:30:23,085] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0137\n",
      "[2024-03-18 13:30:23,253] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=61/154\n",
      "[2024-03-18 13:30:23,255] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:23,257] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:30:23,273] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0144\n",
      "[2024-03-18 13:30:23,465] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=62/154\n",
      "[2024-03-18 13:30:23,466] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:23,469] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:30:23,485] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0149\n",
      "[2024-03-18 13:30:23,668] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=63/154\n",
      "[2024-03-18 13:30:23,670] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:23,672] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=72\n",
      "[2024-03-18 13:30:23,687] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0141\n",
      "[2024-03-18 13:30:23,910] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=64/154\n",
      "[2024-03-18 13:30:23,911] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:23,913] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:30:23,929] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0156\n",
      "[2024-03-18 13:30:24,116] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=65/154\n",
      "[2024-03-18 13:30:24,118] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:24,119] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:30:24,134] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0142\n",
      "[2024-03-18 13:30:24,338] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=66/154\n",
      "[2024-03-18 13:30:24,339] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:24,341] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:30:24,356] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0140\n",
      "[2024-03-18 13:30:24,525] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=67/154\n",
      "[2024-03-18 13:30:24,526] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:24,528] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=68\n",
      "[2024-03-18 13:30:24,543] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0136\n",
      "[2024-03-18 13:30:24,698] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=68/154\n",
      "[2024-03-18 13:30:24,699] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:24,701] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=70\n",
      "[2024-03-18 13:30:24,716] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0143\n",
      "[2024-03-18 13:30:24,912] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=69/154\n",
      "[2024-03-18 13:30:24,914] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:24,915] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=87\n",
      "[2024-03-18 13:30:24,931] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0147\n",
      "[2024-03-18 13:30:25,108] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=70/154\n",
      "[2024-03-18 13:30:25,109] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:25,111] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=69\n",
      "[2024-03-18 13:30:25,126] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0145\n",
      "[2024-03-18 13:30:25,324] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=71/154\n",
      "[2024-03-18 13:30:25,326] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:25,327] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:30:25,342] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0142\n",
      "[2024-03-18 13:30:25,533] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=72/154\n",
      "[2024-03-18 13:30:25,535] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:25,536] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:30:25,551] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0141\n",
      "[2024-03-18 13:30:25,717] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=73/154\n",
      "[2024-03-18 13:30:25,718] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:25,719] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:30:25,735] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0147\n",
      "[2024-03-18 13:30:25,879] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=74/154\n",
      "[2024-03-18 13:30:25,880] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:25,881] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:30:25,896] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0147\n",
      "[2024-03-18 13:30:26,119] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=75/154\n",
      "[2024-03-18 13:30:26,120] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:26,121] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:30:26,137] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0145\n",
      "[2024-03-18 13:30:26,294] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=76/154\n",
      "[2024-03-18 13:30:26,296] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:26,297] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:30:26,313] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0141\n",
      "[2024-03-18 13:30:26,498] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=77/154\n",
      "[2024-03-18 13:30:26,499] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:26,501] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:30:26,515] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0137\n",
      "[2024-03-18 13:30:26,935] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=78/154\n",
      "[2024-03-18 13:30:26,937] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:26,938] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:30:26,954] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0150\n",
      "[2024-03-18 13:30:27,116] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=79/154\n",
      "[2024-03-18 13:30:27,118] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:27,120] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:30:27,138] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0176\n",
      "[2024-03-18 13:30:27,273] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=80/154\n",
      "[2024-03-18 13:30:27,274] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:27,275] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=63\n",
      "[2024-03-18 13:30:27,290] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0136\n",
      "[2024-03-18 13:30:27,498] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=81/154\n",
      "[2024-03-18 13:30:27,499] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:27,500] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:30:27,515] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0139\n",
      "[2024-03-18 13:30:27,691] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=82/154\n",
      "[2024-03-18 13:30:27,692] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:27,694] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=66\n",
      "[2024-03-18 13:30:27,716] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0197\n",
      "[2024-03-18 13:30:27,970] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=83/154\n",
      "[2024-03-18 13:30:27,972] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:27,973] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:30:27,988] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0145\n",
      "[2024-03-18 13:30:28,171] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=84/154\n",
      "[2024-03-18 13:30:28,172] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:28,173] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:30:28,188] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0141\n",
      "[2024-03-18 13:30:28,381] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=85/154\n",
      "[2024-03-18 13:30:28,382] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:28,384] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=62\n",
      "[2024-03-18 13:30:28,399] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0133\n",
      "[2024-03-18 13:30:28,628] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=86/154\n",
      "[2024-03-18 13:30:28,629] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:28,631] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:30:28,645] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0133\n",
      "[2024-03-18 13:30:28,818] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=87/154\n",
      "[2024-03-18 13:30:28,819] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:28,820] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=68\n",
      "[2024-03-18 13:30:28,835] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0140\n",
      "[2024-03-18 13:30:28,972] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=88/154\n",
      "[2024-03-18 13:30:28,974] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:28,975] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:30:28,989] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0134\n",
      "[2024-03-18 13:30:29,136] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=89/154\n",
      "[2024-03-18 13:30:29,137] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:29,138] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=77\n",
      "[2024-03-18 13:30:29,153] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0135\n",
      "[2024-03-18 13:30:29,317] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=90/154\n",
      "[2024-03-18 13:30:29,318] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:29,320] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:30:29,335] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0140\n",
      "[2024-03-18 13:30:29,554] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=91/154\n",
      "[2024-03-18 13:30:29,555] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:29,559] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:30:29,574] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0139\n",
      "[2024-03-18 13:30:29,724] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=92/154\n",
      "[2024-03-18 13:30:29,726] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:29,728] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:30:29,750] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0148\n",
      "[2024-03-18 13:30:29,955] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=93/154\n",
      "[2024-03-18 13:30:29,957] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:29,963] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:30:29,982] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0177\n",
      "[2024-03-18 13:30:30,197] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=94/154\n",
      "[2024-03-18 13:30:30,199] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:30,201] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=69\n",
      "[2024-03-18 13:30:30,216] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0144\n",
      "[2024-03-18 13:30:30,389] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=95/154\n",
      "[2024-03-18 13:30:30,390] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:30,392] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:30:30,409] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0166\n",
      "[2024-03-18 13:30:30,640] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=96/154\n",
      "[2024-03-18 13:30:30,641] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:30,643] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:30:30,659] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0150\n",
      "[2024-03-18 13:30:30,920] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=97/154\n",
      "[2024-03-18 13:30:30,921] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:30,923] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:30:30,939] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0153\n",
      "[2024-03-18 13:30:31,116] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=98/154\n",
      "[2024-03-18 13:30:31,117] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:31,119] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:30:31,135] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0146\n",
      "[2024-03-18 13:30:31,320] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=99/154\n",
      "[2024-03-18 13:30:31,321] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:31,323] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=60\n",
      "[2024-03-18 13:30:31,337] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0137\n",
      "[2024-03-18 13:30:31,517] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=100/154\n",
      "[2024-03-18 13:30:31,518] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:31,520] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=75\n",
      "[2024-03-18 13:30:31,535] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0140\n",
      "[2024-03-18 13:30:31,706] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=101/154\n",
      "[2024-03-18 13:30:31,708] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:31,709] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:30:31,724] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0135\n",
      "[2024-03-18 13:30:31,901] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=102/154\n",
      "[2024-03-18 13:30:31,902] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:31,903] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=81\n",
      "[2024-03-18 13:30:31,918] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0140\n",
      "[2024-03-18 13:30:32,092] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=103/154\n",
      "[2024-03-18 13:30:32,094] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:32,095] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:30:32,110] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0133\n",
      "[2024-03-18 13:30:32,269] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=104/154\n",
      "[2024-03-18 13:30:32,270] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:32,272] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=65\n",
      "[2024-03-18 13:30:32,286] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0131\n",
      "[2024-03-18 13:30:32,463] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=105/154\n",
      "[2024-03-18 13:30:32,464] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:32,466] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:30:32,481] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0137\n",
      "[2024-03-18 13:30:32,674] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=106/154\n",
      "[2024-03-18 13:30:32,675] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:32,677] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=66\n",
      "[2024-03-18 13:30:32,692] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0138\n",
      "[2024-03-18 13:30:32,836] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=107/154\n",
      "[2024-03-18 13:30:32,838] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:32,839] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=72\n",
      "[2024-03-18 13:30:32,854] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0138\n",
      "[2024-03-18 13:30:33,032] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=108/154\n",
      "[2024-03-18 13:30:33,033] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:33,035] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=69\n",
      "[2024-03-18 13:30:33,055] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0192\n",
      "[2024-03-18 13:30:33,212] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=109/154\n",
      "[2024-03-18 13:30:33,212] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:33,214] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:30:33,229] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0142\n",
      "[2024-03-18 13:30:33,399] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=110/154\n",
      "[2024-03-18 13:30:33,400] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:33,402] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:30:33,416] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0135\n",
      "[2024-03-18 13:30:33,581] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=111/154\n",
      "[2024-03-18 13:30:33,583] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:33,584] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:30:33,598] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0136\n",
      "[2024-03-18 13:30:33,800] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=112/154\n",
      "[2024-03-18 13:30:33,801] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:33,802] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:30:33,819] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0160\n",
      "[2024-03-18 13:30:34,022] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=113/154\n",
      "[2024-03-18 13:30:34,023] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:34,024] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=66\n",
      "[2024-03-18 13:30:34,039] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0140\n",
      "[2024-03-18 13:30:34,260] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=114/154\n",
      "[2024-03-18 13:30:34,261] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:34,263] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=62\n",
      "[2024-03-18 13:30:34,278] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0140\n",
      "[2024-03-18 13:30:34,466] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=115/154\n",
      "[2024-03-18 13:30:34,467] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:34,468] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:30:34,482] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0130\n",
      "[2024-03-18 13:30:34,669] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=116/154\n",
      "[2024-03-18 13:30:34,670] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:34,671] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:30:34,685] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0129\n",
      "[2024-03-18 13:30:34,852] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=117/154\n",
      "[2024-03-18 13:30:34,854] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:34,856] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:30:34,870] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0133\n",
      "[2024-03-18 13:30:35,062] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=118/154\n",
      "[2024-03-18 13:30:35,069] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:35,071] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:30:35,086] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0136\n",
      "[2024-03-18 13:30:35,262] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=119/154\n",
      "[2024-03-18 13:30:35,263] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:35,265] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:30:35,279] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0139\n",
      "[2024-03-18 13:30:35,425] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=120/154\n",
      "[2024-03-18 13:30:35,426] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:35,428] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=66\n",
      "[2024-03-18 13:30:35,444] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0149\n",
      "[2024-03-18 13:30:35,687] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=121/154\n",
      "[2024-03-18 13:30:35,688] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:35,690] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:30:35,705] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0139\n",
      "[2024-03-18 13:30:35,867] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=122/154\n",
      "[2024-03-18 13:30:35,868] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:35,870] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:30:35,885] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0140\n",
      "[2024-03-18 13:30:36,086] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=123/154\n",
      "[2024-03-18 13:30:36,088] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:36,089] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:30:36,104] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0136\n",
      "[2024-03-18 13:30:36,279] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=124/154\n",
      "[2024-03-18 13:30:36,280] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:36,283] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:30:36,297] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0133\n",
      "[2024-03-18 13:30:36,481] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=125/154\n",
      "[2024-03-18 13:30:36,482] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:36,483] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:30:36,497] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0134\n",
      "[2024-03-18 13:30:36,697] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=126/154\n",
      "[2024-03-18 13:30:36,698] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:36,700] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=84\n",
      "[2024-03-18 13:30:36,716] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0151\n",
      "[2024-03-18 13:30:36,932] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=127/154\n",
      "[2024-03-18 13:30:36,933] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:36,934] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:30:36,950] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0150\n",
      "[2024-03-18 13:30:37,155] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=128/154\n",
      "[2024-03-18 13:30:37,156] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:37,158] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:30:37,173] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0151\n",
      "[2024-03-18 13:30:37,363] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=129/154\n",
      "[2024-03-18 13:30:37,364] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:37,366] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:30:37,381] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0142\n",
      "[2024-03-18 13:30:37,534] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=130/154\n",
      "[2024-03-18 13:30:37,535] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:37,538] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=55\n",
      "[2024-03-18 13:30:37,554] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0148\n",
      "[2024-03-18 13:30:37,723] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=131/154\n",
      "[2024-03-18 13:30:37,724] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:37,727] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=57\n",
      "[2024-03-18 13:30:37,742] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0141\n",
      "[2024-03-18 13:30:37,937] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=132/154\n",
      "[2024-03-18 13:30:37,939] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:37,940] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:30:37,955] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0145\n",
      "[2024-03-18 13:30:38,136] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=133/154\n",
      "[2024-03-18 13:30:38,137] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:38,138] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=74\n",
      "[2024-03-18 13:30:38,153] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0141\n",
      "[2024-03-18 13:30:38,338] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=134/154\n",
      "[2024-03-18 13:30:38,339] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:38,340] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=57\n",
      "[2024-03-18 13:30:38,355] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0139\n",
      "[2024-03-18 13:30:38,556] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=135/154\n",
      "[2024-03-18 13:30:38,557] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:38,558] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=55\n",
      "[2024-03-18 13:30:38,573] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0144\n",
      "[2024-03-18 13:30:38,747] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=136/154\n",
      "[2024-03-18 13:30:38,748] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:38,750] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=60\n",
      "[2024-03-18 13:30:38,766] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0150\n",
      "[2024-03-18 13:30:38,922] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=137/154\n",
      "[2024-03-18 13:30:38,923] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:38,924] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=99\n",
      "[2024-03-18 13:30:38,939] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0140\n",
      "[2024-03-18 13:30:39,073] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=138/154\n",
      "[2024-03-18 13:30:39,074] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:39,075] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=74\n",
      "[2024-03-18 13:30:39,089] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0132\n",
      "[2024-03-18 13:30:39,305] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=139/154\n",
      "[2024-03-18 13:30:39,306] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:39,307] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:30:39,321] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0139\n",
      "[2024-03-18 13:30:39,511] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=140/154\n",
      "[2024-03-18 13:30:39,512] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:39,513] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=66\n",
      "[2024-03-18 13:30:39,528] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0135\n",
      "[2024-03-18 13:30:39,710] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=141/154\n",
      "[2024-03-18 13:30:39,711] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:39,714] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:30:39,730] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0138\n",
      "[2024-03-18 13:30:39,881] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=142/154\n",
      "[2024-03-18 13:30:39,882] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:39,883] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:30:39,898] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0138\n",
      "[2024-03-18 13:30:40,076] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=143/154\n",
      "[2024-03-18 13:30:40,077] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:40,078] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:30:40,093] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0136\n",
      "[2024-03-18 13:30:40,311] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=144/154\n",
      "[2024-03-18 13:30:40,312] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:40,313] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=60\n",
      "[2024-03-18 13:30:40,332] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0181\n",
      "[2024-03-18 13:30:40,597] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=145/154\n",
      "[2024-03-18 13:30:40,598] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:40,599] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=84\n",
      "[2024-03-18 13:30:40,614] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0135\n",
      "[2024-03-18 13:30:40,783] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=146/154\n",
      "[2024-03-18 13:30:40,784] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:40,786] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:30:40,800] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0136\n",
      "[2024-03-18 13:30:41,130] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=147/154\n",
      "[2024-03-18 13:30:41,131] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:41,133] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:30:41,148] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0144\n",
      "[2024-03-18 13:30:41,352] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=148/154\n",
      "[2024-03-18 13:30:41,353] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:41,355] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:30:41,370] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0145\n",
      "[2024-03-18 13:30:41,531] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=149/154\n",
      "[2024-03-18 13:30:41,532] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:41,534] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:30:41,549] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0143\n",
      "[2024-03-18 13:30:41,711] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=150/154\n",
      "[2024-03-18 13:30:41,712] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:41,714] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:30:41,728] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0132\n",
      "[2024-03-18 13:30:41,876] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=151/154\n",
      "[2024-03-18 13:30:41,877] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:41,878] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:30:41,892] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0133\n",
      "[2024-03-18 13:30:42,031] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=152/154\n",
      "[2024-03-18 13:30:42,032] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:42,034] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:30:42,048] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0135\n",
      "[2024-03-18 13:30:42,196] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=153/154\n",
      "[2024-03-18 13:30:42,197] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:42,198] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:30:42,212] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0132\n",
      "[2024-03-18 13:30:42,359] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=154/154\n",
      "[2024-03-18 13:30:42,361] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=1\n",
      "[2024-03-18 13:30:42,362] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:30:42,376] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0132\n",
      "[2024-03-18 13:30:42,551] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=1/77\n",
      "[2024-03-18 13:30:42,552] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:42,554] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:30:42,554] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=77\n",
      "[2024-03-18 13:30:42,569] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0134\n",
      "[2024-03-18 13:30:42,630] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0729\n",
      "[2024-03-18 13:30:42,861] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=2/77\n",
      "[2024-03-18 13:30:42,862] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:42,864] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=62\n",
      "[2024-03-18 13:30:42,867] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:30:42,881] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0155\n",
      "[2024-03-18 13:30:42,889] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0213\n",
      "[2024-03-18 13:30:43,146] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=3/77\n",
      "[2024-03-18 13:30:43,147] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:43,148] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:30:43,148] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=82\n",
      "[2024-03-18 13:30:43,164] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0136\n",
      "[2024-03-18 13:30:43,171] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0224\n",
      "[2024-03-18 13:30:43,529] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=4/77\n",
      "[2024-03-18 13:30:43,530] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:43,531] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:30:43,534] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:30:43,548] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0158\n",
      "[2024-03-18 13:30:43,563] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0283\n",
      "[2024-03-18 13:30:43,827] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=5/77\n",
      "[2024-03-18 13:30:43,828] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:43,830] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=69\n",
      "[2024-03-18 13:30:43,830] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=60\n",
      "[2024-03-18 13:30:43,845] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0133\n",
      "[2024-03-18 13:30:43,854] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0237\n",
      "[2024-03-18 13:30:44,164] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=6/77\n",
      "[2024-03-18 13:30:44,165] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:44,167] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:30:44,167] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:30:44,184] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0162\n",
      "[2024-03-18 13:30:44,194] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0243\n",
      "[2024-03-18 13:30:44,437] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=7/77\n",
      "[2024-03-18 13:30:44,438] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:44,440] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=65\n",
      "[2024-03-18 13:30:44,440] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=75\n",
      "[2024-03-18 13:30:44,455] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0147\n",
      "[2024-03-18 13:30:44,464] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0208\n",
      "[2024-03-18 13:30:44,696] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=8/77\n",
      "[2024-03-18 13:30:44,697] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:44,699] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=57\n",
      "[2024-03-18 13:30:44,699] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:30:44,715] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0157\n",
      "[2024-03-18 13:30:44,723] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0211\n",
      "[2024-03-18 13:30:44,946] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=9/77\n",
      "[2024-03-18 13:30:44,947] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:44,948] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:30:44,948] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:30:44,964] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0153\n",
      "[2024-03-18 13:30:44,972] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0205\n",
      "[2024-03-18 13:30:45,288] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=10/77\n",
      "[2024-03-18 13:30:45,290] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:45,292] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:30:45,293] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:30:45,310] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0166\n",
      "[2024-03-18 13:30:45,318] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0218\n",
      "[2024-03-18 13:30:45,595] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=11/77\n",
      "[2024-03-18 13:30:45,596] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:45,597] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:30:45,597] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:30:45,612] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0140\n",
      "[2024-03-18 13:30:45,620] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0197\n",
      "[2024-03-18 13:30:45,879] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=12/77\n",
      "[2024-03-18 13:30:45,880] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:45,881] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=60\n",
      "[2024-03-18 13:30:45,881] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:30:45,898] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0158\n",
      "[2024-03-18 13:30:45,905] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0203\n",
      "[2024-03-18 13:30:46,116] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=13/77\n",
      "[2024-03-18 13:30:46,117] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:46,118] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=65\n",
      "[2024-03-18 13:30:46,118] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:30:46,133] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0138\n",
      "[2024-03-18 13:30:46,141] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0179\n",
      "[2024-03-18 13:30:46,373] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=14/77\n",
      "[2024-03-18 13:30:46,375] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:46,376] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:30:46,377] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=63\n",
      "[2024-03-18 13:30:46,394] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0177\n",
      "[2024-03-18 13:30:46,401] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0212\n",
      "[2024-03-18 13:30:46,623] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=15/77\n",
      "[2024-03-18 13:30:46,624] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:46,625] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=55\n",
      "[2024-03-18 13:30:46,627] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=62\n",
      "[2024-03-18 13:30:46,640] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0143\n",
      "[2024-03-18 13:30:46,648] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0180\n",
      "[2024-03-18 13:30:46,867] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=16/77\n",
      "[2024-03-18 13:30:46,868] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:46,869] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:30:46,870] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:30:46,887] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0143\n",
      "[2024-03-18 13:30:46,896] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0253\n",
      "[2024-03-18 13:30:47,217] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=17/77\n",
      "[2024-03-18 13:30:47,218] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:47,220] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:30:47,220] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:30:47,239] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0181\n",
      "[2024-03-18 13:30:47,246] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0223\n",
      "[2024-03-18 13:30:47,506] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=18/77\n",
      "[2024-03-18 13:30:47,507] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:47,509] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=57\n",
      "[2024-03-18 13:30:47,509] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:30:47,525] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0148\n",
      "[2024-03-18 13:30:47,533] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0205\n",
      "[2024-03-18 13:30:47,849] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=19/77\n",
      "[2024-03-18 13:30:47,850] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:47,851] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:30:47,852] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:30:47,869] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0168\n",
      "[2024-03-18 13:30:47,876] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0211\n",
      "[2024-03-18 13:30:48,161] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=20/77\n",
      "[2024-03-18 13:30:48,162] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:48,164] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=65\n",
      "[2024-03-18 13:30:48,164] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:30:48,180] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0147\n",
      "[2024-03-18 13:30:48,188] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0200\n",
      "[2024-03-18 13:30:48,419] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=21/77\n",
      "[2024-03-18 13:30:48,420] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:48,422] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=60\n",
      "[2024-03-18 13:30:48,422] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:30:48,444] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0209\n",
      "[2024-03-18 13:30:48,449] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0204\n",
      "[2024-03-18 13:30:48,738] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=22/77\n",
      "[2024-03-18 13:30:48,739] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:48,741] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=57\n",
      "[2024-03-18 13:30:48,741] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:30:48,756] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0145\n",
      "[2024-03-18 13:30:48,765] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0200\n",
      "[2024-03-18 13:30:49,036] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=23/77\n",
      "[2024-03-18 13:30:49,037] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:49,039] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=73\n",
      "[2024-03-18 13:30:49,039] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=71\n",
      "[2024-03-18 13:30:49,056] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0165\n",
      "[2024-03-18 13:30:49,064] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0206\n",
      "[2024-03-18 13:30:49,373] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=24/77\n",
      "[2024-03-18 13:30:49,374] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:49,375] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:30:49,376] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:30:49,391] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0150\n",
      "[2024-03-18 13:30:49,399] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0198\n",
      "[2024-03-18 13:30:49,604] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=25/77\n",
      "[2024-03-18 13:30:49,605] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:49,607] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:30:49,609] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:30:49,627] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0161\n",
      "[2024-03-18 13:30:49,636] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0177\n",
      "[2024-03-18 13:30:49,909] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=26/77\n",
      "[2024-03-18 13:30:49,911] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:49,912] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:30:49,912] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:30:49,927] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0147\n",
      "[2024-03-18 13:30:49,935] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0195\n",
      "[2024-03-18 13:30:50,192] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=27/77\n",
      "[2024-03-18 13:30:50,194] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:50,195] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=75\n",
      "[2024-03-18 13:30:50,195] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:30:50,212] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0159\n",
      "[2024-03-18 13:30:50,219] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0209\n",
      "[2024-03-18 13:30:50,587] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=28/77\n",
      "[2024-03-18 13:30:50,588] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:50,590] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=90\n",
      "[2024-03-18 13:30:50,590] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=86\n",
      "[2024-03-18 13:30:50,605] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0148\n",
      "[2024-03-18 13:30:50,613] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0204\n",
      "[2024-03-18 13:30:50,887] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=29/77\n",
      "[2024-03-18 13:30:50,888] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:50,890] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=105\n",
      "[2024-03-18 13:30:50,890] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=81\n",
      "[2024-03-18 13:30:50,907] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0163\n",
      "[2024-03-18 13:30:50,915] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0207\n",
      "[2024-03-18 13:30:51,158] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=30/77\n",
      "[2024-03-18 13:30:51,159] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:51,160] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=99\n",
      "[2024-03-18 13:30:51,161] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=72\n",
      "[2024-03-18 13:30:51,177] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0154\n",
      "[2024-03-18 13:30:51,185] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0205\n",
      "[2024-03-18 13:30:51,487] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=31/77\n",
      "[2024-03-18 13:30:51,489] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:51,490] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:30:51,490] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:30:51,507] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0164\n",
      "[2024-03-18 13:30:51,515] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0217\n",
      "[2024-03-18 13:30:51,797] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=32/77\n",
      "[2024-03-18 13:30:51,798] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:51,800] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=72\n",
      "[2024-03-18 13:30:51,800] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:30:51,816] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0155\n",
      "[2024-03-18 13:30:51,826] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0213\n",
      "[2024-03-18 13:30:52,088] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=33/77\n",
      "[2024-03-18 13:30:52,090] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:52,092] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:30:52,094] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:30:52,111] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0162\n",
      "[2024-03-18 13:30:52,117] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0187\n",
      "[2024-03-18 13:30:52,425] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=34/77\n",
      "[2024-03-18 13:30:52,426] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:52,428] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=70\n",
      "[2024-03-18 13:30:52,428] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=68\n",
      "[2024-03-18 13:30:52,443] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0141\n",
      "[2024-03-18 13:30:52,451] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0193\n",
      "[2024-03-18 13:30:52,714] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=35/77\n",
      "[2024-03-18 13:30:52,716] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:52,718] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=87\n",
      "[2024-03-18 13:30:52,718] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=69\n",
      "[2024-03-18 13:30:52,735] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0159\n",
      "[2024-03-18 13:30:52,743] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0176\n",
      "[2024-03-18 13:30:52,982] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=36/77\n",
      "[2024-03-18 13:30:52,983] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:52,987] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:30:52,988] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:30:53,002] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0138\n",
      "[2024-03-18 13:30:53,011] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0195\n",
      "[2024-03-18 13:30:53,306] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=37/77\n",
      "[2024-03-18 13:30:53,307] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:53,308] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:30:53,309] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:30:53,326] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0166\n",
      "[2024-03-18 13:30:53,334] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0206\n",
      "[2024-03-18 13:30:53,615] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=38/77\n",
      "[2024-03-18 13:30:53,617] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:53,619] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:30:53,619] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:30:53,635] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0152\n",
      "[2024-03-18 13:30:53,644] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0172\n",
      "[2024-03-18 13:30:53,867] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=39/77\n",
      "[2024-03-18 13:30:53,868] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:53,870] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:30:53,870] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:30:53,886] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0152\n",
      "[2024-03-18 13:30:53,894] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0173\n",
      "[2024-03-18 13:30:54,166] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=40/77\n",
      "[2024-03-18 13:30:54,168] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:54,171] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:30:54,171] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=63\n",
      "[2024-03-18 13:30:54,187] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0155\n",
      "[2024-03-18 13:30:54,196] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0179\n",
      "[2024-03-18 13:30:54,465] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=41/77\n",
      "[2024-03-18 13:30:54,466] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:54,468] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:30:54,469] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=66\n",
      "[2024-03-18 13:30:54,485] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0157\n",
      "[2024-03-18 13:30:54,491] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0198\n",
      "[2024-03-18 13:30:54,761] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=42/77\n",
      "[2024-03-18 13:30:54,763] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:54,764] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:30:54,769] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:30:54,780] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0149\n",
      "[2024-03-18 13:30:54,789] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0188\n",
      "[2024-03-18 13:30:55,049] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=43/77\n",
      "[2024-03-18 13:30:55,050] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:55,052] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:30:55,052] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=62\n",
      "[2024-03-18 13:30:55,069] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0163\n",
      "[2024-03-18 13:30:55,076] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0205\n",
      "[2024-03-18 13:30:55,378] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=44/77\n",
      "[2024-03-18 13:30:55,379] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:55,381] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=68\n",
      "[2024-03-18 13:30:55,381] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:30:55,396] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0141\n",
      "[2024-03-18 13:30:55,403] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0195\n",
      "[2024-03-18 13:30:55,673] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=45/77\n",
      "[2024-03-18 13:30:55,674] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:55,676] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=77\n",
      "[2024-03-18 13:30:55,676] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:30:55,692] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0156\n",
      "[2024-03-18 13:30:55,699] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0183\n",
      "[2024-03-18 13:30:55,964] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=46/77\n",
      "[2024-03-18 13:30:55,965] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:55,971] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:30:55,971] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:30:55,986] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0135\n",
      "[2024-03-18 13:30:55,993] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0185\n",
      "[2024-03-18 13:30:56,264] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=47/77\n",
      "[2024-03-18 13:30:56,265] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:56,269] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:30:56,270] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=69\n",
      "[2024-03-18 13:30:56,287] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0163\n",
      "[2024-03-18 13:30:56,294] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0190\n",
      "[2024-03-18 13:30:56,536] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=48/77\n",
      "[2024-03-18 13:30:56,537] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:56,539] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:30:56,539] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:30:56,556] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0165\n",
      "[2024-03-18 13:30:56,564] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0194\n",
      "[2024-03-18 13:30:56,850] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=49/77\n",
      "[2024-03-18 13:30:56,851] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:56,853] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:30:56,853] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:30:56,870] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0165\n",
      "[2024-03-18 13:30:56,880] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0191\n",
      "[2024-03-18 13:30:57,312] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=50/77\n",
      "[2024-03-18 13:30:57,313] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:57,314] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=60\n",
      "[2024-03-18 13:30:57,314] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=75\n",
      "[2024-03-18 13:30:57,331] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0155\n",
      "[2024-03-18 13:30:57,339] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0208\n",
      "[2024-03-18 13:30:57,650] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=51/77\n",
      "[2024-03-18 13:30:57,651] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:57,653] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:30:57,654] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=81\n",
      "[2024-03-18 13:30:57,672] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0168\n",
      "[2024-03-18 13:30:57,679] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0210\n",
      "[2024-03-18 13:30:57,880] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=52/77\n",
      "[2024-03-18 13:30:57,881] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:57,882] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:30:57,883] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=65\n",
      "[2024-03-18 13:30:57,902] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0178\n",
      "[2024-03-18 13:30:57,910] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0192\n",
      "[2024-03-18 13:30:58,163] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=53/77\n",
      "[2024-03-18 13:30:58,164] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:58,166] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:30:58,166] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=66\n",
      "[2024-03-18 13:30:58,181] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0148\n",
      "[2024-03-18 13:30:58,188] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0193\n",
      "[2024-03-18 13:30:58,480] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=54/77\n",
      "[2024-03-18 13:30:58,485] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:58,487] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=72\n",
      "[2024-03-18 13:30:58,487] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=69\n",
      "[2024-03-18 13:30:58,502] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0144\n",
      "[2024-03-18 13:30:58,509] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0191\n",
      "[2024-03-18 13:30:58,723] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=55/77\n",
      "[2024-03-18 13:30:58,725] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:58,726] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:30:58,726] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:30:58,743] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0153\n",
      "[2024-03-18 13:30:58,749] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0196\n",
      "[2024-03-18 13:30:59,075] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=56/77\n",
      "[2024-03-18 13:30:59,076] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:59,077] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:30:59,077] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:30:59,092] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0138\n",
      "[2024-03-18 13:30:59,100] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0197\n",
      "[2024-03-18 13:30:59,361] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=57/77\n",
      "[2024-03-18 13:30:59,363] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:59,365] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=62\n",
      "[2024-03-18 13:30:59,366] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=66\n",
      "[2024-03-18 13:30:59,382] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0156\n",
      "[2024-03-18 13:30:59,389] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0179\n",
      "[2024-03-18 13:30:59,663] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=58/77\n",
      "[2024-03-18 13:30:59,665] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:30:59,666] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:30:59,667] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:30:59,683] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0148\n",
      "[2024-03-18 13:30:59,690] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0189\n",
      "[2024-03-18 13:31:00,001] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=59/77\n",
      "[2024-03-18 13:31:00,003] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:31:00,005] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:31:00,005] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:31:00,023] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0159\n",
      "[2024-03-18 13:31:00,031] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0192\n",
      "[2024-03-18 13:31:00,249] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=60/77\n",
      "[2024-03-18 13:31:00,250] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:31:00,251] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:00,252] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=66\n",
      "[2024-03-18 13:31:00,267] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0141\n",
      "[2024-03-18 13:31:00,274] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0196\n",
      "[2024-03-18 13:31:00,543] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=61/77\n",
      "[2024-03-18 13:31:00,544] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:31:00,545] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:00,545] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:00,563] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0168\n",
      "[2024-03-18 13:31:00,569] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0209\n",
      "[2024-03-18 13:31:00,830] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=62/77\n",
      "[2024-03-18 13:31:00,832] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:31:00,833] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:31:00,837] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:00,850] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0145\n",
      "[2024-03-18 13:31:00,858] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0185\n",
      "[2024-03-18 13:31:01,194] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=63/77\n",
      "[2024-03-18 13:31:01,198] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:31:01,200] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:31:01,200] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=84\n",
      "[2024-03-18 13:31:01,217] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0158\n",
      "[2024-03-18 13:31:01,224] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0204\n",
      "[2024-03-18 13:31:01,493] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=64/77\n",
      "[2024-03-18 13:31:01,494] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:31:01,497] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:01,497] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:31:01,515] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0165\n",
      "[2024-03-18 13:31:01,523] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0201\n",
      "[2024-03-18 13:31:01,917] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=65/77\n",
      "[2024-03-18 13:31:01,919] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:31:01,920] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:01,920] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=55\n",
      "[2024-03-18 13:31:01,938] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0167\n",
      "[2024-03-18 13:31:01,945] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0212\n",
      "[2024-03-18 13:31:02,214] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=66/77\n",
      "[2024-03-18 13:31:02,216] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:31:02,217] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=57\n",
      "[2024-03-18 13:31:02,217] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:02,235] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0151\n",
      "[2024-03-18 13:31:02,243] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0243\n",
      "[2024-03-18 13:31:02,507] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=67/77\n",
      "[2024-03-18 13:31:02,509] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:31:02,516] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=57\n",
      "[2024-03-18 13:31:02,517] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=74\n",
      "[2024-03-18 13:31:02,542] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0242\n",
      "[2024-03-18 13:31:02,554] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0224\n",
      "[2024-03-18 13:31:02,852] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=68/77\n",
      "[2024-03-18 13:31:02,855] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:31:02,858] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=55\n",
      "[2024-03-18 13:31:02,858] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=60\n",
      "[2024-03-18 13:31:02,876] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0152\n",
      "[2024-03-18 13:31:02,884] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0180\n",
      "[2024-03-18 13:31:03,144] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=69/77\n",
      "[2024-03-18 13:31:03,145] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:31:03,149] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=74\n",
      "[2024-03-18 13:31:03,149] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=99\n",
      "[2024-03-18 13:31:03,167] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0160\n",
      "[2024-03-18 13:31:03,177] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0232\n",
      "[2024-03-18 13:31:03,492] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=70/77\n",
      "[2024-03-18 13:31:03,497] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:31:03,499] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:31:03,499] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=66\n",
      "[2024-03-18 13:31:03,526] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0217\n",
      "[2024-03-18 13:31:03,532] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0210\n",
      "[2024-03-18 13:31:03,753] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=71/77\n",
      "[2024-03-18 13:31:03,754] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:31:03,756] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:31:03,756] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:31:03,773] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0167\n",
      "[2024-03-18 13:31:03,780] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0197\n",
      "[2024-03-18 13:31:03,997] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=72/77\n",
      "[2024-03-18 13:31:03,999] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:31:04,000] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:04,000] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=60\n",
      "[2024-03-18 13:31:04,015] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0135\n",
      "[2024-03-18 13:31:04,022] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0184\n",
      "[2024-03-18 13:31:04,272] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=73/77\n",
      "[2024-03-18 13:31:04,273] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:31:04,275] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:04,279] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=84\n",
      "[2024-03-18 13:31:04,294] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0165\n",
      "[2024-03-18 13:31:04,300] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0193\n",
      "[2024-03-18 13:31:04,652] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=74/77\n",
      "[2024-03-18 13:31:04,653] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:31:04,654] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:04,654] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:04,671] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0160\n",
      "[2024-03-18 13:31:04,678] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0205\n",
      "[2024-03-18 13:31:04,971] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=75/77\n",
      "[2024-03-18 13:31:04,972] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:31:04,974] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:04,974] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:31:04,990] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0155\n",
      "[2024-03-18 13:31:04,997] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0203\n",
      "[2024-03-18 13:31:05,286] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=76/77\n",
      "[2024-03-18 13:31:05,287] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:31:05,288] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:31:05,289] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:05,305] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0155\n",
      "[2024-03-18 13:31:05,313] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0190\n",
      "[2024-03-18 13:31:05,541] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=77/77\n",
      "[2024-03-18 13:31:05,542] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=2\n",
      "[2024-03-18 13:31:05,544] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:31:05,544] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:31:05,560] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0153\n",
      "[2024-03-18 13:31:05,568] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0205\n",
      "[2024-03-18 13:31:05,853] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=1/39\n",
      "[2024-03-18 13:31:05,854] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:05,856] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=77\n",
      "[2024-03-18 13:31:05,859] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=62\n",
      "[2024-03-18 13:31:05,861] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:05,861] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:05,874] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0170\n",
      "[2024-03-18 13:31:05,887] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0212\n",
      "[2024-03-18 13:31:05,945] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0752\n",
      "[2024-03-18 13:31:05,953] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0863\n",
      "[2024-03-18 13:31:06,458] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=2/39\n",
      "[2024-03-18 13:31:06,459] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:06,461] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:06,463] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=82\n",
      "[2024-03-18 13:31:06,464] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:06,464] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:06,477] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0157\n",
      "[2024-03-18 13:31:06,484] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0196\n",
      "[2024-03-18 13:31:06,493] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0258\n",
      "[2024-03-18 13:31:06,499] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0289\n",
      "[2024-03-18 13:31:06,909] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=3/39\n",
      "[2024-03-18 13:31:06,910] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:06,912] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=69\n",
      "[2024-03-18 13:31:06,912] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:31:06,912] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=60\n",
      "[2024-03-18 13:31:06,913] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:06,931] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0158\n",
      "[2024-03-18 13:31:06,937] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0209\n",
      "[2024-03-18 13:31:06,944] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0257\n",
      "[2024-03-18 13:31:06,951] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0298\n",
      "[2024-03-18 13:31:07,439] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=4/39\n",
      "[2024-03-18 13:31:07,440] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:07,442] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=65\n",
      "[2024-03-18 13:31:07,442] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=75\n",
      "[2024-03-18 13:31:07,442] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:07,442] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=57\n",
      "[2024-03-18 13:31:07,458] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0144\n",
      "[2024-03-18 13:31:07,468] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0224\n",
      "[2024-03-18 13:31:07,474] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0250\n",
      "[2024-03-18 13:31:07,482] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0301\n",
      "[2024-03-18 13:31:07,876] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=5/39\n",
      "[2024-03-18 13:31:07,878] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:07,880] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:07,880] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:31:07,880] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:31:07,880] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:07,898] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0169\n",
      "[2024-03-18 13:31:07,906] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0205\n",
      "[2024-03-18 13:31:07,913] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0248\n",
      "[2024-03-18 13:31:07,921] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0279\n",
      "[2024-03-18 13:31:08,323] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=6/39\n",
      "[2024-03-18 13:31:08,326] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:08,328] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:08,330] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=60\n",
      "[2024-03-18 13:31:08,331] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:08,331] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:31:08,348] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0168\n",
      "[2024-03-18 13:31:08,355] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0179\n",
      "[2024-03-18 13:31:08,364] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0223\n",
      "[2024-03-18 13:31:08,375] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0299\n",
      "[2024-03-18 13:31:08,889] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=7/39\n",
      "[2024-03-18 13:31:08,893] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:08,902] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=65\n",
      "[2024-03-18 13:31:08,902] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:08,903] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:08,903] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=63\n",
      "[2024-03-18 13:31:08,925] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0218\n",
      "[2024-03-18 13:31:08,933] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0218\n",
      "[2024-03-18 13:31:08,935] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0186\n",
      "[2024-03-18 13:31:08,945] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0187\n",
      "[2024-03-18 13:31:09,360] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=8/39\n",
      "[2024-03-18 13:31:09,361] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:09,362] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=55\n",
      "[2024-03-18 13:31:09,362] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=62\n",
      "[2024-03-18 13:31:09,363] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:09,366] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:09,379] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0150\n",
      "[2024-03-18 13:31:09,389] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0220\n",
      "[2024-03-18 13:31:09,395] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0228\n",
      "[2024-03-18 13:31:09,403] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0276\n",
      "[2024-03-18 13:31:10,126] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=9/39\n",
      "[2024-03-18 13:31:10,127] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:10,128] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:31:10,129] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:10,129] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:31:10,129] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=57\n",
      "[2024-03-18 13:31:10,148] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0184\n",
      "[2024-03-18 13:31:10,155] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0215\n",
      "[2024-03-18 13:31:10,163] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0233\n",
      "[2024-03-18 13:31:10,171] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0325\n",
      "[2024-03-18 13:31:10,575] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=10/39\n",
      "[2024-03-18 13:31:10,576] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:10,577] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:31:10,578] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:10,578] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=65\n",
      "[2024-03-18 13:31:10,578] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:10,595] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0160\n",
      "[2024-03-18 13:31:10,603] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0209\n",
      "[2024-03-18 13:31:10,611] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0263\n",
      "[2024-03-18 13:31:10,618] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0296\n",
      "[2024-03-18 13:31:11,051] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=11/39\n",
      "[2024-03-18 13:31:11,052] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:11,054] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=60\n",
      "[2024-03-18 13:31:11,054] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:11,055] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=57\n",
      "[2024-03-18 13:31:11,055] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:11,072] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0162\n",
      "[2024-03-18 13:31:11,080] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0215\n",
      "[2024-03-18 13:31:11,088] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0255\n",
      "[2024-03-18 13:31:11,095] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0339\n",
      "[2024-03-18 13:31:11,636] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=12/39\n",
      "[2024-03-18 13:31:11,637] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:11,639] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=73\n",
      "[2024-03-18 13:31:11,640] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=71\n",
      "[2024-03-18 13:31:11,640] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:11,641] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:31:11,657] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0162\n",
      "[2024-03-18 13:31:11,665] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0211\n",
      "[2024-03-18 13:31:11,673] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0268\n",
      "[2024-03-18 13:31:11,681] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0308\n",
      "[2024-03-18 13:31:12,155] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=13/39\n",
      "[2024-03-18 13:31:12,156] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:12,157] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:12,157] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:12,158] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:12,158] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:31:12,173] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0147\n",
      "[2024-03-18 13:31:12,182] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0207\n",
      "[2024-03-18 13:31:12,190] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0269\n",
      "[2024-03-18 13:31:12,197] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0316\n",
      "[2024-03-18 13:31:12,651] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=14/39\n",
      "[2024-03-18 13:31:12,652] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:12,654] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:31:12,656] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=90\n",
      "[2024-03-18 13:31:12,656] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=86\n",
      "[2024-03-18 13:31:12,656] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=75\n",
      "[2024-03-18 13:31:12,679] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0193\n",
      "[2024-03-18 13:31:12,684] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0217\n",
      "[2024-03-18 13:31:12,690] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0188\n",
      "[2024-03-18 13:31:12,694] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0224\n",
      "[2024-03-18 13:31:13,129] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=15/39\n",
      "[2024-03-18 13:31:13,130] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:13,132] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=105\n",
      "[2024-03-18 13:31:13,132] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=99\n",
      "[2024-03-18 13:31:13,132] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=81\n",
      "[2024-03-18 13:31:13,133] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=72\n",
      "[2024-03-18 13:31:13,152] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0186\n",
      "[2024-03-18 13:31:13,158] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0228\n",
      "[2024-03-18 13:31:13,164] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0163\n",
      "[2024-03-18 13:31:13,170] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0173\n",
      "[2024-03-18 13:31:13,578] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=16/39\n",
      "[2024-03-18 13:31:13,579] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:13,580] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:31:13,580] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:31:13,581] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=72\n",
      "[2024-03-18 13:31:13,584] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:31:13,600] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0152\n",
      "[2024-03-18 13:31:13,607] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0202\n",
      "[2024-03-18 13:31:13,614] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0252\n",
      "[2024-03-18 13:31:13,621] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0258\n",
      "[2024-03-18 13:31:13,997] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=17/39\n",
      "[2024-03-18 13:31:13,998] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:13,999] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:31:14,000] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:14,002] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=68\n",
      "[2024-03-18 13:31:14,003] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=70\n",
      "[2024-03-18 13:31:14,015] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0150\n",
      "[2024-03-18 13:31:14,022] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0181\n",
      "[2024-03-18 13:31:14,029] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0261\n",
      "[2024-03-18 13:31:14,037] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0299\n",
      "[2024-03-18 13:31:14,454] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=18/39\n",
      "[2024-03-18 13:31:14,455] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:14,457] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=87\n",
      "[2024-03-18 13:31:14,457] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=69\n",
      "[2024-03-18 13:31:14,457] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:31:14,457] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:14,474] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0156\n",
      "[2024-03-18 13:31:14,482] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0210\n",
      "[2024-03-18 13:31:14,490] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0269\n",
      "[2024-03-18 13:31:14,497] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0322\n",
      "[2024-03-18 13:31:14,928] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=19/39\n",
      "[2024-03-18 13:31:14,929] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:14,930] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:31:14,931] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:14,931] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:31:14,932] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:14,947] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0149\n",
      "[2024-03-18 13:31:14,955] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0208\n",
      "[2024-03-18 13:31:14,962] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0255\n",
      "[2024-03-18 13:31:14,970] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0315\n",
      "[2024-03-18 13:31:15,396] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=20/39\n",
      "[2024-03-18 13:31:15,398] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:15,399] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:31:15,399] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:15,401] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:15,401] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=63\n",
      "[2024-03-18 13:31:15,415] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0143\n",
      "[2024-03-18 13:31:15,423] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0192\n",
      "[2024-03-18 13:31:15,432] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0268\n",
      "[2024-03-18 13:31:15,438] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0291\n",
      "[2024-03-18 13:31:15,920] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=21/39\n",
      "[2024-03-18 13:31:15,922] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:15,924] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:15,929] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=66\n",
      "[2024-03-18 13:31:15,931] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:15,934] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:15,941] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0150\n",
      "[2024-03-18 13:31:15,949] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0180\n",
      "[2024-03-18 13:31:15,956] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0228\n",
      "[2024-03-18 13:31:15,963] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0262\n",
      "[2024-03-18 13:31:16,407] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=22/39\n",
      "[2024-03-18 13:31:16,408] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:16,410] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=62\n",
      "[2024-03-18 13:31:16,410] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:31:16,411] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=68\n",
      "[2024-03-18 13:31:16,411] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:31:16,426] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0144\n",
      "[2024-03-18 13:31:16,433] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0202\n",
      "[2024-03-18 13:31:16,443] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0278\n",
      "[2024-03-18 13:31:16,449] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0321\n",
      "[2024-03-18 13:31:16,901] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=23/39\n",
      "[2024-03-18 13:31:16,903] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:16,904] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=77\n",
      "[2024-03-18 13:31:16,904] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:16,904] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:31:16,905] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:16,921] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0154\n",
      "[2024-03-18 13:31:16,929] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0206\n",
      "[2024-03-18 13:31:16,938] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0272\n",
      "[2024-03-18 13:31:16,943] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0309\n",
      "[2024-03-18 13:31:17,353] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=24/39\n",
      "[2024-03-18 13:31:17,354] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:17,356] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:17,356] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:31:17,356] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=69\n",
      "[2024-03-18 13:31:17,357] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:17,372] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0144\n",
      "[2024-03-18 13:31:17,379] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0196\n",
      "[2024-03-18 13:31:17,388] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0259\n",
      "[2024-03-18 13:31:17,395] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0312\n",
      "[2024-03-18 13:31:17,846] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=25/39\n",
      "[2024-03-18 13:31:17,848] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:17,850] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:17,850] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:31:17,850] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=60\n",
      "[2024-03-18 13:31:17,851] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=75\n",
      "[2024-03-18 13:31:17,867] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0158\n",
      "[2024-03-18 13:31:17,875] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0211\n",
      "[2024-03-18 13:31:17,883] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0262\n",
      "[2024-03-18 13:31:17,890] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0305\n",
      "[2024-03-18 13:31:18,295] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=26/39\n",
      "[2024-03-18 13:31:18,296] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:18,297] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:31:18,298] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=81\n",
      "[2024-03-18 13:31:18,298] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:31:18,299] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=65\n",
      "[2024-03-18 13:31:18,314] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0143\n",
      "[2024-03-18 13:31:18,322] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0206\n",
      "[2024-03-18 13:31:18,331] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0242\n",
      "[2024-03-18 13:31:18,338] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0291\n",
      "[2024-03-18 13:31:18,806] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=27/39\n",
      "[2024-03-18 13:31:18,807] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:18,809] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=66\n",
      "[2024-03-18 13:31:18,809] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:31:18,809] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=72\n",
      "[2024-03-18 13:31:18,810] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=69\n",
      "[2024-03-18 13:31:18,826] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0153\n",
      "[2024-03-18 13:31:18,834] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0201\n",
      "[2024-03-18 13:31:18,841] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0253\n",
      "[2024-03-18 13:31:18,849] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0311\n",
      "[2024-03-18 13:31:19,406] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=28/39\n",
      "[2024-03-18 13:31:19,408] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:19,410] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:31:19,412] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:31:19,416] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:31:19,417] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:19,431] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0195\n",
      "[2024-03-18 13:31:19,438] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0179\n",
      "[2024-03-18 13:31:19,445] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0168\n",
      "[2024-03-18 13:31:19,479] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0535\n",
      "[2024-03-18 13:31:19,943] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=29/39\n",
      "[2024-03-18 13:31:19,944] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:19,945] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=66\n",
      "[2024-03-18 13:31:19,946] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:19,949] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:19,951] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=62\n",
      "[2024-03-18 13:31:19,963] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0166\n",
      "[2024-03-18 13:31:19,971] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0210\n",
      "[2024-03-18 13:31:19,979] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0265\n",
      "[2024-03-18 13:31:19,987] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0290\n",
      "[2024-03-18 13:31:20,566] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=30/39\n",
      "[2024-03-18 13:31:20,568] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:20,569] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:31:20,570] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:20,570] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=66\n",
      "[2024-03-18 13:31:20,570] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:31:20,587] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0165\n",
      "[2024-03-18 13:31:20,595] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0214\n",
      "[2024-03-18 13:31:20,602] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0262\n",
      "[2024-03-18 13:31:20,610] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0310\n",
      "[2024-03-18 13:31:21,042] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=31/39\n",
      "[2024-03-18 13:31:21,043] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:21,047] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:21,047] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:31:21,047] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:21,047] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:21,066] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0178\n",
      "[2024-03-18 13:31:21,070] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0200\n",
      "[2024-03-18 13:31:21,078] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0253\n",
      "[2024-03-18 13:31:21,085] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0289\n",
      "[2024-03-18 13:31:21,575] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=32/39\n",
      "[2024-03-18 13:31:21,576] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:21,577] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:31:21,578] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=84\n",
      "[2024-03-18 13:31:21,578] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:21,578] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:31:21,594] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0151\n",
      "[2024-03-18 13:31:21,601] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0200\n",
      "[2024-03-18 13:31:21,609] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0248\n",
      "[2024-03-18 13:31:21,616] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0302\n",
      "[2024-03-18 13:31:22,014] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=33/39\n",
      "[2024-03-18 13:31:22,016] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:22,017] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:22,018] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=57\n",
      "[2024-03-18 13:31:22,020] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=55\n",
      "[2024-03-18 13:31:22,020] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:22,035] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0168\n",
      "[2024-03-18 13:31:22,042] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0211\n",
      "[2024-03-18 13:31:22,049] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0258\n",
      "[2024-03-18 13:31:22,057] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0314\n",
      "[2024-03-18 13:31:22,542] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=34/39\n",
      "[2024-03-18 13:31:22,543] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:22,544] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=74\n",
      "[2024-03-18 13:31:22,544] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=57\n",
      "[2024-03-18 13:31:22,545] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=55\n",
      "[2024-03-18 13:31:22,545] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=60\n",
      "[2024-03-18 13:31:22,561] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0160\n",
      "[2024-03-18 13:31:22,569] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0203\n",
      "[2024-03-18 13:31:22,576] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0252\n",
      "[2024-03-18 13:31:22,584] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0300\n",
      "[2024-03-18 13:31:23,139] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=35/39\n",
      "[2024-03-18 13:31:23,140] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:23,142] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=99\n",
      "[2024-03-18 13:31:23,142] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:31:23,142] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=74\n",
      "[2024-03-18 13:31:23,145] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=66\n",
      "[2024-03-18 13:31:23,160] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0165\n",
      "[2024-03-18 13:31:23,167] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0208\n",
      "[2024-03-18 13:31:23,174] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0255\n",
      "[2024-03-18 13:31:23,182] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0310\n",
      "[2024-03-18 13:31:23,692] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=36/39\n",
      "[2024-03-18 13:31:23,693] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:23,695] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:31:23,695] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:31:23,695] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:23,696] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=60\n",
      "[2024-03-18 13:31:23,713] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0166\n",
      "[2024-03-18 13:31:23,721] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0214\n",
      "[2024-03-18 13:31:23,728] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0257\n",
      "[2024-03-18 13:31:23,736] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0308\n",
      "[2024-03-18 13:31:24,344] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=37/39\n",
      "[2024-03-18 13:31:24,345] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:24,347] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=84\n",
      "[2024-03-18 13:31:24,347] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:24,347] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:24,349] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:24,363] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0156\n",
      "[2024-03-18 13:31:24,370] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0204\n",
      "[2024-03-18 13:31:24,378] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0249\n",
      "[2024-03-18 13:31:24,385] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0286\n",
      "[2024-03-18 13:31:24,815] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=38/39\n",
      "[2024-03-18 13:31:24,816] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:24,818] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:24,818] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:31:24,818] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:24,818] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:31:24,834] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0146\n",
      "[2024-03-18 13:31:24,842] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0191\n",
      "[2024-03-18 13:31:24,849] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0242\n",
      "[2024-03-18 13:31:24,858] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0301\n",
      "[2024-03-18 13:31:25,292] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=39/39\n",
      "[2024-03-18 13:31:25,293] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=4\n",
      "[2024-03-18 13:31:25,294] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:31:25,295] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:31:25,298] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:31:25,301] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:31:25,314] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0183\n",
      "[2024-03-18 13:31:25,323] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0229\n",
      "[2024-03-18 13:31:25,329] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0268\n",
      "[2024-03-18 13:31:25,335] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0308\n",
      "[2024-03-18 13:31:25,788] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=1/26\n",
      "[2024-03-18 13:31:25,789] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=6\n",
      "[2024-03-18 13:31:25,790] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:25,791] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=62\n",
      "[2024-03-18 13:31:25,791] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=77\n",
      "[2024-03-18 13:31:25,793] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:25,793] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=82\n",
      "[2024-03-18 13:31:25,794] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:25,812] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0194\n",
      "[2024-03-18 13:31:25,814] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0188\n",
      "[2024-03-18 13:31:25,824] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0221\n",
      "[2024-03-18 13:31:25,830] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0251\n",
      "[2024-03-18 13:31:25,867] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0635\n",
      "[2024-03-18 13:31:25,880] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0710\n",
      "[2024-03-18 13:31:26,484] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=2/26\n",
      "[2024-03-18 13:31:26,485] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=6\n",
      "[2024-03-18 13:31:26,487] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:26,487] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:26,488] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=69\n",
      "[2024-03-18 13:31:26,488] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=60\n",
      "[2024-03-18 13:31:26,489] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:31:26,495] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:26,506] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0174\n",
      "[2024-03-18 13:31:26,515] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0237\n",
      "[2024-03-18 13:31:26,522] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0283\n",
      "[2024-03-18 13:31:26,531] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0355\n",
      "[2024-03-18 13:31:26,538] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0396\n",
      "[2024-03-18 13:31:26,545] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0449\n",
      "[2024-03-18 13:31:27,087] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=3/26\n",
      "[2024-03-18 13:31:27,088] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=6\n",
      "[2024-03-18 13:31:27,089] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=75\n",
      "[2024-03-18 13:31:27,090] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=65\n",
      "[2024-03-18 13:31:27,090] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=57\n",
      "[2024-03-18 13:31:27,090] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:27,090] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:27,091] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:31:27,106] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0153\n",
      "[2024-03-18 13:31:27,114] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0208\n",
      "[2024-03-18 13:31:27,121] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0262\n",
      "[2024-03-18 13:31:27,129] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0316\n",
      "[2024-03-18 13:31:27,137] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0370\n",
      "[2024-03-18 13:31:27,144] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0418\n",
      "[2024-03-18 13:31:27,871] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=4/26\n",
      "[2024-03-18 13:31:27,872] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=6\n",
      "[2024-03-18 13:31:27,873] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:31:27,874] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:27,874] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:27,874] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:27,876] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=60\n",
      "[2024-03-18 13:31:27,876] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:31:27,890] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0155\n",
      "[2024-03-18 13:31:27,897] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0200\n",
      "[2024-03-18 13:31:27,905] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0242\n",
      "[2024-03-18 13:31:27,912] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0287\n",
      "[2024-03-18 13:31:27,919] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0396\n",
      "[2024-03-18 13:31:27,927] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0405\n",
      "[2024-03-18 13:31:28,584] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=5/26\n",
      "[2024-03-18 13:31:28,586] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=6\n",
      "[2024-03-18 13:31:28,588] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:28,589] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=65\n",
      "[2024-03-18 13:31:28,589] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:28,592] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=55\n",
      "[2024-03-18 13:31:28,592] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=63\n",
      "[2024-03-18 13:31:28,594] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=62\n",
      "[2024-03-18 13:31:28,608] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0183\n",
      "[2024-03-18 13:31:28,617] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0217\n",
      "[2024-03-18 13:31:28,623] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0138\n",
      "[2024-03-18 13:31:28,630] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0169\n",
      "[2024-03-18 13:31:28,637] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0200\n",
      "[2024-03-18 13:31:28,646] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0265\n",
      "[2024-03-18 13:31:29,549] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=6/26\n",
      "[2024-03-18 13:31:29,551] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=6\n",
      "[2024-03-18 13:31:29,553] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:29,559] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:29,559] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:31:29,559] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:29,560] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:31:29,560] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=57\n",
      "[2024-03-18 13:31:29,581] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0238\n",
      "[2024-03-18 13:31:29,582] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0206\n",
      "[2024-03-18 13:31:29,585] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0207\n",
      "[2024-03-18 13:31:29,593] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0260\n",
      "[2024-03-18 13:31:29,601] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0312\n",
      "[2024-03-18 13:31:29,608] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0335\n",
      "[2024-03-18 13:31:30,287] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=7/26\n",
      "[2024-03-18 13:31:30,288] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=6\n",
      "[2024-03-18 13:31:30,290] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:31:30,291] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:30,294] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:30,295] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=60\n",
      "[2024-03-18 13:31:30,295] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=65\n",
      "[2024-03-18 13:31:30,295] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:30,309] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0179\n",
      "[2024-03-18 13:31:30,315] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0188\n",
      "[2024-03-18 13:31:30,323] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0233\n",
      "[2024-03-18 13:31:30,331] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0286\n",
      "[2024-03-18 13:31:30,338] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0336\n",
      "[2024-03-18 13:31:30,347] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0401\n",
      "[2024-03-18 13:31:30,992] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=8/26\n",
      "[2024-03-18 13:31:30,993] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=6\n",
      "[2024-03-18 13:31:30,994] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=57\n",
      "[2024-03-18 13:31:30,995] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:30,995] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=71\n",
      "[2024-03-18 13:31:30,998] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:31:30,998] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=73\n",
      "[2024-03-18 13:31:30,998] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:31,016] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0192\n",
      "[2024-03-18 13:31:31,019] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0196\n",
      "[2024-03-18 13:31:31,027] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0243\n",
      "[2024-03-18 13:31:31,034] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0275\n",
      "[2024-03-18 13:31:31,042] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0318\n",
      "[2024-03-18 13:31:31,050] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0368\n",
      "[2024-03-18 13:31:31,646] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=9/26\n",
      "[2024-03-18 13:31:31,649] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=6\n",
      "[2024-03-18 13:31:31,651] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:31:31,651] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:31,651] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:31,652] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:31:31,652] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:31,653] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=75\n",
      "[2024-03-18 13:31:31,679] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0245\n",
      "[2024-03-18 13:31:31,681] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0187\n",
      "[2024-03-18 13:31:31,698] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0333\n",
      "[2024-03-18 13:31:31,708] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0271\n",
      "[2024-03-18 13:31:31,708] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0176\n",
      "[2024-03-18 13:31:31,714] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0189\n",
      "[2024-03-18 13:31:32,285] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=10/26\n",
      "[2024-03-18 13:31:32,286] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=6\n",
      "[2024-03-18 13:31:32,288] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=86\n",
      "[2024-03-18 13:31:32,289] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=90\n",
      "[2024-03-18 13:31:32,289] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=105\n",
      "[2024-03-18 13:31:32,290] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=81\n",
      "[2024-03-18 13:31:32,290] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=99\n",
      "[2024-03-18 13:31:32,292] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=72\n",
      "[2024-03-18 13:31:32,305] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0152\n",
      "[2024-03-18 13:31:32,314] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0204\n",
      "[2024-03-18 13:31:32,320] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0252\n",
      "[2024-03-18 13:31:32,328] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0303\n",
      "[2024-03-18 13:31:32,336] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0361\n",
      "[2024-03-18 13:31:32,344] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0416\n",
      "[2024-03-18 13:31:32,961] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=11/26\n",
      "[2024-03-18 13:31:32,963] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=6\n",
      "[2024-03-18 13:31:32,964] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:31:32,965] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:31:32,965] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=72\n",
      "[2024-03-18 13:31:32,970] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:31:32,974] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:32,976] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:31:32,995] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0287\n",
      "[2024-03-18 13:31:33,000] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0198\n",
      "[2024-03-18 13:31:33,003] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0188\n",
      "[2024-03-18 13:31:33,011] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0224\n",
      "[2024-03-18 13:31:33,019] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0231\n",
      "[2024-03-18 13:31:33,026] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0251\n",
      "[2024-03-18 13:31:33,669] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=12/26\n",
      "[2024-03-18 13:31:33,670] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=6\n",
      "[2024-03-18 13:31:33,671] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=68\n",
      "[2024-03-18 13:31:33,673] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=70\n",
      "[2024-03-18 13:31:33,674] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=87\n",
      "[2024-03-18 13:31:33,674] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=69\n",
      "[2024-03-18 13:31:33,675] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:33,676] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:31:33,686] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0140\n",
      "[2024-03-18 13:31:33,694] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0191\n",
      "[2024-03-18 13:31:33,702] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0249\n",
      "[2024-03-18 13:31:33,709] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0296\n",
      "[2024-03-18 13:31:33,717] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0359\n",
      "[2024-03-18 13:31:33,725] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0414\n",
      "[2024-03-18 13:31:34,271] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=13/26\n",
      "[2024-03-18 13:31:34,272] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=6\n",
      "[2024-03-18 13:31:34,273] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:31:34,274] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:34,276] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:31:34,276] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:34,276] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:31:34,277] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:34,290] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0150\n",
      "[2024-03-18 13:31:34,298] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0206\n",
      "[2024-03-18 13:31:34,305] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0252\n",
      "[2024-03-18 13:31:34,312] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0299\n",
      "[2024-03-18 13:31:34,320] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0354\n",
      "[2024-03-18 13:31:34,328] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0411\n",
      "[2024-03-18 13:31:34,932] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=14/26\n",
      "[2024-03-18 13:31:34,933] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=6\n",
      "[2024-03-18 13:31:34,934] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:34,935] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=63\n",
      "[2024-03-18 13:31:34,935] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:34,936] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:34,938] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=66\n",
      "[2024-03-18 13:31:34,939] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:34,951] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0153\n",
      "[2024-03-18 13:31:34,958] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0163\n",
      "[2024-03-18 13:31:34,966] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0264\n",
      "[2024-03-18 13:31:34,973] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0283\n",
      "[2024-03-18 13:31:34,980] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0341\n",
      "[2024-03-18 13:31:34,987] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0390\n",
      "[2024-03-18 13:31:35,613] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=15/26\n",
      "[2024-03-18 13:31:35,614] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=6\n",
      "[2024-03-18 13:31:35,615] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=62\n",
      "[2024-03-18 13:31:35,616] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:31:35,619] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=68\n",
      "[2024-03-18 13:31:35,621] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:31:35,625] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:35,635] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0181\n",
      "[2024-03-18 13:31:35,636] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=77\n",
      "[2024-03-18 13:31:35,643] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0200\n",
      "[2024-03-18 13:31:35,648] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0201\n",
      "[2024-03-18 13:31:35,655] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0185\n",
      "[2024-03-18 13:31:35,663] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0247\n",
      "[2024-03-18 13:31:35,671] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0267\n",
      "[2024-03-18 13:31:36,365] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=16/26\n",
      "[2024-03-18 13:31:36,369] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=6\n",
      "[2024-03-18 13:31:36,372] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:31:36,375] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:36,379] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:36,385] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:36,385] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=69\n",
      "[2024-03-18 13:31:36,390] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:31:36,398] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0209\n",
      "[2024-03-18 13:31:36,406] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0308\n",
      "[2024-03-18 13:31:36,410] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0254\n",
      "[2024-03-18 13:31:36,418] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0243\n",
      "[2024-03-18 13:31:36,426] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0263\n",
      "[2024-03-18 13:31:36,435] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0308\n",
      "[2024-03-18 13:31:37,109] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=17/26\n",
      "[2024-03-18 13:31:37,110] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=6\n",
      "[2024-03-18 13:31:37,112] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:37,112] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:31:37,114] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=60\n",
      "[2024-03-18 13:31:37,115] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=75\n",
      "[2024-03-18 13:31:37,117] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:31:37,119] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=81\n",
      "[2024-03-18 13:31:37,136] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0219\n",
      "[2024-03-18 13:31:37,139] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0228\n",
      "[2024-03-18 13:31:37,146] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0260\n",
      "[2024-03-18 13:31:37,155] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0321\n",
      "[2024-03-18 13:31:37,162] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0343\n",
      "[2024-03-18 13:31:37,169] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0373\n",
      "[2024-03-18 13:31:37,833] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=18/26\n",
      "[2024-03-18 13:31:37,834] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=6\n",
      "[2024-03-18 13:31:37,837] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:31:37,837] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:31:37,838] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=66\n",
      "[2024-03-18 13:31:37,841] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=72\n",
      "[2024-03-18 13:31:37,841] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=65\n",
      "[2024-03-18 13:31:37,841] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=69\n",
      "[2024-03-18 13:31:37,857] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0183\n",
      "[2024-03-18 13:31:37,868] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0207\n",
      "[2024-03-18 13:31:37,871] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0211\n",
      "[2024-03-18 13:31:37,877] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0247\n",
      "[2024-03-18 13:31:37,886] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0281\n",
      "[2024-03-18 13:31:37,892] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0313\n",
      "[2024-03-18 13:31:38,546] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=19/26\n",
      "[2024-03-18 13:31:38,548] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=6\n",
      "[2024-03-18 13:31:38,550] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:31:38,550] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:31:38,550] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:38,551] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:31:38,553] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=66\n",
      "[2024-03-18 13:31:38,554] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=62\n",
      "[2024-03-18 13:31:38,582] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0227\n",
      "[2024-03-18 13:31:38,584] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0249\n",
      "[2024-03-18 13:31:38,588] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0272\n",
      "[2024-03-18 13:31:38,596] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0307\n",
      "[2024-03-18 13:31:38,603] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0327\n",
      "[2024-03-18 13:31:38,611] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0334\n",
      "[2024-03-18 13:31:39,190] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=20/26\n",
      "[2024-03-18 13:31:39,191] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=6\n",
      "[2024-03-18 13:31:39,192] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:39,193] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:39,194] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:31:39,194] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:31:39,196] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:39,207] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=66\n",
      "[2024-03-18 13:31:39,232] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0336\n",
      "[2024-03-18 13:31:39,241] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0255\n",
      "[2024-03-18 13:31:39,242] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0280\n",
      "[2024-03-18 13:31:39,245] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0234\n",
      "[2024-03-18 13:31:39,255] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0241\n",
      "[2024-03-18 13:31:39,259] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0209\n",
      "[2024-03-18 13:31:39,958] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=21/26\n",
      "[2024-03-18 13:31:39,960] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=6\n",
      "[2024-03-18 13:31:39,963] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:39,964] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:39,964] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:31:39,965] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:39,965] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:31:39,965] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=84\n",
      "[2024-03-18 13:31:39,989] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0196\n",
      "[2024-03-18 13:31:39,992] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0195\n",
      "[2024-03-18 13:31:39,999] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0221\n",
      "[2024-03-18 13:31:40,012] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0314\n",
      "[2024-03-18 13:31:40,016] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0274\n",
      "[2024-03-18 13:31:40,021] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0281\n",
      "[2024-03-18 13:31:40,722] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=22/26\n",
      "[2024-03-18 13:31:40,724] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=6\n",
      "[2024-03-18 13:31:40,726] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:40,728] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:40,729] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:31:40,730] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=55\n",
      "[2024-03-18 13:31:40,730] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=57\n",
      "[2024-03-18 13:31:40,730] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:40,745] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0188\n",
      "[2024-03-18 13:31:40,751] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0200\n",
      "[2024-03-18 13:31:40,760] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0241\n",
      "[2024-03-18 13:31:40,767] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0283\n",
      "[2024-03-18 13:31:40,775] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0342\n",
      "[2024-03-18 13:31:40,783] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0402\n",
      "[2024-03-18 13:31:41,478] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=23/26\n",
      "[2024-03-18 13:31:41,479] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=6\n",
      "[2024-03-18 13:31:41,481] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=57\n",
      "[2024-03-18 13:31:41,482] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=74\n",
      "[2024-03-18 13:31:41,482] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=55\n",
      "[2024-03-18 13:31:41,483] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=60\n",
      "[2024-03-18 13:31:41,485] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=99\n",
      "[2024-03-18 13:31:41,485] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=74\n",
      "[2024-03-18 13:31:41,501] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0181\n",
      "[2024-03-18 13:31:41,508] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0216\n",
      "[2024-03-18 13:31:41,516] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0264\n",
      "[2024-03-18 13:31:41,523] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0308\n",
      "[2024-03-18 13:31:41,532] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0363\n",
      "[2024-03-18 13:31:41,540] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0420\n",
      "[2024-03-18 13:31:42,140] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=24/26\n",
      "[2024-03-18 13:31:42,141] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=6\n",
      "[2024-03-18 13:31:42,143] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:31:42,143] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=66\n",
      "[2024-03-18 13:31:42,143] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:31:42,144] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:31:42,145] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=60\n",
      "[2024-03-18 13:31:42,146] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:42,161] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0168\n",
      "[2024-03-18 13:31:42,169] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0213\n",
      "[2024-03-18 13:31:42,177] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0265\n",
      "[2024-03-18 13:31:42,184] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0310\n",
      "[2024-03-18 13:31:42,191] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0371\n",
      "[2024-03-18 13:31:42,199] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0405\n",
      "[2024-03-18 13:31:42,903] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=25/26\n",
      "[2024-03-18 13:31:42,905] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=6\n",
      "[2024-03-18 13:31:42,906] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=84\n",
      "[2024-03-18 13:31:42,906] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:42,906] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:42,907] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:42,909] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:42,911] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:31:42,927] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0184\n",
      "[2024-03-18 13:31:42,930] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0204\n",
      "[2024-03-18 13:31:42,938] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0246\n",
      "[2024-03-18 13:31:42,946] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0309\n",
      "[2024-03-18 13:31:42,953] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0336\n",
      "[2024-03-18 13:31:42,960] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0344\n",
      "[2024-03-18 13:31:43,938] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=26/26\n",
      "[2024-03-18 13:31:43,939] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=6\n",
      "[2024-03-18 13:31:43,941] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:31:43,942] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:43,943] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:31:43,943] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:31:43,946] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:31:43,947] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:31:43,962] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0183\n",
      "[2024-03-18 13:31:43,968] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0199\n",
      "[2024-03-18 13:31:43,975] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0241\n",
      "[2024-03-18 13:31:43,983] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0281\n",
      "[2024-03-18 13:31:43,990] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0330\n",
      "[2024-03-18 13:31:43,998] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0381\n",
      "[2024-03-18 13:31:44,604] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=1/20\n",
      "[2024-03-18 13:31:44,605] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=8\n",
      "[2024-03-18 13:31:44,608] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=77\n",
      "[2024-03-18 13:31:44,608] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:44,608] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:44,610] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=82\n",
      "[2024-03-18 13:31:44,610] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=62\n",
      "[2024-03-18 13:31:44,610] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:44,613] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:44,614] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:44,629] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0167\n",
      "[2024-03-18 13:31:44,638] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0229\n",
      "[2024-03-18 13:31:44,641] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0243\n",
      "[2024-03-18 13:31:44,649] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0295\n",
      "[2024-03-18 13:31:44,657] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0350\n",
      "[2024-03-18 13:31:44,664] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0374\n",
      "[2024-03-18 13:31:44,672] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0410\n",
      "[2024-03-18 13:31:44,705] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0700\n",
      "[2024-03-18 13:31:45,596] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=2/20\n",
      "[2024-03-18 13:31:45,597] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=8\n",
      "[2024-03-18 13:31:45,599] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=69\n",
      "[2024-03-18 13:31:45,599] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:31:45,599] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=60\n",
      "[2024-03-18 13:31:45,600] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:45,602] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=75\n",
      "[2024-03-18 13:31:45,602] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=57\n",
      "[2024-03-18 13:31:45,602] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=65\n",
      "[2024-03-18 13:31:45,602] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:45,619] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0184\n",
      "[2024-03-18 13:31:45,642] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0355\n",
      "[2024-03-18 13:31:45,634] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0223\n",
      "[2024-03-18 13:31:45,630] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0272\n",
      "[2024-03-18 13:31:45,649] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0279\n",
      "[2024-03-18 13:31:45,655] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0297\n",
      "[2024-03-18 13:31:45,665] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0345\n",
      "[2024-03-18 13:31:45,671] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0361\n",
      "[2024-03-18 13:31:46,393] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=3/20\n",
      "[2024-03-18 13:31:46,394] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=8\n",
      "[2024-03-18 13:31:46,396] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:46,396] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:31:46,397] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:31:46,397] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:46,398] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:46,400] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:46,401] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:31:46,401] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=60\n",
      "[2024-03-18 13:31:46,414] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0158\n",
      "[2024-03-18 13:31:46,425] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0229\n",
      "[2024-03-18 13:31:46,433] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0271\n",
      "[2024-03-18 13:31:46,441] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0236\n",
      "[2024-03-18 13:31:46,445] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0261\n",
      "[2024-03-18 13:31:46,458] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0352\n",
      "[2024-03-18 13:31:46,465] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0397\n",
      "[2024-03-18 13:31:46,477] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0478\n",
      "[2024-03-18 13:31:47,349] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=4/20\n",
      "[2024-03-18 13:31:47,350] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=8\n",
      "[2024-03-18 13:31:47,352] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=65\n",
      "[2024-03-18 13:31:47,353] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:47,354] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=63\n",
      "[2024-03-18 13:31:47,355] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:47,357] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=55\n",
      "[2024-03-18 13:31:47,358] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=62\n",
      "[2024-03-18 13:31:47,358] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:47,360] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:47,374] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0192\n",
      "[2024-03-18 13:31:47,383] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0228\n",
      "[2024-03-18 13:31:47,389] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0247\n",
      "[2024-03-18 13:31:47,396] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0271\n",
      "[2024-03-18 13:31:47,405] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0341\n",
      "[2024-03-18 13:31:47,410] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0353\n",
      "[2024-03-18 13:31:47,420] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0410\n",
      "[2024-03-18 13:31:47,430] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0465\n",
      "[2024-03-18 13:31:48,166] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=5/20\n",
      "[2024-03-18 13:31:48,167] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=8\n",
      "[2024-03-18 13:31:48,169] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:31:48,169] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=57\n",
      "[2024-03-18 13:31:48,169] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:31:48,170] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:48,170] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:31:48,171] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:48,184] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=65\n",
      "[2024-03-18 13:31:48,184] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:48,197] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0255\n",
      "[2024-03-18 13:31:48,213] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0303\n",
      "[2024-03-18 13:31:48,214] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0223\n",
      "[2024-03-18 13:31:48,223] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0184\n",
      "[2024-03-18 13:31:48,230] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0224\n",
      "[2024-03-18 13:31:48,250] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0290\n",
      "[2024-03-18 13:31:48,254] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0379\n",
      "[2024-03-18 13:31:48,258] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0319\n",
      "[2024-03-18 13:31:49,101] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=6/20\n",
      "[2024-03-18 13:31:49,102] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=8\n",
      "[2024-03-18 13:31:49,107] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=60\n",
      "[2024-03-18 13:31:49,108] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:49,113] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=57\n",
      "[2024-03-18 13:31:49,113] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:49,115] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=73\n",
      "[2024-03-18 13:31:49,116] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=71\n",
      "[2024-03-18 13:31:49,118] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:49,121] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:31:49,133] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0202\n",
      "[2024-03-18 13:31:49,136] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0275\n",
      "[2024-03-18 13:31:49,147] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0267\n",
      "[2024-03-18 13:31:49,150] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0309\n",
      "[2024-03-18 13:31:49,155] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0335\n",
      "[2024-03-18 13:31:49,165] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0400\n",
      "[2024-03-18 13:31:49,171] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0380\n",
      "[2024-03-18 13:31:49,178] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0394\n",
      "[2024-03-18 13:31:50,077] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=7/20\n",
      "[2024-03-18 13:31:50,078] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=8\n",
      "[2024-03-18 13:31:50,087] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:31:50,087] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:50,087] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:50,088] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:50,094] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:31:50,094] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=75\n",
      "[2024-03-18 13:31:50,100] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=90\n",
      "[2024-03-18 13:31:50,124] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=86\n",
      "[2024-03-18 13:31:50,138] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0381\n",
      "[2024-03-18 13:31:50,186] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0267\n",
      "[2024-03-18 13:31:50,161] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0215\n",
      "[2024-03-18 13:31:50,184] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0384\n",
      "[2024-03-18 13:31:50,151] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0205\n",
      "[2024-03-18 13:31:50,188] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0325\n",
      "[2024-03-18 13:31:50,190] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0245\n",
      "[2024-03-18 13:31:50,203] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0216\n",
      "[2024-03-18 13:31:51,024] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=8/20\n",
      "[2024-03-18 13:31:51,027] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=8\n",
      "[2024-03-18 13:31:51,029] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=81\n",
      "[2024-03-18 13:31:51,030] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=99\n",
      "[2024-03-18 13:31:51,030] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=72\n",
      "[2024-03-18 13:31:51,030] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=105\n",
      "[2024-03-18 13:31:51,030] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:31:51,032] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:31:51,032] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=72\n",
      "[2024-03-18 13:31:51,036] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:31:51,049] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0159\n",
      "[2024-03-18 13:31:51,057] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0227\n",
      "[2024-03-18 13:31:51,066] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0282\n",
      "[2024-03-18 13:31:51,069] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0291\n",
      "[2024-03-18 13:31:51,077] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0346\n",
      "[2024-03-18 13:31:51,085] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0398\n",
      "[2024-03-18 13:31:51,093] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0446\n",
      "[2024-03-18 13:31:51,101] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0482\n",
      "[2024-03-18 13:31:52,118] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=9/20\n",
      "[2024-03-18 13:31:52,121] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=8\n",
      "[2024-03-18 13:31:52,122] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:52,123] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:31:52,123] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=68\n",
      "[2024-03-18 13:31:52,123] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=70\n",
      "[2024-03-18 13:31:52,124] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=87\n",
      "[2024-03-18 13:31:52,125] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=69\n",
      "[2024-03-18 13:31:52,128] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:52,132] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:31:52,147] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0226\n",
      "[2024-03-18 13:31:52,151] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0209\n",
      "[2024-03-18 13:31:52,159] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0237\n",
      "[2024-03-18 13:31:52,166] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0263\n",
      "[2024-03-18 13:31:52,171] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0264\n",
      "[2024-03-18 13:31:52,179] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0305\n",
      "[2024-03-18 13:31:52,190] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0370\n",
      "[2024-03-18 13:31:52,193] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0378\n",
      "[2024-03-18 13:31:52,963] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=10/20\n",
      "[2024-03-18 13:31:52,964] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=8\n",
      "[2024-03-18 13:31:52,966] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:31:52,966] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:52,967] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:31:52,968] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:52,968] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:31:52,969] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:52,969] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:52,973] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=63\n",
      "[2024-03-18 13:31:52,985] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0159\n",
      "[2024-03-18 13:31:52,995] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0224\n",
      "[2024-03-18 13:31:52,999] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0249\n",
      "[2024-03-18 13:31:53,007] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0256\n",
      "[2024-03-18 13:31:53,013] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0284\n",
      "[2024-03-18 13:31:53,023] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0345\n",
      "[2024-03-18 13:31:53,028] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0354\n",
      "[2024-03-18 13:31:53,037] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0402\n",
      "[2024-03-18 13:31:53,816] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=11/20\n",
      "[2024-03-18 13:31:53,817] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=8\n",
      "[2024-03-18 13:31:53,819] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:53,819] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=66\n",
      "[2024-03-18 13:31:53,820] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:53,820] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:53,821] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=62\n",
      "[2024-03-18 13:31:53,821] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:31:53,821] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:31:53,821] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=68\n",
      "[2024-03-18 13:31:53,845] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0221\n",
      "[2024-03-18 13:31:53,849] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0219\n",
      "[2024-03-18 13:31:53,856] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0229\n",
      "[2024-03-18 13:31:53,868] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0385\n",
      "[2024-03-18 13:31:53,871] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0351\n",
      "[2024-03-18 13:31:53,879] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0401\n",
      "[2024-03-18 13:31:53,888] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0430\n",
      "[2024-03-18 13:31:53,896] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0469\n",
      "[2024-03-18 13:31:54,750] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=12/20\n",
      "[2024-03-18 13:31:54,752] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=8\n",
      "[2024-03-18 13:31:54,753] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=77\n",
      "[2024-03-18 13:31:54,754] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:54,756] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:31:54,757] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:54,757] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:31:54,759] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=69\n",
      "[2024-03-18 13:31:54,762] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:31:54,766] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:54,780] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0242\n",
      "[2024-03-18 13:31:54,785] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0241\n",
      "[2024-03-18 13:31:54,794] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0276\n",
      "[2024-03-18 13:31:54,799] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0304\n",
      "[2024-03-18 13:31:54,807] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0326\n",
      "[2024-03-18 13:31:54,815] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0344\n",
      "[2024-03-18 13:31:54,823] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0365\n",
      "[2024-03-18 13:31:54,830] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0394\n",
      "[2024-03-18 13:31:55,618] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=13/20\n",
      "[2024-03-18 13:31:55,620] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=8\n",
      "[2024-03-18 13:31:55,624] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:55,625] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:31:55,625] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=60\n",
      "[2024-03-18 13:31:55,628] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=75\n",
      "[2024-03-18 13:31:55,630] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:31:55,631] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=81\n",
      "[2024-03-18 13:31:55,632] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:31:55,633] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=65\n",
      "[2024-03-18 13:31:55,648] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0205\n",
      "[2024-03-18 13:31:55,659] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0280\n",
      "[2024-03-18 13:31:55,660] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0253\n",
      "[2024-03-18 13:31:55,665] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0286\n",
      "[2024-03-18 13:31:55,672] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0325\n",
      "[2024-03-18 13:31:55,679] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0328\n",
      "[2024-03-18 13:31:55,687] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0375\n",
      "[2024-03-18 13:31:55,695] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0418\n",
      "[2024-03-18 13:31:56,522] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=14/20\n",
      "[2024-03-18 13:31:56,524] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=8\n",
      "[2024-03-18 13:31:56,525] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:31:56,526] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=72\n",
      "[2024-03-18 13:31:56,526] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=69\n",
      "[2024-03-18 13:31:56,526] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:31:56,526] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:31:56,526] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=66\n",
      "[2024-03-18 13:31:56,527] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:56,529] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:31:56,544] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0162\n",
      "[2024-03-18 13:31:56,551] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0203\n",
      "[2024-03-18 13:31:56,559] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0259\n",
      "[2024-03-18 13:31:56,566] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0304\n",
      "[2024-03-18 13:31:56,574] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0357\n",
      "[2024-03-18 13:31:56,581] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0403\n",
      "[2024-03-18 13:31:56,588] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0437\n",
      "[2024-03-18 13:31:56,596] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0487\n",
      "[2024-03-18 13:31:57,545] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=15/20\n",
      "[2024-03-18 13:31:57,546] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=8\n",
      "[2024-03-18 13:31:57,548] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=66\n",
      "[2024-03-18 13:31:57,548] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=62\n",
      "[2024-03-18 13:31:57,548] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:57,548] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:57,549] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:31:57,549] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:31:57,549] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:57,549] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=66\n",
      "[2024-03-18 13:31:57,564] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0145\n",
      "[2024-03-18 13:31:57,572] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0201\n",
      "[2024-03-18 13:31:57,580] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0256\n",
      "[2024-03-18 13:31:57,587] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0311\n",
      "[2024-03-18 13:31:57,594] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0356\n",
      "[2024-03-18 13:31:57,601] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0406\n",
      "[2024-03-18 13:31:57,609] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0424\n",
      "[2024-03-18 13:31:57,617] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0487\n",
      "[2024-03-18 13:31:58,858] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=16/20\n",
      "[2024-03-18 13:31:58,860] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=8\n",
      "[2024-03-18 13:31:58,861] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:58,861] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:31:58,862] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:31:58,863] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:31:58,863] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=61\n",
      "[2024-03-18 13:31:58,865] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=84\n",
      "[2024-03-18 13:31:58,865] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:58,868] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:31:58,884] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0214\n",
      "[2024-03-18 13:31:58,887] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0212\n",
      "[2024-03-18 13:31:58,893] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0267\n",
      "[2024-03-18 13:31:58,902] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0305\n",
      "[2024-03-18 13:31:58,910] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0368\n",
      "[2024-03-18 13:31:58,918] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0410\n",
      "[2024-03-18 13:31:58,926] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0457\n",
      "[2024-03-18 13:31:58,933] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0468\n",
      "[2024-03-18 13:31:59,788] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=17/20\n",
      "[2024-03-18 13:31:59,790] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=8\n",
      "[2024-03-18 13:31:59,791] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:59,791] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=55\n",
      "[2024-03-18 13:31:59,792] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=57\n",
      "[2024-03-18 13:31:59,792] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=74\n",
      "[2024-03-18 13:31:59,792] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:31:59,793] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=55\n",
      "[2024-03-18 13:31:59,821] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0215\n",
      "[2024-03-18 13:31:59,796] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=60\n",
      "[2024-03-18 13:31:59,813] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0186\n",
      "[2024-03-18 13:31:59,793] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=57\n",
      "[2024-03-18 13:31:59,825] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0219\n",
      "[2024-03-18 13:31:59,835] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0232\n",
      "[2024-03-18 13:31:59,838] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0246\n",
      "[2024-03-18 13:31:59,846] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0257\n",
      "[2024-03-18 13:31:59,853] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0268\n",
      "[2024-03-18 13:31:59,860] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0287\n",
      "[2024-03-18 13:32:00,622] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=18/20\n",
      "[2024-03-18 13:32:00,624] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=8\n",
      "[2024-03-18 13:32:00,625] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=74\n",
      "[2024-03-18 13:32:00,626] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:32:00,626] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=99\n",
      "[2024-03-18 13:32:00,629] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=66\n",
      "[2024-03-18 13:32:00,630] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:32:00,633] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:32:00,633] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=60\n",
      "[2024-03-18 13:32:00,635] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=58\n",
      "[2024-03-18 13:32:00,649] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0167\n",
      "[2024-03-18 13:32:00,657] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0248\n",
      "[2024-03-18 13:32:00,662] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0255\n",
      "[2024-03-18 13:32:00,678] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0358\n",
      "[2024-03-18 13:32:00,680] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0295\n",
      "[2024-03-18 13:32:00,685] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0277\n",
      "[2024-03-18 13:32:00,692] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0283\n",
      "[2024-03-18 13:32:00,697] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0317\n",
      "[2024-03-18 13:32:01,523] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=19/20\n",
      "[2024-03-18 13:32:01,524] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=8\n",
      "[2024-03-18 13:32:01,527] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=84\n",
      "[2024-03-18 13:32:01,527] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=56\n",
      "[2024-03-18 13:32:01,529] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:32:01,529] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=51\n",
      "[2024-03-18 13:32:01,532] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:32:01,533] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=53\n",
      "[2024-03-18 13:32:01,535] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=50\n",
      "[2024-03-18 13:32:01,537] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=59\n",
      "[2024-03-18 13:32:01,551] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0217\n",
      "[2024-03-18 13:32:01,568] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0316\n",
      "[2024-03-18 13:32:01,570] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0308\n",
      "[2024-03-18 13:32:01,580] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0314\n",
      "[2024-03-18 13:32:01,582] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0292\n",
      "[2024-03-18 13:32:01,589] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0290\n",
      "[2024-03-18 13:32:01,597] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0286\n",
      "[2024-03-18 13:32:01,604] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0315\n",
      "[2024-03-18 13:32:02,426] p32749 {295706451.py:39} INFO - e_idx=1/1, chunk_index=20/20\n",
      "[2024-03-18 13:32:02,427] p32749 {2854718021.py:3} INFO - processing chunk with concurrency=8\n",
      "[2024-03-18 13:32:02,429] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:32:02,431] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=54\n",
      "[2024-03-18 13:32:02,431] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:32:02,433] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:32:02,433] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:32:02,435] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:32:02,436] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:32:02,437] p32749 {1106160758.py:22} INFO - get_inference, endpoint=distilbert-base-uncased-1710719092, prompt_tokens=52\n",
      "[2024-03-18 13:32:02,453] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0216\n",
      "[2024-03-18 13:32:02,459] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0236\n",
      "[2024-03-18 13:32:02,466] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0273\n",
      "[2024-03-18 13:32:02,471] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0299\n",
      "[2024-03-18 13:32:02,479] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0355\n",
      "[2024-03-18 13:32:02,487] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0408\n",
      "[2024-03-18 13:32:02,493] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0446\n",
      "[2024-03-18 13:32:02,500] p32749 {1106160758.py:41} INFO - get_inference, done, endpoint=distilbert-base-uncased-1710719092, completion_tokens=6, latency=0.0468\n",
      "[2024-03-18 13:32:03,387] p32749 {295706451.py:63} INFO - the distilbert-base-uncased-ml-p3-2xlarge ran for 112.93984561087564 seconds......\n",
      "[2024-03-18 13:32:03,388] p32749 {295706451.py:70} INFO - the hourly rate for distilbert-base-uncased-ml-p3-2xlarge running on ml.p3.2xlarge is 3.825\n",
      "[2024-03-18 13:32:03,389] p32749 {295706451.py:73} INFO - the rate for distilbert-base-uncased-ml-p3-2xlarge running on ml.p3.2xlarge is 0.0010625 per second\n",
      "[2024-03-18 13:32:03,389] p32749 {295706451.py:77} INFO - the rate for running distilbert-base-uncased-ml-p3-2xlarge running on ml.p3.2xlarge for 112.93984561087564 is $0.11999858596155537....\n",
      "[2024-03-18 13:32:03,390] p32749 {295706451.py:89} INFO - experiment=1/1, name=distilbert-base-uncased-ml-p3-2xlarge, duration=112.94 seconds, done\n",
      "[2024-03-18 13:32:03,402] p32749 {295706451.py:95} INFO - experiment durations:                          experiment_name  instance_type duration_in_seconds  \\\n",
      "0  distilbert-base-uncased-ml-p3-2xlarge  ml.p3.2xlarge              112.94   \n",
      "\n",
      "   cost  \n",
      "0  0.12  \n",
      "[2024-03-18 13:32:03,489] p32749 {295706451.py:104} INFO - Summary for cost of instance per endpoint per run saved to s3://sagemaker-fmbench-write-015469603702/distilbert-base-uncased-v1-SageMaker/data/metrics/yyyy=2024/mm=03/dd=18/hh=13/mm=30/endpoint_per_instance_per_run_costs.csv\n",
      "[2024-03-18 13:32:03,490] p32749 {295706451.py:106} INFO - total cost of all experiments: $0.12\n"
     ]
    }
   ],
   "source": [
    "# for each experiment\n",
    "#   - for each endpoint and concurrency in an experiment\n",
    "\n",
    "def clear_dir(dir_path: str):\n",
    "    files = glob.glob(os.path.join(dir_path, \"*\"))\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "\n",
    "\n",
    "_ = list(map(clear_dir, [METRICS_PER_INFERENCE_DIR, METRICS_PER_CHUNK_DIR]))\n",
    "\n",
    "## Initializing the total model instance cost to 0\n",
    "total_model_instance_cost: int = 0\n",
    "\n",
    "## To keep track of the cost for all model endpoints\n",
    "cost_data = []\n",
    "\n",
    "## To keep track of the experiment durations and the time it takes for the model endpoint to be in service to calculate cost association\n",
    "experiment_durations = []  \n",
    "\n",
    "## start the timer before the start of inferences\n",
    "current_time = datetime.now(timezone.utc)\n",
    "logger.info(f\"Current time recorded while running this experiment is {current_time}..... deployed models are going to start inferences...\")\n",
    "\n",
    "num_experiments: int = len(config['experiments'])\n",
    "for e_idx, experiment in enumerate(config['experiments']):\n",
    "    e_idx += 1  # Increment experiment index\n",
    "    experiment_start_time = time.perf_counter()  # Start timer for the experiment\n",
    "\n",
    "    predictor = create_predictor_for_experiment(experiment, config, endpoint_info_list)\n",
    "    if predictor is None:\n",
    "        logger.error(f\"predictor could not be created for experiment={experiment}, moving to next...\")\n",
    "        continue\n",
    "\n",
    "    combination_data = create_combinations(experiment)\n",
    "\n",
    "    for concurrency, payload_file, split_payload in combination_data:\n",
    "        for chunk_index, chunk in enumerate(split_payload):\n",
    "            logger.info(f\"e_idx={e_idx}/{num_experiments}, chunk_index={chunk_index+1}/{len(split_payload)}\")\n",
    "\n",
    "            responses, metrics = await run_inferences(predictor, chunk, experiment, concurrency, payload_file)\n",
    "            if metrics:\n",
    "                metrics_json = json.dumps(metrics, indent=2)\n",
    "                metrics_file_name = f\"{time.time()}.json\"\n",
    "                metrics_s3_path = os.path.join(METRICS_PER_CHUNK_DIR, metrics_file_name)\n",
    "                write_to_s3(metrics_json, config['aws']['bucket'], \"\", METRICS_PER_CHUNK_DIR, metrics_file_name)\n",
    "\n",
    "            if responses:\n",
    "                for r in responses:\n",
    "                    response_json = json.dumps(r, indent=2)\n",
    "                    response_file_name = f\"{time.time()}.json\"\n",
    "                    response_s3_path = os.path.join(METRICS_PER_INFERENCE_DIR, response_file_name)\n",
    "                    write_to_s3(response_json, config['aws']['bucket'], \"\", METRICS_PER_INFERENCE_DIR, response_file_name)\n",
    "    \n",
    "    ## initializing the experiment cost\n",
    "    exp_cost = 0\n",
    "    \n",
    "    # Experiment done, stopping the timer for this given experiment\n",
    "    experiment_end_time = time.perf_counter()\n",
    "\n",
    "    # calculating the duration of this given endpoint inference time\n",
    "    experiment_duration = experiment_end_time - experiment_start_time\n",
    "    logger.info(f\"the {experiment['name']} ran for {experiment_duration} seconds......\")\n",
    "\n",
    "    # calculating the per second cost for this instance type\n",
    "    exp_instance_type: str = experiment['instance_type']\n",
    "\n",
    "    # price of the given instance for this experiment \n",
    "    hourly_rate = config['pricing'].get(experiment['instance_type'], 0)\n",
    "    logger.info(f\"the hourly rate for {experiment['name']} running on {exp_instance_type} is {hourly_rate}\")\n",
    "\n",
    "    cost_per_second = hourly_rate / 3600\n",
    "    logger.info(f\"the rate for {experiment['name']} running on {exp_instance_type} is {cost_per_second} per second\")\n",
    "    \n",
    "    #cost for this given exp\n",
    "    exp_cost = experiment_duration * cost_per_second\n",
    "    logger.info(f\"the rate for running {experiment['name']} running on {exp_instance_type} for {experiment_duration} is ${exp_cost}....\")\n",
    "\n",
    "    ## tracking the total cost\n",
    "    total_model_instance_cost += exp_cost\n",
    "\n",
    "    experiment_durations.append({\n",
    "        'experiment_name': experiment['name'],\n",
    "        'instance_type': exp_instance_type, \n",
    "        'duration_in_seconds': f\"{experiment_duration:.2f}\", \n",
    "        'cost': f\"{exp_cost:.2f}\", \n",
    "    })\n",
    "\n",
    "    logger.info(f\"experiment={e_idx}/{num_experiments}, name={experiment['name']}, duration={experiment_duration:.2f} seconds, done\")\n",
    "\n",
    "# experiment_durations.append({'total_cost': f\"${total_model_instance_cost:.2f}\"})\n",
    "\n",
    "# After all experiments are done, summarize and optionally save experiment durations along with costs\n",
    "df_durations = pd.DataFrame(experiment_durations)\n",
    "logger.info(f\"experiment durations: {df_durations}\")\n",
    "\n",
    "# Convert the DataFrame to CSV and write it to S3 or wherever you prefer\n",
    "csv_buffer_cost = io.StringIO()\n",
    "df_durations.to_csv(csv_buffer_cost, index=False)\n",
    "experiment_associated_cost = csv_buffer_cost.getvalue()\n",
    "\n",
    "# Assuming write_to_s3() is already defined and configured correctly\n",
    "write_to_s3(experiment_associated_cost, config['aws']['bucket'], \"\", METRICS_DIR, SUMMARY_MODEL_ENDPOINT_COST_PER_INSTANCE)\n",
    "logger.info(f\"Summary for cost of instance per endpoint per run saved to s3://{config['aws']['bucket']}/{METRICS_DIR}/{SUMMARY_MODEL_ENDPOINT_COST_PER_INSTANCE}\")\n",
    "\n",
    "logger.info(f\"total cost of all experiments: ${df_durations.cost.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-18 13:32:03,809] p32749 {utils.py:222} INFO - found 780 items in bucket=sagemaker-fmbench-write-015469603702, prefix=distilbert-base-uncased-v1-SageMaker/data/metrics/yyyy=2024/mm=03/dd=18/hh=13/mm=30/per_inference, suffix=.json\n",
      "[2024-03-18 13:32:03,811] p32749 {utils.py:227} INFO - there are total of 780 items in bucket=sagemaker-fmbench-write-015469603702, prefix=distilbert-base-uncased-v1-SageMaker/data/metrics/yyyy=2024/mm=03/dd=18/hh=13/mm=30/per_inference, suffix=.json\n",
      "[2024-03-18 13:32:58,691] p32749 {11607125.py:10} INFO - created dataframe of shape (780, 10) from all responses\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>endpoint_name</th>\n",
       "      <th>prompt</th>\n",
       "      <th>ContentType</th>\n",
       "      <th>Accept</th>\n",
       "      <th>completion</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>latency</th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>concurrency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>distilbert-base-uncased-1710719092</td>\n",
       "      <td>I'm pretty frustrated about a pound charge tha...</td>\n",
       "      <td>application/x-text</td>\n",
       "      <td>application/json;verbose</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "      <td>0.066721</td>\n",
       "      <td>distilbert-base-uncased-ml-p3-2xlarge</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>distilbert-base-uncased-1710719092</td>\n",
       "      <td>When I used one of the ATMs in the city centre...</td>\n",
       "      <td>application/x-text</td>\n",
       "      <td>application/json;verbose</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>77</td>\n",
       "      <td>6</td>\n",
       "      <td>0.014713</td>\n",
       "      <td>distilbert-base-uncased-ml-p3-2xlarge</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>distilbert-base-uncased-1710719092</td>\n",
       "      <td>Hello. I looked at my account and see that a t...</td>\n",
       "      <td>application/x-text</td>\n",
       "      <td>application/json;verbose</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>62</td>\n",
       "      <td>6</td>\n",
       "      <td>0.014092</td>\n",
       "      <td>distilbert-base-uncased-ml-p3-2xlarge</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>distilbert-base-uncased-1710719092</td>\n",
       "      <td>I tried to get cash at some ATM in the city ce...</td>\n",
       "      <td>application/x-text</td>\n",
       "      <td>application/json;verbose</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>51</td>\n",
       "      <td>6</td>\n",
       "      <td>0.014185</td>\n",
       "      <td>distilbert-base-uncased-ml-p3-2xlarge</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>distilbert-base-uncased-1710719092</td>\n",
       "      <td>I tried to access money earlier but the machin...</td>\n",
       "      <td>application/x-text</td>\n",
       "      <td>application/json;verbose</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "      <td>0.013944</td>\n",
       "      <td>distilbert-base-uncased-ml-p3-2xlarge</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        endpoint_name  \\\n",
       "0  distilbert-base-uncased-1710719092   \n",
       "1  distilbert-base-uncased-1710719092   \n",
       "2  distilbert-base-uncased-1710719092   \n",
       "3  distilbert-base-uncased-1710719092   \n",
       "4  distilbert-base-uncased-1710719092   \n",
       "\n",
       "                                              prompt         ContentType  \\\n",
       "0  I'm pretty frustrated about a pound charge tha...  application/x-text   \n",
       "1  When I used one of the ATMs in the city centre...  application/x-text   \n",
       "2  Hello. I looked at my account and see that a t...  application/x-text   \n",
       "3  I tried to get cash at some ATM in the city ce...  application/x-text   \n",
       "4  I tried to access money earlier but the machin...  application/x-text   \n",
       "\n",
       "                     Accept completion  prompt_tokens  completion_tokens  \\\n",
       "0  application/json;verbose    LABEL_0             53                  6   \n",
       "1  application/json;verbose    LABEL_0             77                  6   \n",
       "2  application/json;verbose    LABEL_0             62                  6   \n",
       "3  application/json;verbose    LABEL_0             51                  6   \n",
       "4  application/json;verbose    LABEL_0             53                  6   \n",
       "\n",
       "    latency                        experiment_name  concurrency  \n",
       "0  0.066721  distilbert-base-uncased-ml-p3-2xlarge            1  \n",
       "1  0.014713  distilbert-base-uncased-ml-p3-2xlarge            1  \n",
       "2  0.014092  distilbert-base-uncased-ml-p3-2xlarge            1  \n",
       "3  0.014185  distilbert-base-uncased-ml-p3-2xlarge            1  \n",
       "4  0.013944  distilbert-base-uncased-ml-p3-2xlarge            1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List .json files in the specified S3 directory\n",
    "s3_files = list_s3_files(config['aws']['bucket'], METRICS_PER_INFERENCE_DIR)\n",
    "\n",
    "# Read and parse each JSON file from S3\n",
    "json_list = list(map(lambda key: json.loads(get_s3_object(config['aws']['bucket'], key)), \\\n",
    "                     s3_files))\n",
    "\n",
    "# Create DataFrame\n",
    "df_responses = pd.DataFrame(json_list)\n",
    "logger.info(f\"created dataframe of shape {df_responses.shape} from all responses\")\n",
    "df_responses.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-18 13:32:58,874] p32749 {utils.py:222} INFO - found 316 items in bucket=sagemaker-fmbench-write-015469603702, prefix=distilbert-base-uncased-v1-SageMaker/data/metrics/yyyy=2024/mm=03/dd=18/hh=13/mm=30/per_chunk, suffix=.json\n",
      "[2024-03-18 13:32:58,875] p32749 {utils.py:227} INFO - there are total of 316 items in bucket=sagemaker-fmbench-write-015469603702, prefix=distilbert-base-uncased-v1-SageMaker/data/metrics/yyyy=2024/mm=03/dd=18/hh=13/mm=30/per_chunk, suffix=.json\n",
      "[2024-03-18 13:33:21,214] p32749 {328901234.py:10} INFO - created dataframe of shape (316, 16) from all responses\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>concurrency</th>\n",
       "      <th>payload_file</th>\n",
       "      <th>errors</th>\n",
       "      <th>successes</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>all_prompts_token_count</th>\n",
       "      <th>prompt_token_count_mean</th>\n",
       "      <th>prompt_token_throughput</th>\n",
       "      <th>all_completions_token_count</th>\n",
       "      <th>completion_token_count_mean</th>\n",
       "      <th>completion_token_throughput</th>\n",
       "      <th>transactions</th>\n",
       "      <th>transactions_per_second</th>\n",
       "      <th>transactions_per_minute</th>\n",
       "      <th>latency_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>distilbert-base-uncased-ml-p3-2xlarge</td>\n",
       "      <td>1</td>\n",
       "      <td>payload_en_50-150.jsonl</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53</td>\n",
       "      <td>53.0</td>\n",
       "      <td>739.37</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>83.70</td>\n",
       "      <td>1</td>\n",
       "      <td>13.95</td>\n",
       "      <td>837</td>\n",
       "      <td>0.066721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>distilbert-base-uncased-ml-p3-2xlarge</td>\n",
       "      <td>1</td>\n",
       "      <td>payload_en_50-150.jsonl</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77</td>\n",
       "      <td>77.0</td>\n",
       "      <td>4286.15</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>333.99</td>\n",
       "      <td>1</td>\n",
       "      <td>55.66</td>\n",
       "      <td>3339</td>\n",
       "      <td>0.014713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>distilbert-base-uncased-ml-p3-2xlarge</td>\n",
       "      <td>1</td>\n",
       "      <td>payload_en_50-150.jsonl</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62</td>\n",
       "      <td>62.0</td>\n",
       "      <td>3441.93</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>333.09</td>\n",
       "      <td>1</td>\n",
       "      <td>55.51</td>\n",
       "      <td>3330</td>\n",
       "      <td>0.014092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>distilbert-base-uncased-ml-p3-2xlarge</td>\n",
       "      <td>1</td>\n",
       "      <td>payload_en_50-150.jsonl</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51</td>\n",
       "      <td>51.0</td>\n",
       "      <td>3015.99</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>354.82</td>\n",
       "      <td>1</td>\n",
       "      <td>59.14</td>\n",
       "      <td>3548</td>\n",
       "      <td>0.014185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>distilbert-base-uncased-ml-p3-2xlarge</td>\n",
       "      <td>1</td>\n",
       "      <td>payload_en_50-150.jsonl</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53</td>\n",
       "      <td>53.0</td>\n",
       "      <td>3186.40</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>360.72</td>\n",
       "      <td>1</td>\n",
       "      <td>60.12</td>\n",
       "      <td>3607</td>\n",
       "      <td>0.013944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         experiment_name  concurrency  \\\n",
       "0  distilbert-base-uncased-ml-p3-2xlarge            1   \n",
       "1  distilbert-base-uncased-ml-p3-2xlarge            1   \n",
       "2  distilbert-base-uncased-ml-p3-2xlarge            1   \n",
       "3  distilbert-base-uncased-ml-p3-2xlarge            1   \n",
       "4  distilbert-base-uncased-ml-p3-2xlarge            1   \n",
       "\n",
       "              payload_file errors  successes  error_rate  \\\n",
       "0  payload_en_50-150.jsonl     []          1         0.0   \n",
       "1  payload_en_50-150.jsonl     []          1         0.0   \n",
       "2  payload_en_50-150.jsonl     []          1         0.0   \n",
       "3  payload_en_50-150.jsonl     []          1         0.0   \n",
       "4  payload_en_50-150.jsonl     []          1         0.0   \n",
       "\n",
       "   all_prompts_token_count  prompt_token_count_mean  prompt_token_throughput  \\\n",
       "0                       53                     53.0                   739.37   \n",
       "1                       77                     77.0                  4286.15   \n",
       "2                       62                     62.0                  3441.93   \n",
       "3                       51                     51.0                  3015.99   \n",
       "4                       53                     53.0                  3186.40   \n",
       "\n",
       "   all_completions_token_count  completion_token_count_mean  \\\n",
       "0                            6                          6.0   \n",
       "1                            6                          6.0   \n",
       "2                            6                          6.0   \n",
       "3                            6                          6.0   \n",
       "4                            6                          6.0   \n",
       "\n",
       "   completion_token_throughput  transactions  transactions_per_second  \\\n",
       "0                        83.70             1                    13.95   \n",
       "1                       333.99             1                    55.66   \n",
       "2                       333.09             1                    55.51   \n",
       "3                       354.82             1                    59.14   \n",
       "4                       360.72             1                    60.12   \n",
       "\n",
       "   transactions_per_minute  latency_mean  \n",
       "0                      837      0.066721  \n",
       "1                     3339      0.014713  \n",
       "2                     3330      0.014092  \n",
       "3                     3548      0.014185  \n",
       "4                     3607      0.013944  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List .json files in the specified S3 directory\n",
    "s3_files = list_s3_files(config['aws']['bucket'], METRICS_PER_CHUNK_DIR)\n",
    "\n",
    "# Read and parse each JSON file from S3\n",
    "json_list = list(map(lambda key: json.loads(get_s3_object(config['aws']['bucket'], key)), \\\n",
    "                     s3_files))\n",
    "\n",
    "# Create DataFrame\n",
    "df_metrics = pd.DataFrame(json_list)\n",
    "logger.info(f\"created dataframe of shape {df_metrics.shape} from all responses\")\n",
    "df_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model_config.PrimaryContainer.Environment.ENDPOINT_SERVER_TIMEOUT', 'model_config.PrimaryContainer.Environment.MODEL_CACHE_ROOT', 'model_config.PrimaryContainer.Environment.SAGEMAKER_ENV', 'model_config.PrimaryContainer.Environment.SAGEMAKER_MODEL_SERVER_WORKERS', 'model_config.PrimaryContainer.Environment.SAGEMAKER_PROGRAM']\n",
      "Columns in df_responses: Index(['endpoint_name', 'prompt', 'ContentType', 'Accept', 'completion',\n",
      "       'prompt_tokens', 'completion_tokens', 'latency', 'experiment_name',\n",
      "       'concurrency'],\n",
      "      dtype='object')\n",
      "Columns in df_endpoints: Index(['experiment_name', 'instance_type', 'EndpointName', 'ModelName',\n",
      "       'Image', 'S3Uri', 'ENDPOINT_SERVER_TIMEOUT', 'MODEL_CACHE_ROOT',\n",
      "       'SAGEMAKER_ENV', 'SAGEMAKER_MODEL_SERVER_WORKERS', 'SAGEMAKER_PROGRAM'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>endpoint_name</th>\n",
       "      <th>prompt</th>\n",
       "      <th>ContentType</th>\n",
       "      <th>Accept</th>\n",
       "      <th>completion</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>latency</th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>concurrency</th>\n",
       "      <th>instance_type</th>\n",
       "      <th>EndpointName</th>\n",
       "      <th>ModelName</th>\n",
       "      <th>Image</th>\n",
       "      <th>S3Uri</th>\n",
       "      <th>ENDPOINT_SERVER_TIMEOUT</th>\n",
       "      <th>MODEL_CACHE_ROOT</th>\n",
       "      <th>SAGEMAKER_ENV</th>\n",
       "      <th>SAGEMAKER_MODEL_SERVER_WORKERS</th>\n",
       "      <th>SAGEMAKER_PROGRAM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>distilbert-base-uncased-1710719092</td>\n",
       "      <td>I'm pretty frustrated about a pound charge tha...</td>\n",
       "      <td>application/x-text</td>\n",
       "      <td>application/json;verbose</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "      <td>0.066721</td>\n",
       "      <td>distilbert-base-uncased-ml-p3-2xlarge</td>\n",
       "      <td>1</td>\n",
       "      <td>ml.p3.2xlarge</td>\n",
       "      <td>distilbert-base-uncased-1710719092</td>\n",
       "      <td>hf-tc-distilbert-base-uncased-2024-03-17-23-44...</td>\n",
       "      <td>763104351884.dkr.ecr.us-east-1.amazonaws.com/h...</td>\n",
       "      <td>s3://jumpstart-cache-prod-us-east-1/huggingfac...</td>\n",
       "      <td>3600</td>\n",
       "      <td>/opt/ml/model</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>inference.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>distilbert-base-uncased-1710719092</td>\n",
       "      <td>When I used one of the ATMs in the city centre...</td>\n",
       "      <td>application/x-text</td>\n",
       "      <td>application/json;verbose</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>77</td>\n",
       "      <td>6</td>\n",
       "      <td>0.014713</td>\n",
       "      <td>distilbert-base-uncased-ml-p3-2xlarge</td>\n",
       "      <td>1</td>\n",
       "      <td>ml.p3.2xlarge</td>\n",
       "      <td>distilbert-base-uncased-1710719092</td>\n",
       "      <td>hf-tc-distilbert-base-uncased-2024-03-17-23-44...</td>\n",
       "      <td>763104351884.dkr.ecr.us-east-1.amazonaws.com/h...</td>\n",
       "      <td>s3://jumpstart-cache-prod-us-east-1/huggingfac...</td>\n",
       "      <td>3600</td>\n",
       "      <td>/opt/ml/model</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>inference.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>distilbert-base-uncased-1710719092</td>\n",
       "      <td>Hello. I looked at my account and see that a t...</td>\n",
       "      <td>application/x-text</td>\n",
       "      <td>application/json;verbose</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>62</td>\n",
       "      <td>6</td>\n",
       "      <td>0.014092</td>\n",
       "      <td>distilbert-base-uncased-ml-p3-2xlarge</td>\n",
       "      <td>1</td>\n",
       "      <td>ml.p3.2xlarge</td>\n",
       "      <td>distilbert-base-uncased-1710719092</td>\n",
       "      <td>hf-tc-distilbert-base-uncased-2024-03-17-23-44...</td>\n",
       "      <td>763104351884.dkr.ecr.us-east-1.amazonaws.com/h...</td>\n",
       "      <td>s3://jumpstart-cache-prod-us-east-1/huggingfac...</td>\n",
       "      <td>3600</td>\n",
       "      <td>/opt/ml/model</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>inference.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>distilbert-base-uncased-1710719092</td>\n",
       "      <td>I tried to get cash at some ATM in the city ce...</td>\n",
       "      <td>application/x-text</td>\n",
       "      <td>application/json;verbose</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>51</td>\n",
       "      <td>6</td>\n",
       "      <td>0.014185</td>\n",
       "      <td>distilbert-base-uncased-ml-p3-2xlarge</td>\n",
       "      <td>1</td>\n",
       "      <td>ml.p3.2xlarge</td>\n",
       "      <td>distilbert-base-uncased-1710719092</td>\n",
       "      <td>hf-tc-distilbert-base-uncased-2024-03-17-23-44...</td>\n",
       "      <td>763104351884.dkr.ecr.us-east-1.amazonaws.com/h...</td>\n",
       "      <td>s3://jumpstart-cache-prod-us-east-1/huggingfac...</td>\n",
       "      <td>3600</td>\n",
       "      <td>/opt/ml/model</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>inference.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>distilbert-base-uncased-1710719092</td>\n",
       "      <td>I tried to access money earlier but the machin...</td>\n",
       "      <td>application/x-text</td>\n",
       "      <td>application/json;verbose</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "      <td>0.013944</td>\n",
       "      <td>distilbert-base-uncased-ml-p3-2xlarge</td>\n",
       "      <td>1</td>\n",
       "      <td>ml.p3.2xlarge</td>\n",
       "      <td>distilbert-base-uncased-1710719092</td>\n",
       "      <td>hf-tc-distilbert-base-uncased-2024-03-17-23-44...</td>\n",
       "      <td>763104351884.dkr.ecr.us-east-1.amazonaws.com/h...</td>\n",
       "      <td>s3://jumpstart-cache-prod-us-east-1/huggingfac...</td>\n",
       "      <td>3600</td>\n",
       "      <td>/opt/ml/model</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>inference.py</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        endpoint_name  \\\n",
       "0  distilbert-base-uncased-1710719092   \n",
       "1  distilbert-base-uncased-1710719092   \n",
       "2  distilbert-base-uncased-1710719092   \n",
       "3  distilbert-base-uncased-1710719092   \n",
       "4  distilbert-base-uncased-1710719092   \n",
       "\n",
       "                                              prompt         ContentType  \\\n",
       "0  I'm pretty frustrated about a pound charge tha...  application/x-text   \n",
       "1  When I used one of the ATMs in the city centre...  application/x-text   \n",
       "2  Hello. I looked at my account and see that a t...  application/x-text   \n",
       "3  I tried to get cash at some ATM in the city ce...  application/x-text   \n",
       "4  I tried to access money earlier but the machin...  application/x-text   \n",
       "\n",
       "                     Accept completion  prompt_tokens  completion_tokens  \\\n",
       "0  application/json;verbose    LABEL_0             53                  6   \n",
       "1  application/json;verbose    LABEL_0             77                  6   \n",
       "2  application/json;verbose    LABEL_0             62                  6   \n",
       "3  application/json;verbose    LABEL_0             51                  6   \n",
       "4  application/json;verbose    LABEL_0             53                  6   \n",
       "\n",
       "    latency                        experiment_name  concurrency  \\\n",
       "0  0.066721  distilbert-base-uncased-ml-p3-2xlarge            1   \n",
       "1  0.014713  distilbert-base-uncased-ml-p3-2xlarge            1   \n",
       "2  0.014092  distilbert-base-uncased-ml-p3-2xlarge            1   \n",
       "3  0.014185  distilbert-base-uncased-ml-p3-2xlarge            1   \n",
       "4  0.013944  distilbert-base-uncased-ml-p3-2xlarge            1   \n",
       "\n",
       "   instance_type                        EndpointName  \\\n",
       "0  ml.p3.2xlarge  distilbert-base-uncased-1710719092   \n",
       "1  ml.p3.2xlarge  distilbert-base-uncased-1710719092   \n",
       "2  ml.p3.2xlarge  distilbert-base-uncased-1710719092   \n",
       "3  ml.p3.2xlarge  distilbert-base-uncased-1710719092   \n",
       "4  ml.p3.2xlarge  distilbert-base-uncased-1710719092   \n",
       "\n",
       "                                           ModelName  \\\n",
       "0  hf-tc-distilbert-base-uncased-2024-03-17-23-44...   \n",
       "1  hf-tc-distilbert-base-uncased-2024-03-17-23-44...   \n",
       "2  hf-tc-distilbert-base-uncased-2024-03-17-23-44...   \n",
       "3  hf-tc-distilbert-base-uncased-2024-03-17-23-44...   \n",
       "4  hf-tc-distilbert-base-uncased-2024-03-17-23-44...   \n",
       "\n",
       "                                               Image  \\\n",
       "0  763104351884.dkr.ecr.us-east-1.amazonaws.com/h...   \n",
       "1  763104351884.dkr.ecr.us-east-1.amazonaws.com/h...   \n",
       "2  763104351884.dkr.ecr.us-east-1.amazonaws.com/h...   \n",
       "3  763104351884.dkr.ecr.us-east-1.amazonaws.com/h...   \n",
       "4  763104351884.dkr.ecr.us-east-1.amazonaws.com/h...   \n",
       "\n",
       "                                               S3Uri ENDPOINT_SERVER_TIMEOUT  \\\n",
       "0  s3://jumpstart-cache-prod-us-east-1/huggingfac...                    3600   \n",
       "1  s3://jumpstart-cache-prod-us-east-1/huggingfac...                    3600   \n",
       "2  s3://jumpstart-cache-prod-us-east-1/huggingfac...                    3600   \n",
       "3  s3://jumpstart-cache-prod-us-east-1/huggingfac...                    3600   \n",
       "4  s3://jumpstart-cache-prod-us-east-1/huggingfac...                    3600   \n",
       "\n",
       "  MODEL_CACHE_ROOT SAGEMAKER_ENV SAGEMAKER_MODEL_SERVER_WORKERS  \\\n",
       "0    /opt/ml/model             1                              1   \n",
       "1    /opt/ml/model             1                              1   \n",
       "2    /opt/ml/model             1                              1   \n",
       "3    /opt/ml/model             1                              1   \n",
       "4    /opt/ml/model             1                              1   \n",
       "\n",
       "  SAGEMAKER_PROGRAM  \n",
       "0      inference.py  \n",
       "1      inference.py  \n",
       "2      inference.py  \n",
       "3      inference.py  \n",
       "4      inference.py  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_endpoints = pd.json_normalize(endpoint_info_list)\n",
    "df_endpoints['instance_type'] = df_endpoints['endpoint_config.ProductionVariants'].map(lambda x: x[0]['InstanceType'])\n",
    "df_endpoints\n",
    "cols_for_env = [c for c in df_endpoints.columns if 'Environment' in c]\n",
    "print(cols_for_env)\n",
    "cols_of_interest = ['experiment_name', \n",
    "                    'instance_type',\n",
    "                    'endpoint.EndpointName',\n",
    "                    'model_config.ModelName',\n",
    "                    'model_config.PrimaryContainer.Image',   \n",
    "                    'model_config.PrimaryContainer.ModelDataSource.S3DataSource.S3Uri']\n",
    "cols_of_interest.extend(cols_for_env)\n",
    "\n",
    "df_endpoints = df_endpoints[cols_of_interest]\n",
    "df_endpoints = df_endpoints[cols_of_interest]\n",
    "cols_of_interest_renamed = [c.split('.')[-1] for c in cols_of_interest]\n",
    "df_endpoints.columns = cols_of_interest_renamed\n",
    "\n",
    "# Check if 'experiment_name' column exists in both DataFrames\n",
    "print(\"Columns in df_responses:\", df_responses.columns)\n",
    "print(\"Columns in df_endpoints:\", df_endpoints.columns)\n",
    "\n",
    "# Merge operation\n",
    "df_results = pd.merge(left=df_responses, right=df_endpoints, how='left', left_on='experiment_name', right_on='experiment_name')\n",
    "\n",
    "# Inspect the result\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>endpoint_name</th>\n",
       "      <th>prompt</th>\n",
       "      <th>ContentType</th>\n",
       "      <th>Accept</th>\n",
       "      <th>completion</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>latency</th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>concurrency</th>\n",
       "      <th>instance_type</th>\n",
       "      <th>EndpointName</th>\n",
       "      <th>ModelName</th>\n",
       "      <th>Image</th>\n",
       "      <th>S3Uri</th>\n",
       "      <th>ENDPOINT_SERVER_TIMEOUT</th>\n",
       "      <th>MODEL_CACHE_ROOT</th>\n",
       "      <th>SAGEMAKER_ENV</th>\n",
       "      <th>SAGEMAKER_MODEL_SERVER_WORKERS</th>\n",
       "      <th>SAGEMAKER_PROGRAM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>distilbert-base-uncased-1710719092</td>\n",
       "      <td>I'm pretty frustrated about a pound charge tha...</td>\n",
       "      <td>application/x-text</td>\n",
       "      <td>application/json;verbose</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "      <td>0.066721</td>\n",
       "      <td>distilbert-base-uncased-ml-p3-2xlarge</td>\n",
       "      <td>1</td>\n",
       "      <td>ml.p3.2xlarge</td>\n",
       "      <td>distilbert-base-uncased-1710719092</td>\n",
       "      <td>hf-tc-distilbert-base-uncased-2024-03-17-23-44...</td>\n",
       "      <td>763104351884.dkr.ecr.us-east-1.amazonaws.com/h...</td>\n",
       "      <td>s3://jumpstart-cache-prod-us-east-1/huggingfac...</td>\n",
       "      <td>3600</td>\n",
       "      <td>/opt/ml/model</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>inference.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>distilbert-base-uncased-1710719092</td>\n",
       "      <td>When I used one of the ATMs in the city centre...</td>\n",
       "      <td>application/x-text</td>\n",
       "      <td>application/json;verbose</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>77</td>\n",
       "      <td>6</td>\n",
       "      <td>0.014713</td>\n",
       "      <td>distilbert-base-uncased-ml-p3-2xlarge</td>\n",
       "      <td>1</td>\n",
       "      <td>ml.p3.2xlarge</td>\n",
       "      <td>distilbert-base-uncased-1710719092</td>\n",
       "      <td>hf-tc-distilbert-base-uncased-2024-03-17-23-44...</td>\n",
       "      <td>763104351884.dkr.ecr.us-east-1.amazonaws.com/h...</td>\n",
       "      <td>s3://jumpstart-cache-prod-us-east-1/huggingfac...</td>\n",
       "      <td>3600</td>\n",
       "      <td>/opt/ml/model</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>inference.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>distilbert-base-uncased-1710719092</td>\n",
       "      <td>Hello. I looked at my account and see that a t...</td>\n",
       "      <td>application/x-text</td>\n",
       "      <td>application/json;verbose</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>62</td>\n",
       "      <td>6</td>\n",
       "      <td>0.014092</td>\n",
       "      <td>distilbert-base-uncased-ml-p3-2xlarge</td>\n",
       "      <td>1</td>\n",
       "      <td>ml.p3.2xlarge</td>\n",
       "      <td>distilbert-base-uncased-1710719092</td>\n",
       "      <td>hf-tc-distilbert-base-uncased-2024-03-17-23-44...</td>\n",
       "      <td>763104351884.dkr.ecr.us-east-1.amazonaws.com/h...</td>\n",
       "      <td>s3://jumpstart-cache-prod-us-east-1/huggingfac...</td>\n",
       "      <td>3600</td>\n",
       "      <td>/opt/ml/model</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>inference.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>distilbert-base-uncased-1710719092</td>\n",
       "      <td>I tried to get cash at some ATM in the city ce...</td>\n",
       "      <td>application/x-text</td>\n",
       "      <td>application/json;verbose</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>51</td>\n",
       "      <td>6</td>\n",
       "      <td>0.014185</td>\n",
       "      <td>distilbert-base-uncased-ml-p3-2xlarge</td>\n",
       "      <td>1</td>\n",
       "      <td>ml.p3.2xlarge</td>\n",
       "      <td>distilbert-base-uncased-1710719092</td>\n",
       "      <td>hf-tc-distilbert-base-uncased-2024-03-17-23-44...</td>\n",
       "      <td>763104351884.dkr.ecr.us-east-1.amazonaws.com/h...</td>\n",
       "      <td>s3://jumpstart-cache-prod-us-east-1/huggingfac...</td>\n",
       "      <td>3600</td>\n",
       "      <td>/opt/ml/model</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>inference.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>distilbert-base-uncased-1710719092</td>\n",
       "      <td>I tried to access money earlier but the machin...</td>\n",
       "      <td>application/x-text</td>\n",
       "      <td>application/json;verbose</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "      <td>0.013944</td>\n",
       "      <td>distilbert-base-uncased-ml-p3-2xlarge</td>\n",
       "      <td>1</td>\n",
       "      <td>ml.p3.2xlarge</td>\n",
       "      <td>distilbert-base-uncased-1710719092</td>\n",
       "      <td>hf-tc-distilbert-base-uncased-2024-03-17-23-44...</td>\n",
       "      <td>763104351884.dkr.ecr.us-east-1.amazonaws.com/h...</td>\n",
       "      <td>s3://jumpstart-cache-prod-us-east-1/huggingfac...</td>\n",
       "      <td>3600</td>\n",
       "      <td>/opt/ml/model</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>inference.py</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        endpoint_name  \\\n",
       "0  distilbert-base-uncased-1710719092   \n",
       "1  distilbert-base-uncased-1710719092   \n",
       "2  distilbert-base-uncased-1710719092   \n",
       "3  distilbert-base-uncased-1710719092   \n",
       "4  distilbert-base-uncased-1710719092   \n",
       "\n",
       "                                              prompt         ContentType  \\\n",
       "0  I'm pretty frustrated about a pound charge tha...  application/x-text   \n",
       "1  When I used one of the ATMs in the city centre...  application/x-text   \n",
       "2  Hello. I looked at my account and see that a t...  application/x-text   \n",
       "3  I tried to get cash at some ATM in the city ce...  application/x-text   \n",
       "4  I tried to access money earlier but the machin...  application/x-text   \n",
       "\n",
       "                     Accept completion  prompt_tokens  completion_tokens  \\\n",
       "0  application/json;verbose    LABEL_0             53                  6   \n",
       "1  application/json;verbose    LABEL_0             77                  6   \n",
       "2  application/json;verbose    LABEL_0             62                  6   \n",
       "3  application/json;verbose    LABEL_0             51                  6   \n",
       "4  application/json;verbose    LABEL_0             53                  6   \n",
       "\n",
       "    latency                        experiment_name  concurrency  \\\n",
       "0  0.066721  distilbert-base-uncased-ml-p3-2xlarge            1   \n",
       "1  0.014713  distilbert-base-uncased-ml-p3-2xlarge            1   \n",
       "2  0.014092  distilbert-base-uncased-ml-p3-2xlarge            1   \n",
       "3  0.014185  distilbert-base-uncased-ml-p3-2xlarge            1   \n",
       "4  0.013944  distilbert-base-uncased-ml-p3-2xlarge            1   \n",
       "\n",
       "   instance_type                        EndpointName  \\\n",
       "0  ml.p3.2xlarge  distilbert-base-uncased-1710719092   \n",
       "1  ml.p3.2xlarge  distilbert-base-uncased-1710719092   \n",
       "2  ml.p3.2xlarge  distilbert-base-uncased-1710719092   \n",
       "3  ml.p3.2xlarge  distilbert-base-uncased-1710719092   \n",
       "4  ml.p3.2xlarge  distilbert-base-uncased-1710719092   \n",
       "\n",
       "                                           ModelName  \\\n",
       "0  hf-tc-distilbert-base-uncased-2024-03-17-23-44...   \n",
       "1  hf-tc-distilbert-base-uncased-2024-03-17-23-44...   \n",
       "2  hf-tc-distilbert-base-uncased-2024-03-17-23-44...   \n",
       "3  hf-tc-distilbert-base-uncased-2024-03-17-23-44...   \n",
       "4  hf-tc-distilbert-base-uncased-2024-03-17-23-44...   \n",
       "\n",
       "                                               Image  \\\n",
       "0  763104351884.dkr.ecr.us-east-1.amazonaws.com/h...   \n",
       "1  763104351884.dkr.ecr.us-east-1.amazonaws.com/h...   \n",
       "2  763104351884.dkr.ecr.us-east-1.amazonaws.com/h...   \n",
       "3  763104351884.dkr.ecr.us-east-1.amazonaws.com/h...   \n",
       "4  763104351884.dkr.ecr.us-east-1.amazonaws.com/h...   \n",
       "\n",
       "                                               S3Uri ENDPOINT_SERVER_TIMEOUT  \\\n",
       "0  s3://jumpstart-cache-prod-us-east-1/huggingfac...                    3600   \n",
       "1  s3://jumpstart-cache-prod-us-east-1/huggingfac...                    3600   \n",
       "2  s3://jumpstart-cache-prod-us-east-1/huggingfac...                    3600   \n",
       "3  s3://jumpstart-cache-prod-us-east-1/huggingfac...                    3600   \n",
       "4  s3://jumpstart-cache-prod-us-east-1/huggingfac...                    3600   \n",
       "\n",
       "  MODEL_CACHE_ROOT SAGEMAKER_ENV SAGEMAKER_MODEL_SERVER_WORKERS  \\\n",
       "0    /opt/ml/model             1                              1   \n",
       "1    /opt/ml/model             1                              1   \n",
       "2    /opt/ml/model             1                              1   \n",
       "3    /opt/ml/model             1                              1   \n",
       "4    /opt/ml/model             1                              1   \n",
       "\n",
       "  SAGEMAKER_PROGRAM  \n",
       "0      inference.py  \n",
       "1      inference.py  \n",
       "2      inference.py  \n",
       "3      inference.py  \n",
       "4      inference.py  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.merge(left=df_responses, right=df_endpoints, how='left', left_on='experiment_name', right_on='experiment_name')\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-18 13:33:21,355] p32749 {1276732506.py:7} INFO - results s3 path for per inference csv --> distilbert-base-uncased-v1-SageMaker/data/metrics/yyyy=2024/mm=03/dd=18/hh=13/mm=30/per_inference_request_results.csv\n",
      "[2024-03-18 13:33:21,655] p32749 {1276732506.py:9} INFO - saved results dataframe of shape=(780, 20) in s3://sagemaker-fmbench-write-015469603702/distilbert-base-uncased-v1-SageMaker/data/metrics/yyyy=2024/mm=03/dd=18/hh=13/mm=30/per_inference_request_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Convert df_results to CSV and write to S3\n",
    "csv_buffer = io.StringIO()\n",
    "df_results.to_csv(csv_buffer, index=False)\n",
    "csv_data_results = csv_buffer.getvalue()\n",
    "results_file_name = config['results']['per_inference_request_file'].format(datetime=date_time)\n",
    "results_s3_path = os.path.join(METRICS_DIR, results_file_name)\n",
    "logger.info(f\"results s3 path for per inference csv --> {results_s3_path}\")\n",
    "write_to_s3(csv_data_results, config['aws']['bucket'], \"\", METRICS_DIR, results_file_name)\n",
    "logger.info(f\"saved results dataframe of shape={df_results.shape} in s3://{BUCKET_NAME}/{results_s3_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-18 13:33:21,666] p32749 {4009704708.py:6} INFO - the metrics metadata path is saved here --> metadata/metrics_path.txt\n",
      "[2024-03-18 13:33:21,759] p32749 {4009704708.py:15} INFO - the information on the defined path for results on these metrics are given in this --> distilbert-base-uncased-v1-SageMaker/data/metrics/yyyy=2024/mm=03/dd=18/hh=13/mm=30\n"
     ]
    }
   ],
   "source": [
    "# Ensure the metadata directory exists\n",
    "os.makedirs(METADATA_DIR, exist_ok=True)\n",
    "\n",
    "# Path for the metrics_path.txt file\n",
    "metrics_path_file = os.path.join(METADATA_DIR, 'metrics_path.txt')\n",
    "logger.info(f\"the metrics metadata path is saved here --> {metrics_path_file}\")\n",
    "\n",
    "# Write the METRICS_DIR to metrics_path.txt\n",
    "with open(metrics_path_file, 'w') as file:\n",
    "    file.write(METRICS_DIR)\n",
    "\n",
    "## Write this data to S3\n",
    "write_to_s3(METRICS_DIR, config['aws']['bucket'], \"\", DATA_DIR, 'metrics_path.txt')\n",
    "\n",
    "logger.info(f\"the information on the defined path for results on these metrics are given in this --> {METRICS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-18 13:33:21,772] p32749 {2907251140.py:1} INFO - df_metrics cols = Index(['experiment_name', 'concurrency', 'payload_file', 'errors', 'successes',\n",
      "       'error_rate', 'all_prompts_token_count', 'prompt_token_count_mean',\n",
      "       'prompt_token_throughput', 'all_completions_token_count',\n",
      "       'completion_token_count_mean', 'completion_token_throughput',\n",
      "       'transactions', 'transactions_per_second', 'transactions_per_minute',\n",
      "       'latency_mean'],\n",
      "      dtype='object')\n",
      "[2024-03-18 13:33:21,776] p32749 {2907251140.py:2} INFO - df_endpoints cols = Index(['experiment_name', 'instance_type', 'EndpointName', 'ModelName',\n",
      "       'Image', 'S3Uri', 'ENDPOINT_SERVER_TIMEOUT', 'MODEL_CACHE_ROOT',\n",
      "       'SAGEMAKER_ENV', 'SAGEMAKER_MODEL_SERVER_WORKERS', 'SAGEMAKER_PROGRAM'],\n",
      "      dtype='object')\n",
      "[2024-03-18 13:33:21,793] p32749 {2907251140.py:12} INFO - results s3 path for metrics csv --> distilbert-base-uncased-v1-SageMaker/data/metrics/yyyy=2024/mm=03/dd=18/hh=13/mm=30/all_metrics.csv\n",
      "[2024-03-18 13:33:21,921] p32749 {2907251140.py:14} INFO - saved metrics results dataframe of shape=(316, 26) in s3://sagemaker-fmbench-write-015469603702/distilbert-base-uncased-v1-SageMaker/data/metrics/yyyy=2024/mm=03/dd=18/hh=13/mm=30/all_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"df_metrics cols = {df_metrics.columns}\")\n",
    "logger.info(f\"df_endpoints cols = {df_endpoints.columns}\")\n",
    "df_metrics = pd.merge(left=df_metrics, right=df_endpoints, how='left', left_on='experiment_name', right_on='experiment_name')\n",
    "df_metrics.head()\n",
    "\n",
    "# Convert df_metrics to CSV and write to S3\n",
    "csv_buffer = io.StringIO()\n",
    "df_metrics.to_csv(csv_buffer, index=False)\n",
    "csv_data_metrics = csv_buffer.getvalue()\n",
    "metrics_file_name = config['results']['all_metrics_file'].format(datetime=date_time)\n",
    "metrics_s3_path = os.path.join(METRICS_DIR, metrics_file_name)\n",
    "logger.info(f\"results s3 path for metrics csv --> {metrics_s3_path}\")\n",
    "write_to_s3(csv_data_metrics, config['aws']['bucket'], \"\", METRICS_DIR, metrics_file_name)\n",
    "logger.info(f\"saved metrics results dataframe of shape={df_metrics.shape} in s3://{config['aws']['bucket']}/{metrics_s3_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.c5.large",
  "kernelspec": {
   "display_name": "conda_my_python311",
   "language": "python",
   "name": "conda_my_python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
